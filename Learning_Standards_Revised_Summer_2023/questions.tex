%QUESTION BANK DOCUMENT
%This is where questions are stored so that they may
%be imported in future documents.


%NEW QUESTION TEMPLATE

%\begin{SaveQuestion}{<question type>}[
        %key=<question key>,
        %prompt={<question>}
%][<learning standards>] %this is written as a comma seperated list with no spaces between commas
    %[<rubric items>]    %this is written as a comma seperated list with no spaces between commas
    %<question solution>
%\end{SaveQuestion}

% NOTES

%1) In the line "key=<question key>," do not use any spaces. 

%2) The arguments <learning standards>, <rubric items>, <items mark>, and <question solution> are all optional arguments. However, they must appear in the order listed above (i.e., if you include any rubric items you must have learning standards included or at least include an empty square bracket). The only exception to such is <question solution> which can be included even if none of the other parameters that succeed it are present. Lastly, both <rubric items> and <items mark> must be included simultaneously and be of equal length; the code will not work if this fails.

%3) There are 5 different question types that can be selected for the <question type> argument. We will denote which of these environments are numbered using an asterisk. All environments are numbered strictly within their own environment.
%  - <exercise> This is used to declare an "Exercise"* environment.
%  - <task> This is used to declare a "Task"* environment.
%  - <problem> This is used to declare a "Problem"* environment.
%  - <question> This is used to declare a "Question"* environment.
%%%SBG
%%%Developmental 
%  - <tbd> This is used to declare a "To Be Decided" environment.
% You must select one of these types to save a question.

%4) Grader (GRAD) and Solution (SOL) audiences are already declared within the package documentation. You must however use the following in the document to select the current audience.
%    \DefCurrentAudience{GRAD}
%    \DefCurrentAudience{SOL}
% You may additionally not specify any of these audiences; this would be the student view. Selecting the SOL audience will show <question solution>. The GRAD audience will show <question solution>, and additionally, <rubric items> and <items mark>.

%5) In order to access saved questions, you must include the following line of code.
%    \input{Learning_Standards_Revised_Summer_2023/questions.tex}
% Once this line has been included, you may use \PullQ{<question key>} to insert the question that <question key> is associted with.

%6) Naming question keys should be done using the following procedure
%   key = ch<question chapter/chapter.section number>-<general topic>-<question specific topic>
%   E.G     ch1-lineq-magiccarpet

%Found a vector that satisfies part (1),Vectors are both unit vectors and separated by an angle of $\frac{\pi}{6}$ in part (2),Vectors are perpendicular non-zero vectors in $R$ in part (3),Must explain why such vectors do not exist in part (4),Line is written in vector form and meets the criteria stated in part (5),Plane meets the criteria stated in part (6)


\begin{SaveQuestion}[
    key=ch0-vecarith-misc1-sbg, 
    prompt={In each part, give an explicit example of the described object or explain why such an object does not exist.
        \begin{enumerate}
            \item A vector in $\mathbb{R}^4$ whose magnitude is 4. 
            \item Two unit vectors in $\mathbb{R}^3$ whose angle between them is $\frac{\pi}{4}$. 
            \item Two perpendicular nonzero vectors in $\mathbb{R}^2$. 
            \item Three mutually perpendicular nonzero vectors in $\mathbb{R}^2$. 
            \item A line in $\mathbb{R}^3$ that passes through $(1,2,3)$ and does not pass through $(0,0,0)$ in vector form, using proper set notation.
            \item Equation of a plane in $\mathbb{R}^3$ that passes through the origin and contains the point $(1,3,4)$ and $(1,1,1)$.
        \end{enumerate}}]
    [chg-WRIT-matnot]
    [Must have correct and consistent notation for their correct answers*Q1: A column or row vector with four (4) entries and enclosed by brackets or parentheses*Q2: Two vectors, in column or row form, each with three (3) entries and enclosed by brackets or parentheses*Q3: Two vectors, in column or row form, each with two (2) entries and enclosed by brackets or parentheses; each vector must contain at least one non-zero entry*Q5: Proper set notation, with braces, must be present; vector form must be used with exactly one (1) parameter*Q6: The plane must be in normal form*]
    \begin{enumerate}
    \item Recall that by definition, the \MathCite{norm}[magnitude] for a vector       $\vec u = \begin{bmatrix} x \\ y \\ z \\ w \end{bmatrix} \in \mathbb{R}^4$ is   given by the following. 
    $$\|\vec u\| = \sqrt{x^2 + y^2 + w^2 + z^2}$$
    Although there exists many possible solutions to the equation above, a trivial example would be to consider the vectors of length four along any of the four axes. For example take $\begin{bmatrix} 4 \\ 0 \\ 0 \\ 0 \end{bmatrix}$, the vector of length 4 along the $x$-axis. 
    
    \item Recall that by definition, the \MathCite{angle} between two vectors $\vec u, \vec v \in \mathbb{R}^n$ is given by the following.
    $$\theta = \arccos\left(\frac{\vec u \cdot \vec v}{\|\vec u\|\|\vec v\|}\right)$$
    In our case, both $\vec u$ and $\vec v$ are unit vectors implying $\|\vec u\| = 1, \|\vec v\| = 1$, and $\theta = \frac{\pi}{4}$. Consequently, we simplify to the equation $\frac{\pi}{4} = \arccos(\vec u \cdot \vec v)$. As $\arccos(\frac{\sqrt{2}}{2}) = \frac{\pi}{4}$, any unit vectors $\vec u, \vec v$ such that $\vec u \cdot \vec v = \frac{\sqrt{2}}{2}$ will work. One example is as follows.
    $$\vec u = \begin{bmatrix} 1 \\ 0 \\ 0 \end{bmatrix}, \ \ \ \vec v = \begin{bmatrix} \frac{\sqrt{2}}{2} \\ \frac{\sqrt{2}}{2} \\ 0 \end{bmatrix} \Longrightarrow \vec u \cdot \vec v = (1)\left(\frac{\sqrt{2}}{2}\right) + (0)\left(\frac{\sqrt{2}}{2}\right) + (0)(0) = \frac{\sqrt{2}}{2}$$
    
    \item Recall that by definition, two vectors $\vec u, \vec v \in \mathbb{R}^2$ are said to be \MathCite{perpendicular} if $\vec u \cdot \vec v = u_1 v_1 + u_2 v_2 = 0$, equivalently $u_1 v_1 = - u_2 v_2$. Although there are many possible solutions, we fix $u_1 = u_2$ which implies that $-v_1 = v_2$. \\ \\
    Thus, $\vec u = \begin{bmatrix} 1 \\ 1 \end{bmatrix}$ and $\vec v \begin{bmatrix} -1 \\ 1 \end{bmatrix}$ are two possible vectors. See visualization \href{https://www.desmos.com/calculator/pdwupzdiyg}{\textbf{here}}.
    
    \item It is not possible. Try to visualize this problem geometrically by drawing two vectors that are perpendicular. In $\mathbb{R}^2$, since there are only two directions we cannot find a third vector that would be mutually perpendicular.  \\ \\
    Consider the vectors $\vec u = \begin{bmatrix} 1 \\ 1 \end{bmatrix}$ and $\vec v \begin{bmatrix} -1 \\ 1 \end{bmatrix}$ from the previous part of this question, and observe the sketch below. See visualization \href{https://www.desmos.com/calculator/pdwupzdiyg}{\textbf{here}}.

    \item Recall that by definition, a \MathCite{line} in $\mathbb{R}^3$ is given by $L = \{t \vec d  + \vec p \ | \ t \in \mathbb{R}\}$, where $\vec d, \vec p \in \mathbb{R}^3$. To ensure the line passes by the point (1, 2, 3), we can fix $\vec p = \begin{bmatrix} 1 \\ 2 \\ 3 \end{bmatrix}$. For the direction vector, choosing any $\vec d$ such that $\forall k \in \mathbb{R}, k \vec d \neq \vec p$ (i.e., not scalar multiples) will yield a line satisfying the constraint. Here, we take $\vec d = \begin{bmatrix} 2 \\ 3 \\ 4 \end{bmatrix}$. \\ \\
    In proper set notation, we write the following\PullLS*[2].
    $$L = \left\{ t \begin{bmatrix} 2 \\ 3 \\ 4 \end{bmatrix} + \begin{bmatrix} 1 \\ 2 \\ 3 \end{bmatrix} \ | \ t \in \mathbb{R}\right\}$$ 

    \item Recall that by definition, a \MathCite{plane} in $\mathbb{R}^3$ is given by $P = \{s\vec d_1 + t\vec d_2 + \vec p \ | \ s,t \in \mathbb{R}\}$, where $\vec d_1, \vec d_2 \in \mathbb{R}^3$ are the two non-zero vectors that are not parallel, and $\vec p \in \mathbb{R}^3$ is the position vector of a point that lies on the plane. Since the point (0, 0, 0) must be in the plane $P$, we may fix $\vec p$ to be the zero vector $\vec 0$. \\ \\
    As for vectors $\vec d_1$ and $\vec d_2$, we can take the position vectors of the points $(1, 3, 4)$ and $(1, 1, 1)$ as they are not scalar multiples of each other (this is needed to form a plane). Thus, the plane $P$ can be describe by the following set\PullLS*[2].
    $$P = \left\{s \begin{bmatrix} 1 \\ 3 \\ 4 \end{bmatrix} + t \begin{bmatrix} 1 \\ 1 \\ 1 \end{bmatrix} \ | \ s,t \in\mathbb{R}\right\}.$$
    Note that choosing $t=0, s=1$ and $t=1, s=0$ gives us the desired points. 
\end{enumerate}
\end{SaveQuestion}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{SaveQuestion}[
        key=ch0-sets-studentgrade-dev, 
		prompt={In this course, we will frequently use the terms \textbf{definition}, \textbf{theorem}, \textbf{justification}, \textbf{counterexample} and occasionally the term \textbf{proof}. A \textbf{definition} is a statement that assigns meaning to a particular word for the first time. A \textbf{theorem} is a mathematical statement that is proved to hold true. A \textbf{justification} is a series of logical statements that are either based on definitions of previously proven theorems or axioms and that justify the truth value of a statement. Sometimes a justification entails a description of an example or a scenario that shows a statement is false. We call such an example a \textbf{counterexample}. A \textbf{proof} is a precisely written justification using accurate mathematical language.\\This problem demonstrates the meaning of these terms. \\ \\
	The \emph{Law of Parental Support} says: If you get a ``B'' or better in MAT188, your parents will buy you a new car.  Let us accept this as a (true) axiom! Take the following definitions of the underlined terms
	\begin{itemize}
		\item  A student is called	an \underline{A student}  if they never get a grade lower than ``A-'' in a given semester.
		\item  A student is called	a \underline{B student} if they get at most one grade lower than a ``B'' in a given	semester.
	\item  A student is called a \underline{C student} if they get no grade higher than ``C'' in a given semester.
	\end{itemize}
	\medskip
	\noindent
	\begin{enumerate}
		\item 	Discuss with your group whether the following statements hold or not. For each statement write a justification, in full sentences, that uses the definitions above and the law of parental support. \\
		a) If I am an ``A'' student, I will get a new car from my
		parents at the end of the semester.\\
		b) If I am a ``B'' student, I will get a new car from my
		parents at the end of the semester. \\
		c) If I am a ``C'' student, I will not get a new car from my
		parents at the end of the semester.
        \item Did you use any counterexample in the justifications you gave above?
	\item Consider set $L=\{\text{ Marina, Selin,  Saba, Noor, Sazia, Subat, Camelia}\}$. Every student in the set $L$ takes at least two courses every semester. Suppose Marina, Selin and Saba never get a grade lower that $A-$, Noor, Sazia, and Subat get at most one grade lower than $B$ and Camelia has no grade higher than $C$ in a given semester. List the elements of the following sets. Use proper set notation.
	\begin{enumerate}
		\item $M=\{x\in L\:|\: x \text{ is a B student}\}$
		\item $S=\{x\in M\:|\: x \text{ is an A student}\}$
		\item $K=\{x\in L\:|\: x \text{ is a C student}\}$
		\item $K\cap S$
		\item $K\cup M$
	\end{enumerate}
\end{enumerate}
  }][ch0-WRIT-sets,chg-WRIT-matnot]
  [Satisfactory: if the sets are correct and the notation used is correct*Can be Improved: if there are any mistakes including true/false errors or notation mistakes with the sets*Try Again: if there are too many mistakes or the sets for part 3 are wrong*Make sure to leave comments everywhere the submission can improve*]
    \begin{enumerate}
    \item
    a) True. If I am an $A$ student, then by definition of an A student, I will not get any grade lower than A- in any class. In particular, my 188 grade is A- or better, which is at least B. So by the law of parental support, they will buy me a car.
    b) False. As a \textbf{counterexample}, perhaps I get an F in MAT188 and an A in everything else. By definition of B student, I am a B student, since only one grade is below B. So, there is no obligation for my parents to buy me a car, as I did not get at least B in MAT188. 
    c). False. The axiom of parental support only says what my parents will do if I get a B or higher in MAT188. It tells us nothing about what happens if I get any other grade.
    \item Yes, in (b)
    \item
    \begin{enumerate}
    \item $M=\{x\in L\:|\: x \text{ is a B student}\}=\{Marina, Selin, Saba, Noor, Sazia, Subat \}$
    \item$ S=\{x\in M\:|\: x \text{ is an A student}\}=\{Marina, Selin, Saba\}$
    \item $K=\{x\in L\:|\: x \text{ is a C student}\}=\{Camelia \}$
    \item $K\cap S=\{\}$
    \item $K\cup M=L$
    \end{enumerate}
    \end{enumerate}
\end{SaveQuestion}




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{SaveQuestion}[
        key=ch0-vecarith-colinear-sbg,
        prompt={Determine whether or not the following points are co-linear, provide a drawing to support your answer: 
    $$J = [2,6,2], K = [-1,3,0], L = [8,1,-2]$$}
][ch0-VG-line] %this is written as a comma seperated list with no spaces between commas
    [Correct that they are not colinear*Drawing included, with labelling*]    %this is written as a comma seperated list with no spaces between commas
    If we find the equation for the line passing through any of the two points, we can then check to see if the third point lies on that line. Choosing points $J$ and $K$, to find the direction vector we get:
    $$\vec d = [2-(-1), 6-3, 2-0] = [3,3,2]$$
    Now the vector equation of the line is:
    $$l = [2,6,2] +t[3,3,2]  | t \in \bbR$$
    To test if $L$ lies on this line we set the equation equal to L:
    $$[8,1,-2] = [2,6,2] +t[3,3,2] \\ 2 + 3t = 8 \to t = 2 \\ 6 + 3t = 1 \to t = \frac{-5}{3} \\ 2+2t = -2 \to t = -2$$
    Since the t values do not line up, we know $L$ does not lie on this line and therefore the points are not colinear. 
\end{SaveQuestion}





%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{SaveQuestion}[
        key=ch0-vecarith-vectooparform-exa,
        prompt={The vector form and the parametric form of a line are closely connected. To write the vector from (also called vector-parametric form), we identify each point of the line with its position vector. Then we describe an arbitrary such vector. In parametric form, we describe each component of an arbitrary point on the line separately.\\ For example given the vector from of the line
$$\begin{bmatrix}
    x\\y
\end{bmatrix}=\begin{bmatrix}
    10\\6
\end{bmatrix}+t\begin{bmatrix}
    13\\1
\end{bmatrix}\quad \text{where}\quad  t \in \bbR$$
  in $\mathbb{R}^2$, we can write the parametric form as  \\
 $l: \begin{cases} 
      x=10+13t \\
      y=6+t 
\end{cases}\quad \text{where} \quad t \in \bbR.$\\
Alternatively, given the parametric from of the line 
  $$l: \begin{cases} 
      x=1+4t \\
      y=-6+t \\
      z=2-2t 
\end{cases} \quad t \in \bbR$$
        in $\mathbb{R}^3$, we can write its vector form as follows:
 $$\begin{bmatrix}
     x\\y\\z
 \end{bmatrix}=\begin{bmatrix}
     1\\-6\\2
 \end{bmatrix}+t\begin{bmatrix}4\\1\\-2\end{bmatrix} \quad  t\in \bbR
 $$    }   
][ch0-CON-parline] %this is written as a comma seperated list with no spaces between commas
    [correct equations*]    %this is written as a comma seperated list with no spaces between commas
    \begin{enumerate}
        \item $l: \begin{cases} 
      x=10+13t \\
      y=6+t 
        \end{cases} t \in \bbR$
        \item $l: \begin{cases} 
      x=3+6t \\
      y=-9t \\
      z=-1+t 
        \end{cases} t \in \bbR$
    \end{enumerate}
\end{SaveQuestion}





%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{SaveQuestion}[
        key=ch0-vecarith-vecandparaform-sbg,
        prompt={Given the points $A(3,4,-5)$ and $B(9,-2,7)$, write a vector form and the parametric form of the line through $A$ and $B$.}
][ch0-CON-vecline,ch0-CON-parline]
    [correct vector form equation*,correct parametric form*]
    We may use the points $A$ and $B$ to obtain the direction vector $\vec d = \begin{bmatrix} 9-3 \\ -2-4 \\ 7-(-5) \end{bmatrix} = \begin{bmatrix} 6 \\ -6 \\ 12 \end{bmatrix}$. \\ \\
    Vector Form:
    $\begin{bmatrix} x \\ y \\ z \end{bmatrix} = \begin{bmatrix} 3 \\ 4 \\ -5 \end{bmatrix} + t \begin{bmatrix} 6 \\ -6 \\ 12 \end{bmatrix}, t\in \bbR$.
    Parametric Form:
    $l: 
    \begin{cases} 
      x=3+6t \\
      y=4-6t \\
      z=-5+12t 
    \end{cases}, t \in \bbR$
\end{SaveQuestion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{SaveQuestion}[
        key=ch0-vecarith-parallelines-exa,
        prompt={Consider the following two lines in $\mathbb{R}^2$.
        $$\ell_1: \begin{cases} x = 3-2t \\ y = 4+t \end{cases} \quad \ell_2: 2x+4y-7=0$$
        Suppose we want to determine whether the line $\ell_1, \ell_2$ are parallel, perpendicular, or neither. First, we will find the vector form of both lines, so that we may use their direction vectors to verify the claim. 
        For $\ell_1$, we fix $\vec d_1$ to be the direction vector.
        $$\begin{bmatrix} x \\ y \end{bmatrix} = \begin{bmatrix} 3 - 2t \\ 4 + t \end{bmatrix} = \begin{bmatrix} 3 \\ 4 \end{bmatrix} + t \begin{bmatrix} -2 \\ 1 \end{bmatrix} \Longrightarrow \vec d_1 = \begin{bmatrix} -2 \\ 1 \end{bmatrix}$$
        For $\ell_2$, let $\vec d_2$ be the direction vector.
        $$\begin{bmatrix} 2 \\ 4 \end{bmatrix} \cdot \vec d_2 = 0 \Longrightarrow \vec d_2 = \begin{bmatrix} -2 \\ 1 \end{bmatrix}$$
        Since $\vec d_1, \vec d_2$ are scalar multiples of each other, the two lines $\ell_1, \ell_2$ must be parallel.}
][ch0-VG-line]
    % [Correct answer of parallel with a labelled drawing*,Correct reasoning for the lines being parallel*Correct reasoning for their wrong answer*]    
    % $l_1$ has a direction vector of $[-2,1]$ which we can see from the parametric form.
    % To find the direction vector of $l_2$, rearrange the equation and plug in values for $x$ to find 2 separate points on the line.
    % $$2x+4y=7$$ $$y = \frac{7-2x}{4}$$
    % choose $x = 0$ and $x=2$ to get the points $(0,\frac{7}{4})$ and $(2,\frac{3}{4})$. Use these points to get the direction vector $\vec d = [0-2,\frac{7}{4} - \frac{3}{4}] = [-2,1]$
    % Since they have the same direction vector $[-2,1]$ this means that the two lines are parallel.
    % \begin{center}
    %     \includegraphics[scale=0.5]{Question Photos/ch0-vecarith-parallelines-sbg.jpg}
    % \end{center}
\end{SaveQuestion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{SaveQuestion}[
        key=ch0-vecarith-vecform4-sbg,
        prompt={Determine a vector form for each line.
    \begin{enumerate}
        \item Perpendicular to the line $4x-3y=17$ and through the point $P(-2,4)$
        \item Parallel to the $z$-axis and through point $P(1,5,10)$
        \item Parallel to $[x,y,z]=[3,3,0]+t[3,-5,-9]$ with $x$-intercept of -10
        \item With the same $x$-intercept as $[x,y,z] = [3,0,0]+t[4,-4,1]$ and the same $z$-intercept as $[x,y,z]=[6,-2,-3]+t[3,-1,-2]$
    \end{enumerate}}
][chg-WRIT-matnot,ch0-CON-vecline] %this is written as a comma seperated list with no spaces between commas
    [All are in vector form with no formatting or notation mistakes*,3 correct final answers*]    %this is written as a comma seperated list with no spaces between commas
    \begin{enumerate}
        \item $4x - 3y = 17 \to y = \frac{17-4x}{-3}$ so 2 points on the line are $(2,-3)$ and $(5,1)$, leaving a direction vector of $[2-5,-3-1] = [-3,-4]$. Since we want to be perpendicular the direction vector of our line is $[4,-3]$. The final vector form is
        $$\begin{bmatrix} x \\ y \end{bmatrix} = \begin{bmatrix} -2 \\ 4 \end{bmatrix} + t \begin{bmatrix} 4 \\ -3 \end{bmatrix}, \text{ where } t \in \bbR$$
        \item $\vec d = [0,0,1]$ therefore $[x,y,z] = [1,5,10]+t[0,0,1] | t \in \bbR$
        \item $[x,y,z] = [-10,0,0] + t[3,-5,-9] | t \in \bbR$
        \item $x$ intercept $[3,0,0]$ and $z$ intercept $[0,0,1]$ so we can find a direction vector of $\vec d = [3,0,-1]$ giving a vector form of $[x,y,z] = [3,0,0] + t[3,0,-1] | t \in \bbR$
    \end{enumerate}
\end{SaveQuestion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{SaveQuestion}[
        key=ch0-vecarith-drawplane-exa,
        prompt={We want to describe a plane that passes through the point $P(1,2,0)$ and that has the following normal vector. 
        $$\vec n = \begin{bmatrix} 4 \\ 3 \\ -5 \end{bmatrix}$$
        Generally, we have that a plane can be written as $n_1 x + n_2 y + n_3 z = c$, where $n_1, n_2, n_3$ are the respective entries of $\vec n$, and $c \in \mathbb{R}$ is a constant. Thus, we first replace $n_1, n_2, n_3$ with the entries given by the selected normal vector $\vec n$. This yields $4x + 3y - 5z = c$. Since the point $P(1,2,0)$ is on the plane, we must have $4(1) + 3(2) - 5(0) = c \Longrightarrow 10 = c$. \\ \\
        Consequently, the plane that passes through the point $P(1,2,0)$ and that has a normal vector $\vec n = \begin{bmatrix} 4 \\ 3 \\ -5 \end{bmatrix}$ can be described as the set of solutions to $4x + 3y - 5z = 10$.}
][ch0-CON-plane] %this is written as a comma seperated list with no spaces between commas
    [Correct answer*Drawing with labelling and normal vector is perpendicular to the plane*]    %this is written as a comma seperated list with no spaces between commas
    The point does lie on the plane. Drawing.
\end{SaveQuestion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{SaveQuestion}[
        key=ch0-vecarith-planeint-sbg,
        prompt={Find the x, y, and z-intercepts of each plane. Use that information to draw them.
    \begin{enumerate}
        \item $4x+2y-7z+14=0$
        \item $3x+6z+18=0$
    \end{enumerate}}
][ch0-VG-plane] %this is written as a comma seperated list with no spaces between commas
    [correct answer and labelled drawing]    %this is written as a comma seperated list with no spaces between commas
    \begin{enumerate}
        \item $x=-3.5, y=-7, z=2$ and a drawing
        \item $x=-6, y=undefined, z=-3$ and a drawing
    \end{enumerate}
\end{SaveQuestion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{SaveQuestion}[
        key=ch0-vecarith-paraplane-sbg,
        prompt={Write the parametric form of the plane $[x,y,z]=[0,-4,1]+s[1,10,-1]+t[0,3,4]$ and draw it.}
][ch0-VG-plane] %this is written as a comma seperated list with no spaces between commas
    [labelled drawing*]    %this is written as a comma seperated list with no spaces between commas
    $l: \begin{cases} 
      x=s \\
      y=-4+10s+3t \\
      z=1-s+4t 
        \end{cases} s,t \in \bbR$
\end{SaveQuestion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{SaveQuestion}[
        key=ch0-vecarith-vecplane-sbg,
        prompt={Write the vector form of the plane using the normal equation $\pi: 2x + 3y + 5z = -10$ and draw the plane.}
][ch0-VG-plane] %this is written as a comma seperated list with no spaces between commas
    [labelled drawing*]    %this is written as a comma seperated list with no spaces between commas
    $[x,y,z] = [2,0,11] + s[1,12,6] + t[7,-8,0] | s,t \in \bbR UPDATE SOLUTION$
\end{SaveQuestion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{SaveQuestion}[
        key=ch0-vecarith-pointonplanedrawing-sbg,
        prompt={Determine if the point $P(-4,-13,10)$ is on the plane $[x,y,z] = [6,-7,10]+s[1,3,-1]+t[2,-2,1]$ and draw it.}
][ch0-VG-plane] %this is written as a comma seperated list with no spaces between commas
    [labelled drawing*]    %this is written as a comma seperated list with no spaces between commas
    $[-4,-13,10] = [6,-7,10] + s[1,3,-1] + t[2,-2,2] $ 
    $ -4 = 6 + s + 2t \\ s = -2t -10$
    $-13 = -7 +3s -2t \\ -6 = 3(-2t -10) -2t \\ -6 = -8t -30 \\ 24 = -8t \\ t = -3$
    $s = -2(-3) -10 = -4$
    $10 = 10 - (-4) + (-3) \\ 10 = 10 + 4 - 3 \\ 10 = 11$ since this is a false statement this shows that $P$ does not lie on the plane. Drawing.
\end{SaveQuestion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{SaveQuestion}[
        key=ch0-subsets-drawing-dev,
        prompt={Draw the following subsets of $\bbR^2$: 
        \begin{enumerate}
            \item $V = \left\{ \vec x \in \bbR^2 : \vec x = \begin{bmatrix}
                0 \\ t
            \end{bmatrix} \text{ for some } t \in \bbR \right\} $
            \item $H = \left\{ \vec x \in \bbR^2 : \vec x = \begin{bmatrix}
                t \\ 0
            \end{bmatrix} \text{ for some } t \in \bbR \right\} $
            \item $D = \left\{ \vec x \in \bbR^2 : \vec x = t \begin{bmatrix}
                1 \\ 1
            \end{bmatrix} \text{ for some } t \in \bbR \right\} $
            \item $V \cup H$
            \item $V \cap H$
            \item Does $V \cup H = \bbR^2$?
        \end{enumerate}
        }
][ch0-VG-line] %this is written as a comma seperated list with no spaces between commas
    [<rubric items>]    %this is written as a comma seperated list with no spaces between commas
    Drawings
\end{SaveQuestion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{SaveQuestion}[
        key=ch0-vecarith-vectorform5-sbg,
        prompt={Express the following lines in vector form. \begin{enumerate}
            \item $l_1 \subseteq \bbR^2$ with equation $4x-3y=-10$.
            \item $l_2 \subseteq \bbR^2$ which passes through the points $A = (1,1)$ and $B=(2,7)$.
            \item $l_3 \subseteq \bbR^2$ which passes through $\vec 0$ and is parallel to the line with equation $4x-3y=-10$.
            \item $l_4 \subseteq \bbR^3$ which passes through the points $A = (-1,-1,0)$ and $B=(2,3,5)$.
            \item $l_5 \subseteq \bbR^3$ which is contained in the $yz$-plane and where the coordinates of every point in $l_5$ satisfy $x+2y-3z=5$.
        \end{enumerate}
        }
][ch0-CON-vecline] %this is written as a comma seperated list with no spaces between commas
    [<rubric items>]    %this is written as a comma seperated list with no spaces between commas
    <question solution>
\end{SaveQuestion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{SaveQuestion}[
        key=ch0-vecarith-collidinglines-dev,
        prompt={Let $l_1, l_2,$ and $l_3 \subset\mathbb{R}^3$ be described in vector form by the following.
        $$l_1 = \left\{t_1 \begin{bmatrix} 1 \\ 1 \\ 0\end{bmatrix} + \begin{bmatrix} 1 \\ 3 \\ 1 \end{bmatrix} \ | \ t_1 \in \mathbb{R}\right\}$$ 
        $$l_2 = \left\{t_2 \begin{bmatrix} 2 \\ 0 \\ 3 \end{bmatrix} + \begin{bmatrix} -1 \\ 1 \\ 1 \end{bmatrix} \ | \ t_2 \in \mathbb{R}\right\}$$
        $$l_3 = \left\{t_3 \begin{bmatrix} 2 \\ 2 \\ 0 \end{bmatrix} + \begin{bmatrix}  2 \\ 4 \\ 0 \end{bmatrix} \ | \ t_3 \in \mathbb{R}\right\}$$
        \begin{enumerate}
            \item[] \textbf{(Reflect)} In $\mathbb{R}^3$ how can two lines intersect? Generally, how many different ways can two lines be related? 
            \item Determine which pairs of the lines $l_1$, $l_2$, and $l_3$ intersect, coincide, and/or are parallel.
            \item What is $l_1 \cap l_2 \cap l_3$?
         \end{enumerate}
        }
][ch0-VG-line]
    [Satisfactory: Hint provided by the TA was used effectively and is manifest in the solution *Can be improved: Solution may be correct, but does not employ techniques or display a skill-set indicative of MAT188 material *Try Again: No attempt was made, or, solution is wholly incorrect with no relation to the original question*] 
    In $\mathbb{R}^3$, similarly to $\mathbb{R}^2$, lines that intersect either intersect at a singular point or coincide. In $\mathbb{R}^2$, two lines not intersecting implies that the lines are parallel, however, in $\mathbb{R}^3$ non intersecting lines can either be parallel or skew lines. Thus, there exists four distinct relationships between two lines in $\mathbb{R}^3$. 
    \begin{enumerate}
        \item First, we notice that the direction vectors of $l_1$ and $l_2$ are not scalar multiples of each other. Thus, $l_1$ and $l_2$ cannot be \MathCite{parallel} or coincide. However, these line do intersect at the point (-1, 1, 1).
        $$-2 \begin{bmatrix} 1 \\ 1 \\ 0\end{bmatrix} + \begin{bmatrix} 1 \\ 3 \\ 1 \end{bmatrix} = \begin{bmatrix} -1 \\ 1 \\ 1 \end{bmatrix} = 0\begin{bmatrix} 2 \\ 0 \\ 3 \end{bmatrix} + \begin{bmatrix} -1 \\ 1 \\ 1 \end{bmatrix}$$

        Notice that if the direction vectors of two lines are scalar multiples of each other, they are \MathCite{parallel}. Moreover, the direction vectors of $l_1$ and $l_3$ are indeed scalar multiples of each other.
        $$2 \begin{bmatrix} 1 \\ 1 \\ 0 \end{bmatrix} = \begin{bmatrix} 2 \\ 2 \\ 0 \end{bmatrix}$$
        We can further show that there are no intersections between $l_1$ and $l_3$ to confirm that they do not coincide. 
        $$t_1 \begin{bmatrix} 1 \\ 1 \\ 0\end{bmatrix} + \begin{bmatrix} 1 \\ 3 \\ 1 \end{bmatrix} = t_3 \begin{bmatrix} 2 \\ 2 \\ 0 \end{bmatrix} + \begin{bmatrix}  2 \\ 4 \\ 0 \end{bmatrix} \Longrightarrow \begin{bmatrix} t_1 - 2t_3 \\ t_1 - 2t_3 \\ 0 \end{bmatrix} = \begin{bmatrix} 1 \\ 1 \\ -1 \end{bmatrix}$$
        Looking at the last entries of the equation above, notice that there is a contradiction as $0 \neq -1$. Thus, $l_1$ and $l_3$ do not coincide and are just parallel.

        First, we notice that the direction vectors of $l_2$ and $l_3$ are not scalar multiples of each other. Thus, $l_2$ and $l_3$ cannot be \MathCite{parallel} or coincide. In fact, the lines do not intersect as they are skew lines. We can further show that there are no intersections between $l_2$ and $l_3$ to confirm that they are skew lines. 
        $$t_2 \begin{bmatrix} 2 \\ 0 \\ 3 \end{bmatrix} + \begin{bmatrix} -1 \\ 1 \\ 1 \end{bmatrix} = t_3 \begin{bmatrix} 2 \\ 2 \\ 0 \end{bmatrix} + \begin{bmatrix}  2 \\ 4 \\ 0 \end{bmatrix} \Longrightarrow \begin{bmatrix} 2t_2 - 2t_3 \\ -2t_3 \\ 3t_2 \end{bmatrix} = \begin{bmatrix} 3 \\ 3 \\ -1 \end{bmatrix} \Longrightarrow t_2 = -\frac{1}{3}, t_3 = -\frac{3}{2} \Longrightarrow 2t_2 - 2t_3 = -\frac{2}{3} + 3 = \frac{7}{3} \neq 3$$
        Consequently, the line $l_2$ and $l_3$ do not intersect. Visualizations \href{https://www.geogebra.org/3d/acpywquf}{\textbf{here}}.
        
        Thus, the $l_1$ and $l_2$ pair intersect, no pairs coincide, and the $l_1$ and $l_3$ pair are parallel. 
        \item Notice that for any two non-coinciding parallel lines, their intersection must be the empty set (try and picture why this would be the case). This implies that $l_1 \cap l_3 = \emptyset$ Moreover, the set $l_1 \cap l_2$ must be a subset of (or equal to) $l_1$. Therefore, we have the following.
        $$l_1 \cap l_2 \subseteq l_1 \Longrightarrow l_1 \cap l_2 \cap l_3 \subseteq l_1 \cap l_3 = \emptyset$$
        Since $l_1 \cap l_2 \cap l_3$ is a subset (or equal to) the empty set, it must be that $l_1 \cap l_2 \cap l_3$ is also the empty set. 

        Thus, we have $l_1 \cap l_2 \cap l_3 = \emptyset$. Visualizations \href{https://www.geogebra.org/3d/acpywquf}{\textbf{here}}.
    \end{enumerate}
    \begin{center}
        \includegraphics[width=0.75\textwidth]{Question Photos/MAT188F2024TUT1Q4.png}
    \end{center}
\end{SaveQuestion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{SaveQuestion}[
        key=<question key>,
        prompt={Let L be the set of points $(x,y) \in \bbR^2$ such that $y = 2x+1$. 
        \begin{enumerate}
            \item Describe $L$ using set-builder notation.
            \item Draw $L$ as a subset of $\bbR^2$.
            \item Add the vectors $\vec a \begin{bmatrix}
                -1 \\ -1
            \end{bmatrix}, \begin{bmatrix}
                1 \\ 3
            \end{bmatrix}$ and $\vec d = \vec b - \vec a$ to your drawing.
            \item Is $\vec d \in L$? Explain.
            \item For which $t \in \bbR$ is it true that $\vec a + t \vec d \in L$? Explain using your picture.
        \end{enumerate}
}
][ch0-VG-line] %this is written as a comma seperated list with no spaces between commas
    [<rubric items>]    %this is written as a comma seperated list with no spaces between commas
    <question solution>
\end{SaveQuestion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{SaveQuestion}[
        key=ch0-vecarith-uniquevecform-sbg,
        prompt={Let $l \subseteq \bbR^2$ be the line with equation $2x+y=3$, and let $L \subseteq \bbR^3$ be the line with equations $2x+y=3$ and $z=y$. 
        \begin{enumerate}
            \item Write $l$ in vector form. Is the vector form of $l$ unique?
            \item Write $L$ in vector form.
            \item Find another vector form for $L$ where both "$\vec d$" and "$\vec p$" are different from before. 
        \end{enumerate}
        }
][ch0-CON-vecline] %this is written as a comma seperated list with no spaces between commas
    [<rubric items>]    %this is written as a comma seperated list with no spaces between commas
    <question solution>
\end{SaveQuestion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\begin{SaveQuestion}[
        %key=<question key>,
        %prompt={<question>}
%][<learning standards>] %this is written as a comma seperated list with no spaces between commas
    %[<rubric items>]    %this is written as a comma seperated list with no spaces between commas
    %<question solution>
%\end{SaveQuestion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{SaveQuestion}[
        key=ch0-generalsol-vislineq-sbg,
        prompt={Consider the linear equation $2x - y + z = 0$. 
        \begin{enumerate}	
        \item By inspection find values for $x$, $y$ and $z$ that satisfy $2x - y + z = 0$. How many such values can you find?
        \item Consider the set $A$ of vectors (in standard position) in $\mathbb{R}^3$ that satisfy $2x - y + z = 0$, and the set $B$ of points satisfying $x + 3y + 4 z = 0$. More specifically, we have the following for $A,B \subseteq \mathbb{R}^3$.
        $$A=\left\{\begin{bmatrix} x \\ y \\ z \end{bmatrix} \in \mathbb{R}^3 \ | \ 2x - y + z = 0\right\} \ \ \ \ \ \ B = \left\{\begin{bmatrix} x \\ y \\ z  \end{bmatrix} \in \mathbb{R}^3 \ | \ x + 3y + 4 z = 0\right\}$$
            \begin{enumerate}
            \item What type of geometric objects are the sets  $A$ and $B$? Can you draw them?
            \item Is the origin $\begin{bmatrix} 0\\0\\0 \end{bmatrix}$ in either of $A$ or $B$? Interpret your answer geometrically.
            \item What type of  geometric object  is the  set $A \cap B$?
            \item Is the origin $\begin{bmatrix} 0\\0\\0 \end{bmatrix}$ in $A \cap B$?  Interpret your answer geometrically.
            \item Find the set of all points in $\mathbb{R}^3$ that satisfy the following linear equations (use any method).
            \begin{align*} 2x - y + z &= 0 \\ x + 3y + 4 z &= 0 \end{align*} 
            What does this have to do with your answer to (b)?
            \item Describe your answer to (c) as a line in vector form and in the parametric equation. Draw this line.
            \end{enumerate}
        \end{enumerate}}
 ][ch0-VG-plane]
    [Correct geometric and/or algebraic answer and reasoning for parts a and b*N.B. A drawing or sketch is encouraged, but not necessary to earn the learning standard*Justification should be concise, and have a combination of intuition and mathematical rigour*]
    \begin{enumerate}
        \item By inspection, $(0, 0, 0)$ and $(1,2,0)$ are couple of points. There are infinitely many points that satisfy this equation.
        \item \begin{enumerate}
	\item  They are planes\PullLS*[2]. See visualization \href{https://www.geogebra.org/3d/wvme9jbr}{\textbf{here}}. 
	\item Yes, this point is on both of the planes, which means both these planes pass through the origin\PullLS*[2]. 
        $$2(0) - (0) + (0) = 0 \Longrightarrow \vec 0 \in A \ \ \ \ \ \ (0) + 3(0) + 4(0) \Longrightarrow \vec 0 \in B$$
        \item A line through the origin. Note that for any two planes $P_1, P_2 \subset \mathbb{R}^3$, $P_1 \cap P_2$ is either a plane, a line, or the empty set. The intersection of two planes is a plane if and only if $P_1 = P_2$. This is not the case (use the fact that the norms are not scalar multiples of each other, or find a point unique to each set). Since both $A$ and $B$ contain the origin their intersection cannot be the empty set. Thus, $A \cap B$ forms a line\PullLS*[1]. 
	\item Yes, the origin is in both sets, hence in the intersection. The intersection is a line going through the origin\PullLS*[1].
        \item We have \begin{eqnarray*} 2x-y+z&=&0\\ x+3y+4z&=&0 \end{eqnarray*}
        Multiplying the second equation by $2$ and then subtracting this from the first equation we get $(2x - y + z) - 2(x + 3y + 4z) \Longrightarrow y = -z$.
	Plugging this result into the first equation we get $x=y, x=-z$. 
        If $x$ takes an arbitrary value $t$, then the solution set is given by the following.  
        $$\left\{\begin{bmatrix} t \\ t \\ -t \end{bmatrix} \ | \ t\in \mathbb{R}\right\}=\left\{t\begin{bmatrix} 1 \\ 1 \\ -1 \end{bmatrix} \ | \ t\in \mathbb{R}\right\}$$ 
        In relationship to part (b), we see that the origin is this set since it satisfies the equation that constrains both $A$ and $B$. \\ \\
        This set of vectors makes a line in $\mathbb{R}^3$\PullLS*[3]. 
        \item Vector form: $t\begin{bmatrix} 1\\1\\-1 \end{bmatrix}$, where $t\in \mathbb{R}$. \\ \\
        Parametric form: \begin{eqnarray*} x&=&t\\y&=&t\\z&=&-t \end{eqnarray*} where $t\in \mathbb{R}$. \\ \\
        Visualization \href{https://www.geogebra.org/3d/kz5chu46}{\textbf{here}}\PullLS*[3].
        \end{enumerate}
    \end{enumerate}
    \begin{center}
        \includegraphics[width=0.75\textwidth]{Question Photos/MAT188F2024TUT1Q3b.png}
    \end{center}
\end{SaveQuestion}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{SaveQuestion}[
        key=ch1-generalsol-lineq4var-sbg,
        prompt={Consider the following system of linear equations in four variables $x_1, x_2, x_3,x_4$: 
        \begin{align*} 
            x_1 + 3x_2 - x_3 + 2x_4 & = 5 \\ 2x_1 + 6x_2 - x_3 - x_4 &= 6 
        \end{align*}
        \begin{enumerate}
            \item Suppose $\vec c = \begin{pmatrix} c_1 \\ c_2 \\ c_3 \\ c_4 \end{pmatrix} \in \mathbb{R}^4$ is a solution to this system. Find a matrix $A$ and a vector $\vec b$ such that $A\vec c = \vec b$.
            \item The augmented matrix of this system of linear equations after some row reductions results in the matrix $$\begin{amatrix}{4} 1 & 3 & 0 & -3 & 1 \\ 0 & 0 & 1 & -5 & -4\end{amatrix}$$ Is this matrix in RREF? Justify your answer.
            \item Write a system of linear equations corresponding to the matrix given in (2).
            \item Can you tell what the solution type of this system is without any further computation? What is it?
            \item Which variables are free and which are dependent (or basic)? Write the general solution by solving for dependent variables in terms of free variables.
            \item Write your solution set in vector-parametric form using set builder notation. What does your solution set represent geometrically in $\bbR^4$?
            \item Can we write $\vec b$ from (1) as a linear combination of columns from $A$? How? Give an example. 
        \end{enumerate}
}][ch1-WRIT-gslinsys,ch1-COM-pslinsys] %this is written as a comma seperated list with no spaces between commas
    [Solution must feature the correct vector-parametric form notation.*The correct free variables must be used (preferably using the same variable naming conventions as in the question).*The free variables (in the set-builder notation) must be stipulated (with the correct notation and no quantifiers) as being elements in the reals*,Explicitly makes a choice of values for the free variables and substitutes them in the vector-parametric form to arrive at a particular vector in the solution set.*Writes the linear combination using the vector's entries as coefficients in the correct order.*The sum of vectors is NOT evaluated.*]  
    \begin{enumerate}
        \item First, we note that the system includes 2 equations and 4 variables. Consequently, we know that the matrix $A$ should be a $2 \times 4$ matrix. Finding the matrix $A$ is as simple as extracting the coefficients from the equations within the system.
        $$\begin{matrix} ax_1 + bx_2 + cx_3 + dx_4 \\ ex_1 + fx_2 + g_3 + hx_4 \end{matrix} \longrightarrow \begin{bmatrix} a & b & c & d \\ e & f & g & h \end{bmatrix}$$
        In this case, we see that the first equation has coefficients 1, 3, -1, and 2, whereas the second equation has coefficients 2, 6, -1, and -1. Thus, we obtain the following matrix $A$.
        $$A := \begin{bmatrix} 1 & 3 & -1 & 2 \\ 2 & 6 & -1 & -1 \end{bmatrix}$$
        Since $\vec c$ is a solution to the system, we know that $c_1 + 3c_2 - c_3 + 2c_4 = 5, 2c_1 + 6c_2 - c_3 - c_4 = 6$. Thus, we take $\vec b$ to be the constant terms in both equations, respectively.
        $$\vec b := \begin{bmatrix} 5 \\ 6 \end{bmatrix}$$
        Briefly, we verify that indeed, $A\vec c = \vec b$
        $$A\vec c = \begin{bmatrix} 1 & 3 & -1 & 2 \\ 2 & 6 & -1 & -1 \end{bmatrix} \begin{bmatrix} c_1 \\ c_2 \\ c_3 \\ c_4 \end{bmatrix} = \begin{bmatrix} c_1 + 3c_2 - c_3 + 2c_4 \\ 2c_1 + 6c_2 - c_3 - c_4 \end{bmatrix} = \begin{bmatrix} 5 \\ 6 \end{bmatrix} = \vec b$$
        
        \item Yes, the matrix is indeed in REF form since all of the leading entries are 1.
        $$
        \begin{tikzpicture}
        \draw (0,0) node{$\begin{bmatrix} 1 & 3 & 0 & -3 \\ 0 & 0 & 1 & -5\end{bmatrix}$};
        \draw[red] (-0.9,0.20) circle (6pt);
        \draw[red] (0.1,-0.20) circle (6pt);
        \end{tikzpicture}
        $$
        \item To write the system of linear equations corresponding to the matrix, we must extract the coefficients of the matrix. Note that the first row corresponds to the coefficients of the first equation, and the second row corresponds to the coefficients of the second equation. As this is an augmented matrix, the coefficients on the left of the vertical bar correspond to the scalars of the variables, and the coefficients on the right of the vertical bar correspond to constant terms. Thus, we know that the first equation should equal 1 and the second equation should equal -4. 
        $$\begin{matrix} 1x_1 & +3x_2 & +0x_3 & -3x_4 & = 1 \ \ \ \  \\ 0x_1 & + 0x_2 & +1x_3 & -5x_4 & = -4 \end{matrix} \ \Longrightarrow \ \begin{matrix} x_1 + 3x_2 - 3x_4 & = 1 \ \ \ \  \\ x_3 - 5x_4 & = -4 \end{matrix}$$
        
        \item Recall that the three solution types are no solution, one solution, and infinitely many solutions. From the REF of the matrix $A$, we may deduce that this system has free variables, and thus, there must be infinitely many solutions. 
        
        \item Recall that basic variables are associated with pivot columns and free variables with non-pivot columns. Below, the pivot columns are circled in red and the non-pivot columns in blue. 
        $$
        \begin{tikzpicture}
        \draw (0,0) node{$\begin{bmatrix} 1 & 3 & 0 & -3 \\ 0 & 0 & 1 & -5\end{bmatrix}$};
        \draw[red] (-0.9,0) ellipse (0.2cm and 0.6cm);
        \draw[blue] (-0.4,0) ellipse (0.2cm and 0.6cm);
        \draw[red] (0.1,0) ellipse (0.2cm and 0.6cm);
        \draw[blue] (0.8,0) ellipse (0.2cm and 0.6cm);
        \end{tikzpicture}
        $$
        Since the first and third columns are pivots, the basic variables are $x_1$ and $x_3$. Conversely, the free variables are $x_2$ and $x_4$ as those columns are not pivots. Noting that $x_1$ and $x_3$ are dependent variables, we may rearrange each equation such that they depend on $x_2$ and $x_4$. 
        \begin{align*}
            x_3     &= 5x_4 - 4 \\
            x_1     &= -3x_2 + 3x_4 + 1
        \end{align*}
        
        \item From the previous part of this question, we know that if a vector $\vec x \in \mathbb{R}^4$, then $x_1 = -3x_2 + 3x_4 + 1, x_3 = 5x_4 - 4$. To find the solution set in vector parametric form, we must first substitute the equalities above for the first and third entry of $\vec x$, decompose the vector into groups of similar terms.
        $$\vec x = \begin{bmatrix} x_1 \\ x_2 \\ x_3 \\ x_4 \end{bmatrix} = \begin{bmatrix} -3x_2 + 3x_4 + 1 \\ x_2 \\ 5x_4 - 4 \\ x_4 \end{bmatrix} = \begin{bmatrix} -3x_2 \\ x_2 \\ 0 \\ 0 \end{bmatrix} + \begin{bmatrix} 3x_4 \\ 0 \\ 5x_4 \\ x_4 \end{bmatrix} + \begin{bmatrix} 1 \\ 0 \\ - 4 \\ 0 \end{bmatrix} = x_2 \begin{bmatrix} -3 \\ 1 \\ 0 \\ 0 \end{bmatrix} + x_4 \begin{bmatrix} 3 \\ 0 \\ 5 \\ 1 \end{bmatrix} + \begin{bmatrix} 1 \\ 0 \\ - 4 \\ 0 \end{bmatrix}$$
        Now that we have the general form of solutions, we define the following as the set of solutions to the system.
        $$\left\{\vec x \in \mathbb{R}^4 \ | \ \vec x = \begin{bmatrix} x_1 \\ x_2 \\ x_3 \\ x_4 \end{bmatrix} = x_2 \begin{bmatrix} -3 \\ 1 \\ 0 \\ 0 \end{bmatrix} + x_4 \begin{bmatrix} 3 \\ 0 \\ 5 \\ 1 \end{bmatrix} + \begin{bmatrix} 1 \\ 0 \\ -4 \\ 0 \end{bmatrix}\right\}$$
        
        \item To write $\vec b$ as a linear combination of columns from $A$, it is sufficient to find any solution to the system and use the entries as coefficients for the columns. 
        $$\begin{bmatrix} 5 \\ 6 \end{bmatrix} = \begin{bmatrix} 1 & 3 & -1 & 2 \\ 2 & 6 & -1 & -1 \end{bmatrix} \begin{bmatrix} x_1 \\ x_2 \\ x_3 \\ x_4 \end{bmatrix} = x_1 \begin{bmatrix} 1 \\ 2 \end{bmatrix} + x_2 \begin{bmatrix} 3 \\ 6 \end{bmatrix} + x_3 \begin{bmatrix} -1 \\ -1 \end{bmatrix} + x_4 \begin{bmatrix} 2 \\ -1 \end{bmatrix}$$
        For example, the vector $\begin{bmatrix} 1 \\ 1 \\ 1 \\ 1 \end{bmatrix}$ is a solution to the system. Thus, we have the following.
        $$\begin{bmatrix} 5 \\ 6 \end{bmatrix} = 1 \begin{bmatrix} 1 \\ 2 \end{bmatrix} + 1 \begin{bmatrix} 3 \\ 6 \end{bmatrix} + 1 \begin{bmatrix} -1 \\ -1 \end{bmatrix} + 1 \begin{bmatrix} 2 \\ -1 \end{bmatrix}$$
    \end{enumerate}
\end{SaveQuestion}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{SaveQuestion}[
        key=ch1-generalsol-linsystf1-sbg,
        prompt={The parts of this problem are independent of one another.
        \begin{enumerate}
            \item True or false? Justify your answer. \\ If $A = [\vec u, \vec v, \vec w]$ and $\rref(A) = \begin{bmatrix} 1 & 0 & 2 \\ 0 & 1 & 3 \\ 0 & 0 & 0 \end{bmatrix}$ then the equation $\vec w = 2\vec u + 3\vec v$ must hold. 
            \item True or false? Justify your answer. \\ The linear systems $A\vec x = \vec b$ is consistent exactly when $\rank(A) = \rank[A|\vec b]$.
        \end{enumerate}
}][chg-CON-tf] %this is written as a comma seperated list with no spaces between commas
    %[<rubric items>]    %this is written as a comma seperated list with no spaces between commas
    %[<items mark>]      %this is written as a comma seperated list with no spaces between commas

\end{SaveQuestion}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%       W.I.P.       %%%%%%%%%%%%%%%

\begin{SaveQuestion}[
        key=ch1-generalsol-linsysvis-sbg,
        prompt={Give a geometrical description of the set of all vectors of the form $a\vec v + b \vec w$, where $0 \leq a \leq 1$ and $0 \leq b \leq 1$ using $\vec v$ and $\vec w$ in the image below.
        \begin{center}
        \includegraphics[scale=0.75]{Question Photos/tut2vectors.png}
        \end{center}
}][ch1-VG-lincom,chg-CON-exp] %this is written as a comma seperated list with no spaces between commas
    %[<rubric items>]    %this is written as a comma seperated list with no spaces between commas
    %[<items mark>]      %this is written as a comma seperated list with no spaces between commas
 
\end{SaveQuestion}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%     W.I.P.     %%%%%%%%

\begin{SaveQuestion}[
        key=ch1-generalsol-linsys3soltype-sbg,
        prompt={Suppose we have a system of three linear equations in three unknowns: 
	 $$\begin{aligned} a x + b y + c z &= p\\ dx + ey + f z &= q \\ g x + h y + k z &= r,\end{aligned}$$ 
	 where $a, b, c, d, e, f, g, h, k,  p, q, r$ are all real numbers.
	 \begin{enumerate}
	 	\item Discuss with your group why we can think of the solution space as an intersection of three planes in $\mathbb{R}^3$.
	 	\item Find an explicit non-trivial example (values of the constants) in which the solution space is a plane.
	 	\item Find an explicit non-trivial example (values of the constants) in which the solution space is a line.
	 	\item Find an explicit non-trivial example (values of the constants) in which the solution space is a point.
	 	\item Find an explicit non-trivial example (values of the constants) so that the system is inconsistent (ie., has no solutions). 
	 	\item Are there values of the constants so that the solution space is a circle? A parabola? A union of two different lines? Place a bet on the shape of the solution space if you were to pick the constants at random.
	 \end{enumerate}
}][ch1-VG-gslinsys,chg-CON-exp] %this is written as a comma seperated list with no spaces between commas
    [Correct explanation for question 1*At least 3 correct examples for 2-5*,All 4 correct examples for 2-5*]    %this is written as a comma seperated list with no spaces between commas
    %[<items mark>]      %this is written as a comma seperated list with no spaces between commas
    %<question solution> 
    %%     MAKE BETTER       %%
    \begin{enumerate}
        \item Each equation represents a plane so the vectors satisfying all three equations is the set of (vectors) points on all three planes, or the intersection of the three planes. 
        \item One way to get a solution space which is a plane, is to make sure all the planes are the same. We can do this by making the equations be multiples of each other. For an explicit example:    
        $$\begin{aligned}  x +  y +  z &= 2\\
	 	2x + 2y + 2 z &= 4 \\
	 	3 x + 3 y + 3 z &= 6 \end{aligned}$$ 
        \item To make the solution space a line, we can take 2 equations which are not parallel/the same planes and which intersect in a line. Then adding a third equation which is some combination of the first 2 equations ensures the solution is a line. For example: 
	   $$\begin{aligned} 2x - y + z &= 0\\
	   x + 3y + 4 z &= 0 \\
	   3x + 2y + 5z &= 0
	   \end{aligned}$$
        \item The easiest way to get a point is to take, for example, $x + 0y + 0z = 0, 0x + y + 0z = 0 $ and $0x + 0 y + z = 0$. On the other hand, most choices of the constants will get a point as the solution space, since typically we expect three planes to intersect in a point. 
        \item One way to make the system inconsistent is to make two of the planes parallel but not coincident: For example
	 $$\begin{aligned}  x +  y +  z &= 2\\
	 x - y +  3 z &= 6 \\ 2x - y + z &= 0 \end{aligned}$$ 
	 is inconsistent since the first two planes don't intersect at all. 
        \item The solution space can never be a circle or two lines. It can only be a point, line or plane.
     \end{enumerate}
\end{SaveQuestion}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{SaveQuestion}[
        key=ch1-rref-nonsqmatrixex-sbg,
        prompt={Give an example of 
		\begin{enumerate}
			\item A $2\times 3$ matrix in REF form but not in RREF form.
			\item A $2\times 3$ matrix in RREF form.
			\item repeat the previous parts with a $4 \times 3$ matrix. 
			\item Compare your answers with your group mate. 
		\end{enumerate}
}][chg-CON-exp] %this is written as a comma seperated list with no spaces between commas
    %[<rubric items>]    %this is written as a comma seperated list with no spaces between commas
    %[<items mark>]      %this is written as a comma seperated list with no spaces between commas
    \begin{enumerate}
		\item $\begin{bmatrix}
			2&1&1\\0&0&4
		\end{bmatrix}$
		\item $\begin{bmatrix}
		1&1&0\\0&0&1
		\end{bmatrix}$
		\item REF but not RREF: $\begin{bmatrix}
		2&1&1\\0&2&4\\0&0&3\\0&0&0
		\end{bmatrix}$, RREF:$\begin{bmatrix}
		1&0&0\\0&1&0\\0&0&1\\0&0&0
		\end{bmatrix}$
	\end{enumerate}	
\end{SaveQuestion}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{SaveQuestion}[
        key=ch1-generalsol-linsystype1-sbg,
        prompt={Consider the following systems of equations: \\
	(a)
	$$
	\begin{array}{rcl}
	y & = & 2w+3z-8 \\
	x & = & w+z-4 \\
	y & = & 6w-6x+6z-24 \\
	w+z & = & 3
	\end{array}
        $$
	(b)
	$$
	3w+3x-5z \ = \ 3w+3x-3y \ = \ 6w+6x-6y-5z \ = \ w+x \ = \ 0
	$$
	(c)
	$$
	\begin{array}{ccccccc}
	-5x & \!\!+\!\! & 3y & \!\!+\!\! & 3z & = & -5 \\
	-7x & \!\!+\!\! & 4y & \!\!+\!\! & 4z & = & -5 \\
	-2x & \!\!+\!\! & y & \!\!+\!\! & z & = & 5 \\
	\end{array}
	$$
	\begin{enumerate}		
		\item For each of the linear systems in parts (a) through (c) above, rewrite the system in standard way by writing the variables in their natural order:  $w,x,y,z$.
		\item  Write the coefficient matrix and the augmented matrix of each linear system.
		\item Use technology to find the REF form of the augmented matrix of the linear systems from part I. Here is a great online tool to do \href{http://www.math.odu.edu/~bogacki/cgi-bin/lat.cgi?c=roc}{\textbf{row reduction}}.
		\item  What type of solution does each system have (you don't need the RREF to answer to this question)?
		\item Now continue your row reduction to get the RREF form of each matrix.  Write the general solution for each system.	
	\end{enumerate}
}][ch1-CON-augsoltype] %this is written as a comma seperated list with no spaces between commas
    [The solution correctly recognises the number of pivots and the number of free variables for each linear system.*The student uses the REF of the augmented matrix to deduce and justify a "no solution" case and/or an "infinitely many solutions" case.*Justification for the type of solution set for each system is provided.*]    
    \begin{enumerate}
        \item  This exercise is a simple matter of rearranging the given systems such that the variables correspond to their column-wise order.
        \begin{enumerate}
            \item[(a)] 
            $$\begin{array}{rcl}
        	y & = & 2w+3z-8 \\
        	x & = & w+z-4 \\
        	y & = & 6w-6x+6z-24 \\
        	w+z & = & 3
	   \end{array}
          \Longrightarrow 
        \begin{array}{ccccl}
             -2w & + 0x & -y & -3z &= 0  \\
             -w & + x & + 0y & -z &= -4 \\
             -6w & +6x & + y & -6z &= -24 \\
             w & + 0x & + 0y & + z &= 3
        \end{array}$$
        \item[(b)]
        $$3w+3x-5z \ = \ 3w+3x-3y \ = \ 6w+6x-6y-5z \ = \ w+x \ = \ 0
        \Longrightarrow
        \begin{array}{ccccl}
             3w & + 3x & + 0y & -5z &= 0  \\
             3w & + 3x &  -3y & + 0z &= 0 \\
             6w & +6x & -6y & -5z &= 0 \\
             w & + x & + 0y & + 0z &= 0
        \end{array}$$
        \item[(c)]
        $$\begin{array}{cccl}
    	-5x & + 3y & + 3z & = -5 \\
    	-7x & + 4y & + 4z & = -5 \\
    	-2x & + y & + z & = 5 \\
	\end{array}
        \Longrightarrow
        \begin{array}{ccccl}
    	0w & -5x & + 3y & + 3z & = -5 \\
    	0w & -7x & + 4y & + 4z & = -5 \\
    	0w & -2x & + y & + z & = 5 \\
	\end{array}$$
        \end{enumerate}
    \item To find the associated coefficient matrix and the augmented matrix of the linear systems, we will extract the coefficients from our rearranged equations in the previous part. To determine the coefficient, we consider the column of the variable and the row of the equation. We will use $M_a, M_b, M_c$ to represent the augmented matrix for systems (a), (b), and (c), respectively. 
    \begin{enumerate}
        \item[(a)] Recall that we derived the following for the rearranged equations.
        $$\begin{array}{ccccl}
             -2w & + 0x & -y & -3z &= 0  \\
             -w & + x & + 0y & -z &= -4 \\
             -6w & +6x & + y & -6z &= -24 \\
             w & + 0x & + 0y & + z &= 3
        \end{array}$$
        This yields the following coefficient matrix (and augmented matrix).
        $$\begin{bmatrix} -2 & 0 & -1 & -3 \\ -1 & 1 & 0 & -1 \\ -6 & 6 & 1 & -6 \\ 1 & 0 & 0 & 1\end{bmatrix}, \ \ \ \ \ \ \ \ M_a := \begin{amatrix}{4} -2 & 0 & -1 & -3 & 0 \\ -1 & 1 & 0 & -1 & -4 \\ -6 & 6 & 1 & -6 & -24 \\ 1 & 0 & 0 & 1 & 3 \end{amatrix}$$
        \item[(b)] Recall that we derived the following for the rearranged equations.
        $$\begin{array}{ccccl}
             3w & + 3x & + 0y & -5z &= 0  \\
             3w & + 3x &  -3y & + 0z &= 0 \\
             6w & +6x & -6y & -5z &= 0 \\
             w & + x & + 0y & + 0z &= 0
        \end{array}$$
        This yields the following coefficient matrix (and augmented matrix).
        $$\begin{bmatrix} 3 & 3 & 0 & -5 \\ 3 & 3 & -3 & 0 \\ 6 & 6 & -6 & -5 \\ 1 & 1 & 0 & 0\end{bmatrix}, \ \ \ \ \ \ \ \ M_b := \begin{amatrix}{4} 3 & 3 & 0 & -5 & 0 \\ 3 & 3 & -3 & 0 & 0 \\ 6 & 6 & -6 & -5 & 0 \\ 1 & 1 & 0 & 0 & 0\end{amatrix}$$
        \item[(c)] Recall that we derived the following for the rearranged equations.
        $$\begin{array}{ccccl}
    	0w & -5x & + 3y & + 3z & = -5 \\
    	0w & -7x & + 4y & + 4z & = -5 \\
    	0w & -2x & + y & + z & = 5 \\
	\end{array}$$
        This yields the following coefficient matrix (and augmented matrix).
        $$\begin{bmatrix} 0 & -5 & 3 & 3 \\ 0 & -7 & 4 & 4 \\ 0 & -2 & 1 & 1 \end{bmatrix}, \ \ \ \ \ \ \ \ M_c := \begin{amatrix}{4} 0 & -5 & 3 & 3 & -5 \\ 0 & -7 & 4 & 4 & -5 \\ 0 & -2 & 1 & 1 & 5 \end{amatrix}$$
        \end{enumerate}
    \item Using the \MathCite{rref}[REF] tool, we get the following matrices. 
    $$\rref(M_a) = \begin{amatrix}{4} 1 & 0 & \frac{1}{2} & \frac{3}{2} & 0 \\ 0 & 1 & \frac{1}{2} & \frac{1}{2} & -4 \\ 0 & 0 & 1 & 0 & 0 \\ 0 & 0 & 0 & 1 & -6 \end{amatrix}, \ \ \rref(M_b) = \begin{amatrix}{4} 1 & 1 & 0 & -\frac{5}{3} & 0 \\ 0 & 0 & 1 & -\frac{5}{3} & 0 \\ 0 & 0 & 0 & 1 & 0 \\ 0 & 0 & 0 & 0 & 0 \end{amatrix}, \ \ \rref(M_c) = \begin{amatrix}{4} 0 & 1 & -\frac{3}{5} & -\frac{3}{5} & 1 \\ 0 & 0 & 1 & 1 & -10 \\ 0 & 0 & 0 & 0 & 1 \end{amatrix}$$
    \item To determine the solution type, we consult the last row of the REF matrix for each system. 
        \begin{enumerate}
            \item[(a)] Consistent system, with one solution. 
            \item[(b)] Consistent system, with infinitely many solutions (bottom row is all zeroes).
            \item[(c)] Inconsistent system, there are no solutions (zero coefficients cannot yield a nonzero number). 
        \end{enumerate}
    \item Using the \MathCite{rref}[RREF] tool, we get the following matrices. 
    $$\Rref(M_a) = \begin{amatrix}{4} 1 & 0 & 0 & 0 & 9 \\ 0 & 1 & 0 & 0 & -1 \\ 0 & 0 & 1 & 0 & 0 \\ 0 & 0 & 0 & 1 & -6 \end{amatrix}, \ \ \Rref(M_b) = \begin{amatrix}{4} 1 & 1 & 0 & 0 & 0 \\ 0 & 0 & 1 & 0 & 0 \\ 0 & 0 & 0 & 1 & 0 \\ 0 & 0 & 0 & 0 & 0 \end{amatrix}, \ \ \Rref(M_c) = \begin{amatrix}{4} 0 & 1 & 0 & 0 & 0 \\ 0 & 0 & 1 & 1 & 0 \\ 0 & 0 & 0 & 0 & 1 \end{amatrix}$$
        \begin{enumerate}
            \item $\left\{\begin{bmatrix} w \\ x \\ y \\ z \end{bmatrix} \in \mathbb{R}^4 \ | \ \begin{bmatrix} w \\ x \\ y \\ z \end{bmatrix} = \begin{bmatrix} 9 \\ -1 \\ 0 \\ 6 \end{bmatrix}\right\}$
            \item $\left\{\begin{bmatrix} w \\ x \\ y \\ z \end{bmatrix} \in \mathbb{R}^4 \ | \ \begin{bmatrix} w \\ x \\ y \\ z \end{bmatrix} = t \begin{bmatrix} 1 \\ -1 \\ 0 \\ 0 \end{bmatrix}, t \in \mathbb{R}\right\}$
            \item \O
        \end{enumerate}
    \end{enumerate}
\end{SaveQuestion}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{SaveQuestion}[
        key=ch1-rref-rrefunknowns-dev,
        prompt={Consider a matrix $A$, which we transform to the matrix 
	$$
	B = \begin{bmatrix} 
	0 & a & 0 & 0 & b \\
	c & 0 & d & 0 & e \\
	0 & 0 & 0 & 1 & f
	\end{bmatrix}
	$$
	by a series of row operations.  Assume $B = \rref(A)$ (read $B$ is \textbf{the} reduced row echelon form of $A$).
	\begin{enumerate}
		\item  What can we say about the constants $a$ through $f$? What is the first column of $A$?
            \item  What is the rank of the matrix $A$?
		\item  Suppose $\begin{bmatrix} A\;|\;\vec 0\,\end{bmatrix}$ is the augmented matrix for a linear system. Here $\vec 0$ means a zero column. That is $\begin{bmatrix} 0\\ 0\\ 0 \end{bmatrix}$. Is the augmented matrix for a linear system. Is the system consistent?  If it is, how many solutions are there?
		\item Now, going further, suppose that $\begin{bmatrix} A\;|\;\vec v\,\end{bmatrix}$ (where $\vec{v}\ne\vec{0}$) is the augmented matrix for a linear system. Is the system consistent?  If so is, how many solutions are there?
		\item Continue to suppose that $\begin{bmatrix} A\;|\;\vec v\,\end{bmatrix}$ (where $\vec{v}\ne\vec{0}$) is the augmented matrix for a linear system.  Can you change the last row of $B$ so that the resulting linear system has no solutions?  Can you change the last row of $B$ to ensure that there is a \emph{unique} solution?
	\end{enumerate}
}][ch1-CON-rref,ch1-CON-augsoltype] %this is written as a comma seperated list with no spaces between commas
    %[<rubric items>]    %this is written as a comma seperated list with no spaces between commas
    %[<items mark>]      %this is written as a comma seperated list with no spaces between commas
\end{SaveQuestion}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{SaveQuestion}[
        key=ch1-matvec-lincomb1-dev,
        prompt={Let $\vec a = \begin{bmatrix} 0 \\ 1 \\ -1 \\ 2 \end{bmatrix}$ and $\vec b = \begin{bmatrix} 2 \\ 0 \\ 1 \\ 0 \end{bmatrix}$. 
\begin{enumerate}
	   \item Compute the {\bf linear combination} $2 \vec a + 3 \vec b.$ Compute  the {\bf linear combination} $5 \vec a - 2 \vec b$.
	   \item Form the $4 \times 2$ matrix $A = \begin{bmatrix} \vec a & \vec b\end{bmatrix}$  whose columns are the vectors $\vec a$ and $\vec b$. Compute the products 
	$A \begin{bmatrix} 2 \\ 3 \\ \end{bmatrix} $ and $A \begin{bmatrix} 5 \\ -2 \\ \end{bmatrix}$.
	   \item Compare your answers to (1) and (2). What do you notice? 
	   \item Let $\vec e_1 =  \begin{bmatrix} 1 \\ 0 \\ 0 \end{bmatrix}, \vec e_2 = \begin{bmatrix} 0 \\ 1 \\ 0 \end{bmatrix},$ and $ \vec e_3 = \begin{bmatrix} 0 \\ 0\\1\\ \end{bmatrix}$. Compute the linear combination $a \vec e_1 + b \vec e_2 + c \vec e_3$ (where the $a, b, c$ are real constants). Compute also the product $ \begin{bmatrix} \vec e_1 & \vec e_2 & \vec e_3 \end{bmatrix}  \begin{bmatrix} a \\ b \\ c \end{bmatrix}.$ What do you notice?
	   \item Let $\vec a = \begin{bmatrix} a_1\\  a_2 \end{bmatrix}$ and $\vec b =  \begin{bmatrix} b_1 \\ b_2 \end{bmatrix}$ in $\mathbb{R}^2$. For scalars $\lambda$ and $\mu$,   compute the linear combination $\lambda \vec a + \mu \vec b$. Can you find a $2\times 2$ matrix $A$ so that the product $ A \begin{bmatrix} \lambda \\ \mu  \end{bmatrix} = \lambda \vec a + \mu \vec b$. Check your work.
	   \item State,  in precise mathematical language, a criterion  for when a vector $\vec b \in \mathbb{R}^n$ is a linear combination of some vectors $\vec v_1, \vec v_2, \cdots \vec v_d$ in $\mathbb{R}^n$  in terms of some system of linear equations you can write down using the matrix whose columns are the $v_i$. 
        \end{enumerate}
}][ch1-CON-matlincom,chg-WRIT-matcom] %this is written as a comma seperated list with no spaces between commas
    %[<rubric items>]    %this is written as a comma seperated list with no spaces between commas
    %[<items mark>]      %this is written as a comma seperated list with no spaces between commas
\end{SaveQuestion}

%%Chapter 2%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{SaveQuestion}[
        key=ch2-lintrans-matrix-dev,
        prompt={A.   Consider the following mapping $$\mathbb{R}^2 \overset{T}\longrightarrow \mathbb{R}^2 \,\,\,\,\,{\text{sending}} \,\,\, \begin{bmatrix}x\\y\end{bmatrix} \mapsto \begin{bmatrix}x + 2y \\ x\end{bmatrix}.$$ Note that the coordinate entries are {\it linear expressions.} \begin{enumerate}
	\item Compute $T(\begin{bmatrix}1\\0\end{bmatrix}) $,\,$T(\begin{bmatrix}0\\1\end{bmatrix} ) $ and $T( \begin{bmatrix}1\\2\end{bmatrix})$. \item Let $A$ be the matrix $ \begin{bmatrix}1 & 2 \\1 &0\end{bmatrix}. $ Compute the product $A \begin{bmatrix}x\\y\end{bmatrix}$. \item Give a compact formula for the mapping $T$ in terms of the matrix $A$. \item Verify that $T( \begin{bmatrix}1\\0\end{bmatrix} + \begin{bmatrix}0\\1\end{bmatrix}) = T( \begin{bmatrix}1\\0\end{bmatrix})+ T(\begin{bmatrix}0\\1\end{bmatrix})$. \item Is  $T(\vec v_1 + \vec v_2) = T(\vec v_1) + T(\vec v_2)$ for any $\vec v_i \in \mathbb{R}^2$? Can you justify? \\
	{\tiny{ Advice: sometimes it helps to write out explicitly what things mean,  like $\vec v_1$ and also $T$ in this case.}} \item Is $T(\lambda \vec v) = \lambda T(\vec v)$ for all $\vec v \in \mathbb{R}^2$ and all scalars $\lambda$? Can you justify? \item Can every mapping of the form 
	$$\mathbb{R}^2 \overset{T}\longrightarrow \mathbb{R}^2, \,\,\,\,\, \begin{bmatrix}x\\y\end{bmatrix} \mapsto \begin{bmatrix}ax + by \\ cx + dy\\ \end{bmatrix}$$  be written compactly as matrix multiplication? Explain. \end{enumerate} \newline B.  Now take any two linear expressions in three variables, say $2x + 3y -z$ and $ x-y-4z$, and use them to build a ``multi-variable linear mapping" $$ \mathbb{R}^3 \overset{T'}\longrightarrow \mathbb{R}^2\,\,\,\,\,\,\, \begin{bmatrix}x\\y\\z \end{bmatrix}\mapsto \begin{bmatrix} 2x + 3y -z\\ x-y-4z\end{bmatrix}.$$ Speculating with your table, ask your own questions to come to an understanding of this mapping as in (A) above. For example, can $T'$ be written using matrix multiplication? Justify!{\footnote{ In a case like this, yous simply need to write down explicitly the claimed matrix, and then check that it works.}}Do you think that $T'(\lambda \vec v_1) = \lambda T'(\vec v_1)$? Is  $T'(\vec v_1 + \vec v_2) = T'(\vec v_1) + T'(\vec v_2)$? Justify!}]
[ch2-COM-standmat] %this is written as a comma seperated list with no spaces between commas
    %[<rubric items>]    %this is written as a comma seperated list with no spaces between commas
    %[<items mark>]      %this is written as a comma seperated list with no spaces between commas
    Part A. \begin{enumerate}
        \item $T( \begin{bmatrix}1\\0\end{bmatrix}) = \begin{bmatrix}1\\1\end{bmatrix}, \hskip 1cm
		\, T(  \begin{bmatrix}0\\1\end{bmatrix} )  = \begin{bmatrix}2\\0\end{bmatrix} $ \,\,\,\,\,\, and $T( \begin{bmatrix}1\\2\end{bmatrix}) = \begin{bmatrix}5\\1\end{bmatrix}
		$.
  \item $A \begin{bmatrix}x\\y\end{bmatrix} =   \begin{bmatrix}1 & 2 \\1 &0\end{bmatrix}\begin{bmatrix}x\\y\end{bmatrix}  =  \begin{bmatrix}x + 2y \\ x\end{bmatrix}.$
  \item $T(\begin{bmatrix}x\\ y\end{bmatrix} ) = A \begin{bmatrix}x\\ y\end{bmatrix} $.
  \item $T( \begin{bmatrix}1\\0\end{bmatrix} + \begin{bmatrix}0\\1\end{bmatrix}) = T( \begin{bmatrix}1\\1\end{bmatrix} ) = \begin{bmatrix}3\\1\end{bmatrix} $, which is 
		$ \begin{bmatrix}1\\1\end{bmatrix} +  \begin{bmatrix}2\\0\end{bmatrix} $. We can also use the distributive property of matrices multiplication:
		$$
		T( \begin{bmatrix}1\\0\end{bmatrix} + \begin{bmatrix}0\\1\end{bmatrix})  = A ( \begin{bmatrix}1\\0\end{bmatrix} + \begin{bmatrix}0\\1\end{bmatrix}) = 
		A \begin{bmatrix}1\\0\end{bmatrix} + A \begin{bmatrix}0\\1\end{bmatrix}) = T( \begin{bmatrix}1\\0\end{bmatrix}) + T( \begin{bmatrix}0\\1\end{bmatrix}) ).$$
  \item Yes!  Let $\vec v_1 =  \begin{bmatrix}x_1\\ y_1 \end{bmatrix}$ and $\vec v_2 =  \begin{bmatrix}x_2\\ y_2 \end{bmatrix}$. Then  
			$$T(\vec v_1 + \vec v_2) = A  (\begin{bmatrix}x_1\\ y_1 \end{bmatrix}+   \begin{bmatrix}x_2\\ y_2 \end{bmatrix}) = 
			A  \begin{bmatrix}x_1\\ y_1 \end{bmatrix} +  A \begin{bmatrix}x_2\\ y_2 \end{bmatrix},$$ which is 
			$T(\vec v_1) + T(\vec v_2).$
   \item Yes! let $\vec v = \begin{bmatrix}x\\ y\end{bmatrix}. $ Then 
		$$T(\lambda \vec v) =   T(\lambda   \begin{bmatrix} x\\   y\end{bmatrix}) = T( \begin{bmatrix} \lambda x\\  \lambda y\end{bmatrix})   = \begin{bmatrix}\lambda x + 2(\lambda y)  \\ \lambda x\end{bmatrix},$$
		using the original definition of the mapping $T$.  But then factoring out the $\lambda$, this is equal to  
		$ 
		\begin{bmatrix}\lambda (x + 2y)  \\ \lambda x\end{bmatrix} =   \lambda \begin{bmatrix}  (x + 2y)  \\  x\end{bmatrix}  = \lambda T( \begin{bmatrix}x\\ y\end{bmatrix})$. 
  \item Yes! Just check that $T( \begin{bmatrix}x\\ y \end{bmatrix}) $ is the matrix product  $\begin{bmatrix}a &  b \\ c &  d\\ \end{bmatrix} \begin{bmatrix}x\\y\end{bmatrix}.$
    \end{enumerate}

    Part B.
    Yes this map can be described using matrix multiplication. We have $T'( \begin{bmatrix}x\\y \\z \end{bmatrix}) = \begin{bmatrix} 2 &  3 &  - 1 \\ 1 & -1 & -4\end{bmatrix}\begin{bmatrix}x\\y \\z \end{bmatrix}$, as you can check. It does respect addition and scalar multiplication, which you can check directly from the formula:
		$$
		\begin{aligned}
		T'( \begin{bmatrix}x_1\\y_1 \\z_1 \end{bmatrix} +  \begin{bmatrix}x_2\\y_2 \\z_2 \end{bmatrix}) =& T'( \begin{bmatrix}x_1 +x_2\\y_1+y_2 \\z_1+z_2 \end{bmatrix} ) 
		= 
		\begin{bmatrix} 2(x_1+x_2) + 3(y_1+y_2) -(z_1+z_2)\\ (x_1+x_2) -(y_1+y_2)-4(z_1+z_2)\end{bmatrix}. \\ = &   
		\begin{bmatrix} 2x_1+ 3y_1 - z_1 \\ x_1 -y_1-z_1\end{bmatrix}. +  \begin{bmatrix} 2x_2 + 3y_2 -z_2\\ x_2 -y_2-4z_2+z_2\end{bmatrix} \\ =&
		T'(\begin{bmatrix}x_1\\y_1 \\z_1 \end{bmatrix}) + T'( \begin{bmatrix}x_2\\y_2 \\z_2 \end{bmatrix}).
		\end{aligned}$$
		Alternatively (and perhaps more straightforwardly), you can also use the distributive property of matrix multiplication to check this.
		Similarly, the map $T'$ respects scalar multiplication.
\end{SaveQuestion}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{SaveQuestion}[
        key=ch2-lintrans-matrix-sbg,
        prompt={Take the two linear expressions in three variables $2x + 3y -z$ and $ x-y-4z$, and use them to build a ``multi-variable linear mapping".
        $$ \mathbb{R}^3 \overset{T} \longrightarrow \mathbb{R}^2 \quad \begin{bmatrix} x \\ y \\ z \end{bmatrix} \mapsto \begin{bmatrix} 2x + 3y - z \\ x - y - 4z \end{bmatrix}$$
        \begin{enumerate} 
            \item What is the domain and codomain of $T$? 
            \item To better understand this map, answer the following. What is $T\left(\begin{bmatrix} 1\\3\\-1 \end{bmatrix}\right)$? What about $T\left(\begin{bmatrix} 5\\15\\-5 \end{bmatrix}\right)$? Can we find $T\left(\begin{bmatrix} 1\\-2 \end{bmatrix}\right)$? 
            \item If $T$ were linear, could we determine $T\left(\begin{bmatrix} 5\\15\\-5 \end{bmatrix}\right)$ using $T\left(\begin{bmatrix} 1 \\ 3 \\ -1 \end{bmatrix}\right)$?
            \item  Verify that $T$ is linear by using the definition of a linear transformation. 
            \item Can $T$ be written using matrix multiplication?  If yes find the matrix. Justify your work by referring to a theorem from your reading!  \end{enumerate}}
][ch2-COM-standmat, chg-WRIT-matcom] %this is written as a comma seperated list with no spaces between commas
    [Correct matrix in part 5 with correct justification: either reading off the matrix from the general formula of the linear transformation or computing the output of the standard vectors.*,Part 4* i) Correct and complete definition of linearity.* ii) Correct application of the definition to this map.* iii) Correct deduction of linearity.*Uses the correct definition of a linear transformation from PCE4.*]    %this is written as a comma seperated list with no spaces between commas
    %[<items mark>]      %this is written as a comma seperated list with no spaces between commas
    \begin{enumerate}
      \item The domain of the linear transformation $T$ is $\mathbb{R}^3$ and the codomain is $\mathbb{R}^2$.
      
      \item We compute the following by directly evaluating the map $T$. 
      $$T\left(\begin{bmatrix} 1 \\ 3 \\ -1 \end{bmatrix}\right) = \begin{bmatrix} 2(1) + 3(3) - (-1) \\ (1) - (3) - 4(-1) \end{bmatrix} = \begin{bmatrix} 12 \\ 2 \end{bmatrix} \quad T\left(\begin{bmatrix} 5 \\ 15 \\ -5 \end{bmatrix}\right) = \begin{bmatrix} 2(5) + 3(15) - (-5) \\ (5) - (15) - 4(-5) \end{bmatrix} = \begin{bmatrix} 60 \\ 10 \end{bmatrix} \quad T\left(\begin{bmatrix} 1 \\ -2 \end{bmatrix}\right) = \text{ D.N.E.}$$
      Note that $T$ can only map vectors in $\mathbb{R}^3$. 
      \item If $T$ were linear, we could find $T\left(\begin{bmatrix} 5\\15\\-5 \end{bmatrix}\right)$ using $T\left(\begin{bmatrix} 1 \\ 3 \\ -1 \end{bmatrix}\right)$, using the linear property of $T$. 
      $$T\left(\begin{bmatrix} 5\\15\\-5 \end{bmatrix}\right) = T\left(5\begin{bmatrix} 1 \\ 3 \\ -1 \end{bmatrix}\right) = 5 \cdot T\left(\begin{bmatrix} 1 \\ 3 \\ -1 \end{bmatrix}\right)$$
      \item To verify that $T$ is linear, we need to verify that for any $\vec v_1, \vec v_2 \in \mathbb{R}^3$ and $k \in \mathbb{R}$, we have the following.
      $$T(\vec v_1 + \vec v_2) = T(\vec v_1) + T(\vec v_2) \quad T(k\vec v_1) = k T(\vec v_1)$$
      Verify the addition aspect of linearity.
      \begin{align*}
          T(\vec v_1 + \vec v_2)        &= T\left(\begin{bmatrix} x_1 + x_2 \\ y_1 + y_2 \\ z_1 + z_2 \end{bmatrix}\right)                                                              &\text{Writing out $\vec v_1, \vec v_2$.} \\
                                        &= \begin{bmatrix} 2(x_1 + x_2) + 3(y_1 + y_2) - (z_1 + z_2) \\ (x_1 + x_2) - (y_1 + y_2) - 4(z_1 + z_2) \end{bmatrix}                          &\text{Evaluating $T(\vec v_1 + \vec v_2)$.} \\
                                        &= \begin{bmatrix} 2x_1 + 3y_1 - z_1 \\ x_1 - y_1 - 4z_1 \end{bmatrix} + \begin{bmatrix} 2x_2 + 3y_2 - z_2 \\ x_2 - y_2 - 4z_2 \end{bmatrix}    &\text{Splitting the vectors.} \\
                                        &= T\left(\begin{bmatrix} x_1 \\ y_1 \\ z_1 \end{bmatrix}\right) + T\left(\begin{bmatrix} x_2 \\ y_2 \\ z_2 \end{bmatrix}\right)                &\text{Definition of $T$.} \\
                                        &= T(\vec v_1) + T(\vec v_2)                                                                                                                    &\text{Substituting.}
      \end{align*}
      Verify the scalar multiplication aspect of linearity.
      \begin{align*}
          T(k \vec v_1)         &= T\left(\begin{bmatrix} k x_1 \\ k y_1 \\ k z_1 \end{bmatrix}\right)                                      &\text{Writing out $k \vec v_1$.} \\
                                &= \begin{bmatrix} 2(k x_1) + 3(k y_1) - (k z_1) \\ (k x_1) - (k y_1) - 4(k z_1) \end{bmatrix}              &\text{Evaluating $T(k\vec v_1)$.} \\ 
                                &= \begin{bmatrix} k(2x_1 + 3y_1 - z_1) \\ k(x_1 - y_1 - 4z_1) \end{bmatrix}                                &\text{Factoring $k$.} \\
                                &= k \begin{bmatrix} 2x_1 + 3y_1 - z_1 \\ x_1 - y_1 - 4z_1 \end{bmatrix}                                    &\text{Factoring $k$.} \\
                                &= k T\left(\begin{bmatrix} x_1 \\ y_1 \\ z_1 \end{bmatrix}\right)                                          &\text{Definition of $T$.} \\ 
                                &= k T(\vec v_1)                                                                                            &\text{Substituting.}
      \end{align*}
      Thus, we have verified that by definition, $T$ is a linear transformation. 

      \item Yes this map can be described using matrix multiplication. We have $T\left(\begin{bmatrix}x\\y \\z \end{bmatrix}\right) = \begin{bmatrix} 2 &  3 &  - 1 \\ 1 & -1 & -4\end{bmatrix}\begin{bmatrix}x\\y \\z \end{bmatrix}$. 
      
      We can find this matrix directly or by using the Theorem[Linear Transformations and Matrices] from readings which tell us that the columns of the standard matrix of a linear map are the output of standard vectors in our domain $\mathbb{R}^3$. 
      
      Alternatively, the Linear Transformation and Matrices Theorem from the readings states that any linear transformation can be represented by a matrix, and any transformation that can be represented by a matrix must be linear. We already showed $T$ is linear, so we can write $T$ using matrix multiplication. 

        
         
  \end{enumerate}
\end{SaveQuestion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{SaveQuestion}[
        key=ch2-lintrans-match-sbg,
        prompt={Each of the linear transformations in parts (1) through (5) corresponds to one or more of the matrices $A$ through $F$. One of the matrices is a composition of 2 of the linear transformations. Match them up and identify which is a composition and what that composition is. Draw the effects on a non-zero vector of your choice to justify your matchups. \begin{enumerate} \item Scaling \item Shear \item Rotation \item Orthogonal projection \item Reflection \end{enumerate}$$ A= \begin{bmatrix} 0 & 0\\ 0 & 1 \end{bmatrix} \; \; \; B= \begin{bmatrix} 2 & 1\\ 1 & 0 \end{bmatrix} \; \; \; C= \begin{bmatrix} -0.6 & 0.8\\ -0.8 & -0.6 \end{bmatrix}$$ $$D= \begin{bmatrix} 7 & 0\\ 0 & 7 \end{bmatrix} \; \; \; E= \begin{bmatrix} 1 & 0\\ -3 & 1 \end{bmatrix} \; \; \; F= \begin{bmatrix} 0.6 & 0.8\\ 0.8 & -0.6 \end{bmatrix}$$}
][ch2-CON-geotrans,ch2-VG-geotrans] %this is written as a comma seperated list with no spaces between commas
    [Correct pairings excluding matrix B*,Drawing that clearly shows the input vector and the output vector of the linear transformation for each matrix*]    %this is written as a comma seperated list with no spaces between commas
    %[<items mark>]      %this is written as a comma seperated list with no spaces between commas
    \begin{itemize}
        \item $A$ is the orthogonal projection onto the $y$-axis. 
        \item $B$ is a composition of a reflection and a shear (not one of the listed options), 
        \item $C$ is a rotation through angel $\arccos(-0.6)$, 
        \item $D$ is scaling by a factor of $7$, 
        \item $E$ is a shear,
        \item $F$ is a reflection. Note that the magnitude of the standard vectors remains unchanged. So $F$ can not be a scaling or shear. Drawing the output of the standard vectors shows that the order of these vectors switches after the transformation. This change in the orientation of the space is a characteristic of a reflection. We can find exactly which line by comparing the entries of this matrix with the general form of a reflection matrix. 
    \end{itemize}
\end{SaveQuestion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{SaveQuestion}[
        key=ch2-lintrans-unitsqr-sbg,
        prompt={In this problem, you will visualize the effect of some of the linear transformations in the following list: 
        $$A = \begin{bmatrix} 0 & 0\\ 0 & 1 \end{bmatrix} \quad B = \begin{bmatrix} 2 & 1 \\ 1 & 0 \end{bmatrix} \quad C = \begin{bmatrix} -0.6 & 0.8 \\ -0.8 & -0.6 \end{bmatrix}$$ 
        For the following, assume $T: \mathbb{R}^2 \rightarrow \mathbb{R}^2$ is a linear transformation induced by one of the matrices above.
        \begin{enumerate} 
        \item Given scalars $c_1, c_2 \in \mathbb{R}$, can you simplify $T(c_1\vec e_1 + c_2 \vec e_2)$? Recall that $T$ is given by a matrix multiplication and hence is linear.
        \item For each linear transformation, draw two copies of $\mathbb{R}^2$. The left copy represents the domain and the right copy represents the codomain.
        \begin{itemize}
            \item[(a)] Draw the standard vectors $\vec e_1$ and $\vec e_2$ in the domain $\mathbb{R}^2$. Shade the set  $R= \{c_1\vec e_1 + c_2 \vec e_2 \,  | \,0 \leq c_1, c_2 \leq 1$\} in the domain.  
            \item[(b)] Next, draw $T(\vec e_1)$ and $T(\vec e_2)$ in the codomain $\mathbb{R}^2$. Shade the set $T(R)=\{T(c_1\vec e_1 + c_2 \vec e_2) \,  | \,0 \leq c_1, c_2 \leq 1$\} in the codomain. 
            \item[(c)] Explain in words, what does $T$ do to the unit square? 
            \item[(d)] Apply the transformation $T$ to the image below. \begin{center} \includegraphics[scale=0.25]{Question Photos/ch2-lintrans-unitsqr-sbg.png}\end{center} 
            Hint: Recall that the associated matrix induces the linear transformation.
        \end{itemize}
        \end{enumerate}}
][ch2-VG-unitlintrans] %this is written as a comma seperated list with no spaces between commas
    [Correct drawing in part 2b (for each linear transformation); the drawing can be visually deduced to be a linear combination of the outputs of the standard vectors.*Correct answer to part 2c (for each linear transformation) which clearly identifies the linear transformation that T represents.*]    %this is written as a comma seperated list with no spaces between commas
    %[<items mark>]      %this is written as a comma seperated list with no spaces between commas
    \begin{enumerate}
    \item To simplify the expression $T(c_1 \vec e_1 + c_2 \vec e_2)$, we will use the fact that $T$ is linear. 
    \begin{align*}
        T(c_1 \vec e_1 + c_2 \vec e_2)      &= T(c_1 \vec e_1) + T(c_2 \vec e_2) \\
                                            &= c_1 T(\vec e_1) + c_2 T(\vec e_2) \\
    \end{align*}
    From this, we see that the output of a linear transformation is entirely defined by the outputs of the standard vectors. 
    \item
    \begin{itemize}
        \item[(a)] We obtain that $R \subseteq \mathbb{R}^2$ is the unit square.
        Visualization \href{https://www.desmos.com/calculator/phpjhwlgnp}{here}.
        \item[(b)] We obtain the following from the three linear transformations.
        Visualization \href{https://www.desmos.com/calculator/ouxfmt4tcg}{here}. 
        \item[(c)] The linear transformation described by the matrix $A$ is a projection onto the $y$-axis. The linear transformation described by the matrix $B$ is a shear. The linear transformation described by the matrix $C$ is a rotation. 
    \end{itemize}
    \end{enumerate}
\end{SaveQuestion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{SaveQuestion}[
        key=ch2-lintrans-dilate3-dev,
        prompt={Let $S:  \mathbb{R}^2 \rightarrow \mathbb{R}^2$ be {\it dilation}  by a factor of three. \begin{enumerate} \item Give a {\it geometric} reason that $S$ is a linear transformation {\it using the definition}. \item What is the associated matrix $A$ so that $S(\vec v) = A \vec v$? \item What about dilation (or contraction) by an arbitrary factor? \end{enumerate}}
][ch2-CON-geotrans] %this is written as a comma seperated list with no spaces between commas
    %[<rubric items>]    %this is written as a comma seperated list with no spaces between commas
    %[<items mark>]      %this is written as a comma seperated list with no spaces between commas
    \begin{enumerate}
		\item 
		\item $A=\begin{bmatrix}
		3&0\\0&3
		\end{bmatrix}$
		\item $A=\begin{bmatrix}
		k&0\\0&k
		\end{bmatrix}$
	\end{enumerate}
\end{SaveQuestion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{SaveQuestion}[
        key=ch2-lintrans-rotccw-dev,
        prompt={Let $L: \mathbb{R}^2 \rightarrow \mathbb{R}^2$ be {\it rotation} in the counter-clockwise direction by $90^\circ$ (fixing the origin). \begin{enumerate} \item Give a {\it geometric} explanation why $L$ is a linear transformation {\it using the definition}. \item What is the associated matrix $A$ so that $L(\vec v) = A \vec v$? \item What about rotation through an arbitrary angle $\theta$? To write the matrix, you need to remember your high school trig. \end{enumerate}}
][ch2-CON-geotrans] %this is written as a comma seperated list with no spaces between commas
    %[<rubric items>]    %this is written as a comma seperated list with no spaces between commas
    %[<items mark>]      %this is written as a comma seperated list with no spaces between commas
    \begin{enumerate}
		\item 
		\item $A=\begin{bmatrix}
		0&-1\\1&0
		\end{bmatrix}$
		\item $A=\begin{bmatrix}
		\cos\theta&-\sin\theta\\\sin \theta&\cos \theta
		\end{bmatrix}$. Read Sec 2.2
	\end{enumerate}
\end{SaveQuestion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{SaveQuestion}[
        key=ch2-lintrans-reflectx-dev,
        prompt={Let $M: \mathbb{R}^2 \rightarrow \mathbb{R}^2$ be {\it reflection} over the $x$-axis. \begin{enumerate} \item Show that $M$ is linear by writing down a formula for it explicitly. \item What about reflection over the line $y = x$? Is this a linear tranformation? If so, find its matrix. \end{enumerate}}
][ch2-CON-geotrans] %this is written as a comma seperated list with no spaces between commas
    %[<rubric items>]    %this is written as a comma seperated list with no spaces between commas
    %[<items mark>]      %this is written as a comma seperated list with no spaces between commas
    \begin{enumerate}
		\item $M(\begin{bmatrix}
		x\\y
		\end{bmatrix})=\begin{bmatrix}
		x\\-y
		\end{bmatrix}$. $$M(\begin{bmatrix}
		x_1\\y_1
		\end{bmatrix}+\begin{bmatrix}
		x_2\\y_2
		\end{bmatrix})=M(\begin{bmatrix}
		x_1+x_2\\y_1+y_2
		\end{bmatrix})=\begin{bmatrix}
		x_1+x_2\\-(y_1+y_2)
		\end{bmatrix}=\begin{bmatrix}
		x_1\\-y_1)
		\end{bmatrix}+\begin{bmatrix}
		x_2\\y_2
		\end{bmatrix}=M\begin{bmatrix}
		x_1\\y_1
		\end{bmatrix}+M\begin{bmatrix}
		x_1\\y_1
		\end{bmatrix}$$
		and 
		$$ 
		M(k\begin{bmatrix}
		x\\y
		\end{bmatrix})=M\begin{bmatrix}
		kx\\ky
		\end{bmatrix}=\begin{bmatrix}
		kx\\-ky
		\end{bmatrix}=k\begin{bmatrix}
		x\\-y
		\end{bmatrix}=kM\begin{bmatrix}
		x\\y
		\end{bmatrix}
		$$
		\item Read Sec 2.2 
	\end{enumerate}
\end{SaveQuestion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{SaveQuestion}[
        key=ch2-lintrans-strcont-dev,
        prompt={Let $Q: \mathbb{R}^2 \rightarrow \mathbb{R}^2$ be the transformation that stretches  vertically by a factor of two and contracts horizontally by a factor of 3. \begin{enumerate} \item Show that $Q$ is linear by writing down a formula for it explicitly. \item What about arbitrary (but different) scale factors vertically and horizontally? What happens if they are negative? \end{enumerate}}
][ch2-VG-geotrans] %this is written as a comma seperated list with no spaces between commas
    %[<rubric items>]    %this is written as a comma seperated list with no spaces between commas
    %[<items mark>]      %this is written as a comma seperated list with no spaces between commas
    \begin{enumerate}
		\item $Q\begin{bmatrix}
		x\\y
		\end{bmatrix}=\begin{bmatrix}
		1/3x\\2y
		\end{bmatrix}$
		\item $Q\begin{bmatrix}
		x\\y
		\end{bmatrix}=\begin{bmatrix}
		kx\\ly
		\end{bmatrix}$
	\end{enumerate}
\end{SaveQuestion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{SaveQuestion}[
        key=ch2-lintrans-arbreflect-dev,
        prompt={Thinking geometrically, do you think that a reflection over an arbitrary line through the origin is a linear transformation? Challenge: Can you write down its matrix?}
][ch2-CON-lintranscheck,ch2-VG-geotrans] %this is written as a comma seperated list with no spaces between commas
    %[<rubric items>]    %this is written as a comma seperated list with no spaces between commas
    %[<items mark>]      %this is written as a comma seperated list with no spaces between commas
    Yes, read Sec 2.2
\end{SaveQuestion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{SaveQuestion}[
        key=ch2-lintrans-multiexamp-dev,
        prompt={\begin{enumerate}
            \item Let $M: \mathbb{R}^2 \rightarrow \mathbb{R}^2$ be {\it reflection} over the $x$-axis. \begin{enumerate} \item Write an explicit formula for $M$. Use this formula and the definition of a linear transformation to show that $M$ is linear.
            Show that $M$ is linear by writing down a formula for it explicitly. \item What about reflection over the line $y = x$? Is this a linear transformation? If so, find its matrix by finding the output of standard vectors. \end{enumerate}
            \item Thinking geometrically, do you think that a reflection over an arbitrary line through the origin is a linear transformation? Draw an image that backs up your argument.
        \end{enumerate}}
][ch2-CON-geotrans,ch2-VG-geotrans,ch2-CON-lintranscheck,chg-WRIT-matnot] %this is written as a comma seperated list with no spaces between commas
    [Satisfactory: Good notation for part 1a. Correct matrix part 1b. Drawing that justifies linearity by representing vector addition and scalar multiplication*Can be Improved: Any notational or minor mathematical mistakes*Try Again: Major conceptual misunderstanding.*]    %this is written as a comma seperated list with no spaces between commas
    %[<items mark>]      %this is written as a comma seperated list with no spaces between commas
    \begin{enumerate}
    \item \begin{enumerate}
		\item $M\left(\begin{bmatrix}
		x\\y
		\end{bmatrix}\right)=\begin{bmatrix}
		x\\-y
		\end{bmatrix}$. $$M\left(\begin{bmatrix}
		x_1\\y_1
		\end{bmatrix}+\begin{bmatrix}
		x_2\\y_2
		\end{bmatrix}\right)=M\left(\begin{bmatrix}
		x_1+x_2\\y_1+y_2
		\end{bmatrix}\right)=\begin{bmatrix}
		x_1+x_2\\-(y_1+y_2)
		\end{bmatrix}$$
        $$=\begin{bmatrix}
		x_1\\-y_1
		\end{bmatrix}+\begin{bmatrix}
		x_2\\-y_2
		\end{bmatrix}=M\begin{bmatrix}
		x_1\\y_1
		\end{bmatrix}+M\begin{bmatrix}
		x_1\\y_1
		\end{bmatrix}$$
		and 
		$$ 
		M\left(k\begin{bmatrix}
		x\\y
		\end{bmatrix}\right)=M\begin{bmatrix}
		kx\\ky
		\end{bmatrix}=\begin{bmatrix}
		kx\\-ky
		\end{bmatrix}=k\begin{bmatrix}
		x\\-y
		\end{bmatrix}=kM\begin{bmatrix}
		x\\y
		\end{bmatrix}
		$$
		\item Yes it is a linear transformation. It's matrix is $$\begin{bmatrix}
		    0 & 1 \\ 1 & 0
		\end{bmatrix}$$ 
	\end{enumerate}
    \item Yes it is a linear transformation. The image should be a picture of an arbitrary line with a drawing of two arbitrary vectors being reflected, showing that the vector addition (tip to tail) is preserved. Similarly with scalar multiplication.
    \end{enumerate}
\end{SaveQuestion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{SaveQuestion}[
        key=ch2-lintrans-composition2-sbg,
        prompt={\begin{enumerate} 
        \item Below are certain examples of matrices $A$ and $B$. Remember that an $m\times n$ matrix gives a linear map from $\bbR^n$ to $\bbR^m$ by left multiplication. Let us write $L_A$ and $L_B$ for the linear maps given by left multiplication by $A$ and $B$ respectively. In which of the cases below does it make sense to consider the composite map \( L_A \circ L_B ? \) \begin{enumerate} \item  $A= \begin{bmatrix} 4 & 1 & -5 \\ 2 & -1 & 3\end{bmatrix}$, $B= \begin{bmatrix} 6 \\ 7\\1  \end{bmatrix} $ \item $A= \begin{bmatrix} 4 & 1 & -5\\ 2 & -1 & 3 \end{bmatrix}$, $B= \begin{bmatrix} 6 & 7&1  \end{bmatrix} $ \item $A= \begin{bmatrix} 4 & 1 & -5 \\ 2 & -1 & 3\end{bmatrix}$, $B= \begin{bmatrix} 6 & 7 & -4 \\ 3 & 2 &  -2\\1&0&0\end{bmatrix} $ \end{enumerate}\item In the cases from the previous problem where $L_A \circ L_B$ makes sense, it is given by left multiplication by a matrix, i.e., \[ L_A \circ L_B = L_C \] for a {\it unique} choice of matrix $C$. State the theorem(s) that guarantees the existence of such a matrix $C$? 
        \item  What is the relation between the columns of $C$ and the linear map $L_C$? 
        \item Compute $C$ by computing $L_C(\vec{e}_i)$. 
        \item $C$ is the product of $A$ and $B$ in a certain order. What is the correct order? Use matrix multiplication to verify your claim. 
        \end{enumerate} }
][ch2-COM-matvec,ch2-COM-matdotprod]
    [Correctly computes the matrix of the composite linear map by applying A to the columns of B using matrix-vector multiplication (for each compatible case).*,Correctly computes the matrix of the composite linear map by finding the ij-th entry of AB directly by computing the dot product between the ith row of A and the jth column of B (for each compatible case).*]
    \begin{enumerate}
        \item We know that if we want to consider the composition of two linear maps, it must be that the domain of $L_A$ is the codomain of $L_B$. 
        \begin{enumerate}
            \item $L_B: \mathbb{R}^1 \rightarrow \mathbb{R}^3, L_A: \mathbb{R}^3 \rightarrow \mathbb{R}^2$
            \item $L_B: \mathbb{R}^3 \rightarrow \mathbb{R}^1, L_A: \mathbb{R}^3 \rightarrow \mathbb{R}^2$
            \item $L_B: \mathbb{R}^3 \rightarrow \mathbb{R}^3, L_A: \mathbb{R}^3 \rightarrow \mathbb{R}^2$.
        \end{enumerate}
        So (a) and (c) makes sense. 

        \item This can be found in the definition `Product of Matrices` in PCE4 (pg. 4). This states let $T: \mathbb{R}^m \rightarrow \mathbb{R}^n, T(\vec x) = A\vec x$ and $S: \mathbb{R}^n \rightarrow \mathbb{R}^p, S(\vec y) = B\vec y$ be linear transformations with associated standard matrices A and B respectively. Then BA is defined to be the unique matrix associated with the composition $S \circ T: \mathbb{R}^m \rightarrow \mathbb{R}^p$. So we have that $C = BA$. 

        \item We know that the $i$-th column of $C$ represents the output of the $i$-th standard vector $\vec e_i$. Ultimately, this means that any output of $L_C$ is some scalar combination of the columns of $C$. 

        \item Note, that we only do the following for (a) and (c), since the other composition does not make sense.
        \begin{enumerate}
            \item[(a)] Since the domain is $\mathbb{R}^1$, we only have the one standard vector $\vec e_1 \in \mathbb{R}^1$. Therefore, we have the following.
            $$C = \begin{bmatrix} \vert \\ L_C(\vec e_1) \\ \vert \end{bmatrix} = \begin{bmatrix} \vert \\ L_A(L_B(\vec e_1)) \\ \vert \end{bmatrix} = \begin{bmatrix} \vert \\ L_A\left(\begin{bmatrix} 6 \\ 7\\1  \end{bmatrix}\right) \\ \vert \end{bmatrix} = \begin{bmatrix} 26 \\ 8 \end{bmatrix}$$

            \item[(c)] Since the domain is $\mathbb{R}^3$, we have the three standard vectors $\vec e_1, \vec e_2, \vec e_3 \in \mathbb{R}^3$. Therefore, we have the following.
            $$\begin{matrix}
            \begin{array}{cl}
                L_C(\vec e_1)   &= L_A \circ L_B(\vec e_1) \\
                                &= L_A(L_B(\vec e_1) \\
                                &= L_A\left(\begin{bmatrix} 6 \\ 3 \\ 1 \end{bmatrix}\right) \\
                                &= \begin{bmatrix} 22 \\ 12 \end{bmatrix}
            \end{array}&
            \begin{array}{cl}
                L_C(\vec e_2)   &= L_A \circ L_B(\vec e_2) \\
                                &= L_A(L_B(\vec e_2) \\
                                &= L_A\left(\begin{bmatrix} 7 \\ 2 \\ 0 \end{bmatrix}\right) \\
                                &= \begin{bmatrix} 30 \\ 12 \end{bmatrix}
            \end{array}&
            \begin{array}{cl}
                L_C(\vec e_3)   &= L_A \circ L_B(\vec e_3) \\
                                &= L_A(L_B(\vec e_3) \\
                                &= L_A\left(\begin{bmatrix} -4 \\ -2 \\ 0 \end{bmatrix}\right) \\
                                &= \begin{bmatrix} -18 \\ -6 \end{bmatrix}
            \end{array}
            \end{matrix}$$
            Using these computations, we may derive $C$. 
            $$C = \begin{bmatrix} \vert & \vert & \vert \\ L_C(\vec e_1) & L_C(\vec e_2) & L_C(\vec e_3) \\ \vert & \vert & \vert \end{bmatrix} = \begin{bmatrix} 22 & 30 & -18 \\ 12 & 12 & -6 \end{bmatrix}$$
        \end{enumerate}

        \item Note, that we only do the following for (a) and (c), since the other composition does not make sense. Since we define $L_C$ as the compostion $L_A \circ L_B$, we must multiply in the order $AB$. This means that the transformation $L_B$ is applied first, then $L_A$. 
        \begin{enumerate}
            \item[(a)] $$C = AB = \begin{bmatrix} 4 & 1 & -5 \\ 2 & -1 & 3\end{bmatrix}\begin{bmatrix} 6 \\ 7\\1  \end{bmatrix} = \begin{bmatrix} (4)(6) + (1)(7) + (-5)(1) \\ (2)(6) + (-1)(7) + (3)(1) \end{bmatrix} = \begin{bmatrix} 26 \\ 8 \end{bmatrix}$$
            \item[(c)] $$C = AB = \begin{bmatrix} 4 & 1 & -5 \\ 2 & -1 & 3\end{bmatrix}\begin{bmatrix} 6 & 7 & -4 \\ 3 & 2 & -2 \\ 1 & 0 & 0 \end{bmatrix} = \begin{bmatrix} 22 & 30 & -18 \\ 12 & 12 & -6 \end{bmatrix}$$
        \end{enumerate}
    \end{enumerate}
\end{SaveQuestion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{SaveQuestion}[
        key=ch2-lintrans-composition3-sbg,
        prompt={Consider the following three operations on $\bbR^2$. Rotate by $\pi/2$ anticlockwise ($R: \mathbb{R}^2 \rightarrow \mathbb{R}^2$), reflect in the line $x=y$ ($L: \mathbb{R}^2 \rightarrow \mathbb{R}^2$), project orthogonally onto the line $x=-y$ ($P: \mathbb{R}^2 \rightarrow \mathbb{R}^2$). We want to perform these three operations in some order. \begin{enumerate} \item How many choices of order are there? Pick ONE of these choices. Each such choice gives a linear map $T: \mathbb{R}^2 \rightarrow \mathbb{R}^2$. In the rest of this question, we will find the standard matrix of this linear map in two different ways. \item \textbf{(Prediction)} Do you think each order you found in (a) would produce the same composition? This is not for correctness, but to discuss as a group. \item Think geometrically. Find the standard matrix of the final map by tracing the standard vectors as they change via your choice. \item The final map is a composition of three linear transformations. Find its standard matrix by multiplying the corresponding matrix for each map. Pay attention to the order of multiplication.  \end{enumerate}}
][ch2-CON-lintranscomp]
    [Correctly computes the standard matrix of the composite linear map.*This is done either by: tracing the standard vectors or by finding the matrix representation for each linear map and then multiplying the three matrices together.*]
    \begin{enumerate}
        \item Let's put $R$, $L$ and $P$ for associate matrices of rotation, reflection and projection respectively. Then we have the following six possibilities: $PLR, LPR, RPL, PRL, RLP, LRP$. 

        \item Below, we will see that indeed the order of composition matters. This can be attributed to the fact that generally, matrices do not commute. That is, we cannot guarantee that $AB = BA$.  

        \item Find the image of standard vectors geometrically. We demonstrate the case where we select PLR (i.e., rotation, reflection, then projection). 
	$$\begin{array}{ccccccc}
	   \vec e_1  & \overset{R}{\longrightarrow}    &\begin{bmatrix} 0 \\ 1 \end{bmatrix} &\overset{L}{\longrightarrow} &\begin{bmatrix} 1 \\ 0 \end{bmatrix} & \overset{P}{\longrightarrow} &\begin{bmatrix} \frac{1}{2} \\ -\frac{1}{2} \end{bmatrix} \\ \\
	     \vec e_2  & \overset{R}{\longrightarrow}    &\begin{bmatrix} -1 \\ 0 \end{bmatrix} &\overset{L}{\longrightarrow} &\begin{bmatrix} 0 \\ -1 \end{bmatrix} & \overset{P}{\longrightarrow} &\begin{bmatrix} \frac{1}{2} \\ -\frac{1}{2} \end{bmatrix}
	\end{array}$$
        Visualizations \href{https://www.desmos.com/calculator/uixbjn2wdc}{here}. Thus, we get that $T$ is given by following matrix.
        $$\begin{bmatrix}  \frac{1}{2} &  \frac{1}{2} \\  -\frac{1}{2} &  -\frac{1}{2} \end{bmatrix} = \frac{1}{2}\begin{bmatrix} 1 & 1 \\ -1 & -1 \end{bmatrix}$$
	
        \item
        Note that we can determine $R, L$ and $P$ using the following.
        $$R = \begin{bmatrix} \vert & \vert \\ R(\vec e_1) & R(\vec e_2) \\ \vert & \vert \end{bmatrix} \quad L = \begin{bmatrix} \vert & \vert \\ L(\vec e_1) & L(\vec e_2) \\ \vert & \vert \end{bmatrix} \quad P = \begin{bmatrix} \vert & \vert \\ P(\vec e_1) & P(\vec e_2) \\ \vert & \vert \end{bmatrix}$$
        Using matrix multiplication, we obtain the following.
        \begin{align*}
            PLR     &= \frac{1}{2}\begin{bmatrix} 1 & 1 \\ -1 & -1 \end{bmatrix} \\
            LPR     &= \frac{1}{2}\begin{bmatrix} 1 & 1 \\ -1 & -1 \end{bmatrix} \\
            PRL     &= \frac{1}{2}\begin{bmatrix} -1 & -1 \\ 1 & 1 \end{bmatrix} \\
            LRP     &= \frac{1}{2}\begin{bmatrix} 1 & -1 \\ 1 & -1 \end{bmatrix} \\ 
            RPL     &= \frac{1}{2}\begin{bmatrix} -1 & 1 \\ -1 & 1 \end{bmatrix} \\
            RLP     &= \frac{1}{2}\begin{bmatrix} -1 & 1 \\ -1 & 1 \end{bmatrix}
        \end{align*}
  \end{enumerate}
\end{SaveQuestion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{SaveQuestion}[
        key=ch2-injsur-examples5-dev,
        prompt={For any 4 of the 6 linear mappings below, state whether it is injective, surjective, and/or invertible and give a 1-2 sentence justification of your choice. If it is invertible, give the inverse map. Note: You are not required to find the matrix of each inverse, a description of the map in the same detail the original map was given will suffice. 
        \begin{enumerate} 
        \item The linear mapping $\mathbb{R}^3 \rightarrow \mathbb{R}^3$ which scales every vector by $2$. 
        \item The linear mapping $\mathbb{R}^3 \rightarrow \mathbb{R}^3$ which rotates every vector by $\theta$ around the $x$-axis. 
        \item The mapping  $\mathbb{R}^2 \rightarrow \mathbb{R}^2$  defined by projection onto a line $L$ that goes through the origin.
        \item The mapping $T\left(\begin{bmatrix}
            x \\ y \\ z
        \end{bmatrix} \right) = \begin{bmatrix}
            x \\ y
        \end{bmatrix} $
        \item The mapping $T\left( \begin{bmatrix}
            x \\ y
        \end{bmatrix} \right) = \begin{bmatrix}
            x \\ 0 \\ y
        \end{bmatrix}$
        \item The shear $\mathbb{R}^2 \rightarrow \mathbb{R}^2$  defined by multiplication by the matrix $\begin{bmatrix} 1 & 5 \\ 0 & 1 \end{bmatrix}.$ What is the matrix of the inverse map? \end{enumerate}}
][ch2-COM-inv,ch2-CON-surinj]
    [Satisfactory: Correct answer and any justification as to why the example is injective/surjective/invertible.*Can Be Improved: Incorrect answer with attempted justification or correct answer with no justification.*Try Again: Anything less than can be improved.*Hint 1: Check the definitions page on the tutorial worksheet and reference them in your solution.*Hint 2: Think of two vectors that project to the same output for statements 3/4/5.*Hint 3: Use the super-augmented matrix in order to find the inverse of the matrix in statement 6.*]
    Hint 1: Check the definitions page on the tutorial worksheet and reference them in your solution.\\
    Hint 2: Think of two vectors that project to the same output for statements 3/4/5. \\
    Hint 3: Use the super-augmented matrix in order to find the inverse of the matrix in statement 6.
    \begin{enumerate}
        \item The linear map that scales every vector by 2 is injective and surjective (and thus, bijective). Consequently, we may also claim that it is invertible, with the inverse map scaling vectors by 1/2. This is given by the following matrix.
        $$\begin{bmatrix} \frac{1}{2} & 0 & 0 \\ 0 & \frac{1}{2} &0 \\ 0 & 0 & \frac{1}{2}\end{bmatrix}$$

        \item The linear map that rotates every vector by $\theta$ around the $x$-axis is injective and surjective (and thus, bijective). Consequently, we may also claim that it is invertible, with the inverse map rotating vectors by $-\theta$ along the $x$-axis. This is given by the following matrix.
        $$\begin{bmatrix} 1 & 0 & 0 \\ 0 & \cos(-\theta) &-\sin(-\theta) \\ 0 &\sin(-\theta) & \cos(-\theta)\end{bmatrix}$$

        \item This mapping is neither injective or surjective, and therefore not invertible. Consider the orthogonal line $L_0 \subseteq \mathbb{R}^2$ that passes through the origin. All the vectors on the line $L_0$ will project to the same point in $L$, thus not injective. Moreover, the range of the map is $L$, which is a subset of $\mathbb{R}^2$, and thus cannot be surjective. Since the map is not both injective and surjective, it cannot be invertible as it is not bijective. 

        \item This map is surjective, but not injective. Consequently, this map is not bijective nor invertible. To see that the map is not injective, consider $x,y,z_1, z_2 \in \mathbb{R}$ such that $z_1 \neq z_2$. Then we have the following.
        $$T\left(\begin{bmatrix} x \\ y \\ z_1 \end{bmatrix}\right) = \begin{bmatrix} x \\ y \end{bmatrix} = T\left(\begin{bmatrix} x \\ y \\ z_2 \end{bmatrix}\right), \quad \text{ where } \begin{bmatrix} x \\ y \\ z_1 \end{bmatrix} \neq \begin{bmatrix} x \\ y \\ z_2 \end{bmatrix}$$
        To see that $T$ is surjective, consider that the $x$ and $y$ entries are mapped to themselves, we can deduce that any vector in $\mathbb{R}^2$ can be mapped to, thus surjective. 
        
        \item This map is injective, but not surjective. Consequently, this map is not bijective nor invertible. To see that this map is not surjective, consider the standard vector $\vec e_2 \in \mathbb{R}^3$. Since the second entry of the output is always zero, we cannot obtain $\vec e_2$ as an output of $T$. To see that $T$ is injective, consider $x_1, x_2, y_1, y_2 \in \mathbb{R}$.
        $$T\left(\begin{bmatrix} x_1 \\ y_1 \end{bmatrix}\right) = T\left(\begin{bmatrix} x_2 \\ y_2 \end{bmatrix}\right) \Longrightarrow \begin{bmatrix} x_1 \\ 0 \\ y_1 \end{bmatrix} = \begin{bmatrix} x_2 \\ 0 \\ y_2 \end{bmatrix} \Longrightarrow x_1 = x_2, y_1, y_2 \Longrightarrow \begin{bmatrix} x_1 \\ y_1 \end{bmatrix} = \begin{bmatrix} x_2 \\ y_2 \end{bmatrix}$$
        Thus, $T$ satisfies the definition of injective. 

        \item Notice that for any $\vec x, \vec y \in \mathbb{R}^2$, we have the following.
        $$\begin{bmatrix} 1 & 5 \\ 0 & 1 \end{bmatrix}\begin{bmatrix} x_1 \\ x_2 \end{bmatrix} = \begin{bmatrix} y_1 \\ y_2 \end{bmatrix} \Longrightarrow \begin{bmatrix} x_1 \\ x_2 \end{bmatrix} = \begin{bmatrix} y_1 - 5y_2 \\ y_2 \end{bmatrix}$$
        That is, we can map to any vector in the codomain (i.e., surjective) and each output is associated with a unique input (i.e., injective). Consequently, we may also claim that it is invertible, as it satisfies the definition of bijective, with the inverse map being the shear given by the following matrix.
        $$\begin{bmatrix} 1 & -5 \\ 0 & 1 \end{bmatrix}$$
    \end{enumerate}
\end{SaveQuestion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{SaveQuestion}[
        key=ch2-injsur-rephrase-sbg,
        prompt={For a {\bf linear transformation }  $\phi:\mathbb{R}^n \rightarrow \mathbb{R}^m$ we can say \begin{enumerate} \item[]{$\bullet$}  $\phi$ is surjective if and only if for all $\vec y$ in the target, the equation $\phi (\vec x) = \vec y$ has at least one solution, and \item[]{$\bullet$}  $\phi$ is injective if and only if for all $\vec y$ in the target, the equation $\phi (\vec x) = \vec y$ has at most one solution, and \item[]{$\bullet$}  $\phi$ is bijective  if and only if for all $\vec y$ in the target, the equation $\phi (\vec x) = \vec y$ has exactly  one solution. \end{enumerate} Make sure you understand how the bullet points above are equivalent to the definitions of surjective, injective, and bijective. Rephrase the three bullet points in terms of solving a system of linear equations involving the matrix of $\phi$.}
][ch2-CON-surinj] %this is written as a comma seperated list with no spaces between commas
    %[<rubric items>]    %this is written as a comma seperated list with no spaces between commas
    %[<items mark>]      %this is written as a comma seperated list with no spaces between commas
    Let $A$ be the matrix of $T$. 
    \begin{enumerate}
        \item[]{$\bullet$} Then $T$ is surjective if and only if for all $\vec y \in \mathbb{R}^n$, the system of linear equations $A \vec x = \vec y$ has at least one solution (ie. is consistent). 
        \item[]{$\bullet$} Then $T$ is injective if and only if for all $\vec y \in \mathbb{R}^n$, the system of linear equations $A \vec x = \vec y$ has at most one solution. 
        \item[]{$\bullet$} Then $T$ is invertible if and only if for all $\vec y \in \mathbb{R}^n$, the system of linear equations $A \vec x = \vec y$ has exactly one solution.
    \end{enumerate}
\end{SaveQuestion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{SaveQuestion}[
        key=ch2-lintrans-rowredsurj-sbg,
        prompt={Let $T:\mathbb{R}^3 \rightarrow \mathbb{R}^3$ be the linear transformation given by left multiplication by $\begin{bmatrix} 1  & 4 & 1 \\ 0 & 1 & 1\\ 0 &  1&1  \end{bmatrix}.$ Use row-reduction to determine whether or not there is an vector $\vec x$ such that $T(\vec x) = \begin{bmatrix} 0\\ 2 \\ 1  \end{bmatrix}.$}
][ch2-CON-surinj] %this is written as a comma seperated list with no spaces between commas
    [Correctly identifies that the vector [0, 1, 2] is not in the image space of T.*States that T is, at least, not surjective.*Conveys a correct understanding of surjectivity through their justification (the image space is not equivalent to the codomain).*]    %this is written as a comma seperated list with no spaces between commas
    %[<items mark>]      %this is written as a comma seperated list with no spaces between commas
    We want to know whether or not there is an $\vec x =  \begin{bmatrix} x_1\\ x_2 \\ x_3  \end{bmatrix}$ such that $T( \begin{bmatrix} x_1\\ x_2 \\ x_3  \end{bmatrix}) =  \begin{bmatrix} 0\\ 2 \\ 1  \end{bmatrix}.$ That is, we want to know if the system 
			$$  A \begin{bmatrix} x_1\\ x_2 \\ x_3  \end{bmatrix} =  \begin{bmatrix} 0\\ 2 \\ 1  \end{bmatrix}
			$$
			has a solution or not. 
			The augmented matrix is 
			$\begin{bmatrix} 1  & 4 & 1 & 0 \\ 0 & 1 & 1 & 2 \\ 0 &  1&1 & 1 \end{bmatrix},$ 
			which can be row-reduced to   $\begin{bmatrix} 1  & 4 & 1 & 0 \\ 0 & 1 & 1 & 2 \\ 0 &  0& 0 & -1 \end{bmatrix}$ by replacing row 3 by "row 3 minus row 2".  This is not yet in row reduce echelon form, but already we see that we have an inconsistent system, since the last row stands for the equation $0x_1 + 0 x_2 + 0x_3 = -1$, which obviously has no solutions. So there is no solution to this system, and this means there is no $\vec x$ such that $T(\vec x) =  \begin{bmatrix} 0\\ 2 \\ 1  \end{bmatrix}.$ This means that  $\begin{bmatrix} 0\\ 2 \\ 1  \end{bmatrix}$ is not in the image of $T$ and that $T$ is not surjective.
\end{SaveQuestion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{SaveQuestion}[
        key=ch2-injsur-truefalse-sbg,
        prompt={State whether each of the following statements is True or False. For a linear transformation $T:\mathbb{R}^n \rightarrow \mathbb{R}^m$ given by $T(\vec x)=A\vec x$ we can say \begin{enumerate} \item  $T$ is surjective if and only if for all $\vec y$ in the codomain, the equation $A \vec x = \vec y$ has at least one solution. \item $T$ is injective if and only if for all $\vec y$ in the codomain, the equation $A\vec x = \vec y$ has at most one solution. \item $T$ is bijective if and only if for all $\vec y$ in the codomain, the equation $A\vec x = \vec y$ has exactly one solution. 
        % \item Let $T:\mathbb{R}^3 \rightarrow \mathbb{R}^3$ be the linear transformation given by left multiplication by $\begin{bmatrix} 1  & 4 & 1 \\ 0 & 1 & 1\\ 0 &  1&1  \end{bmatrix}.$. Use your knowledge about solution types of a linear system to decide whether $T$ is injective, surjective and/or bijective. Justify your answer.
        \item Consider the Linear transformation $T:\bbR^3\to \bbR^4$ given by $T(\vec x) = A \vec x$ where we have the following.
        $$A= \begin{bmatrix} 1 & 1 & 1 \\ -1 & 0 & 1 \\ 2 & -1 & 0 \\ 2 & 0 & 2 \\ \end{bmatrix} \quad \rref(A) = \begin{bmatrix} 1 & 1 & 1\\ 0 & 1 & 2\\ 0 & 0 & 1\\ 0 & 0 & 0\\ \end{bmatrix}$$ \begin{enumerate} \item Is $T$ surjective, why? If not, can you give an example of a vector in the codomain which can not be reached by $T$ (Hint: $\rank(T) = \text{ \# pivots in } \rref(A)$).  \item Is $T$ injective, why? If not, give an example of two different input vectors that are mapped to the same output. \item Is $T$ bijective, why? \item Is $T$ invertible, why? \end{enumerate}
        \end{enumerate}}
][ch2-CON-surinj]
    [Correctly identifies whether the linear transformation T is surjective/injective/bijective/invertible and includes a justification in the form of a counterexample or proof.*]
    \begin{enumerate}
	\item True. This follows from the definition of surjectivity (or onto). \\ \\
        Assume that $T$ is surjective. Then by definition, for all $\vec y \in \mathbb{R}^m$ there exists $\vec x \in \mathbb{R}^n$ such that $\vec y = T(\vec x)$. Since $T(\vec x) = A\vec x$, we have that $\vec y = A\vec x$. That is, for each $\vec y$ in the codomain, there is at least one solution to $A \vec x = \vec y$. 
        Assume that for all $\vec y$ in the codomain, the equation $A \vec x = \vec y$ has at least one solution. Since $A$ induces the transformation $T$, we have that $T(\vec x) = A\vec x$, we have that there is at least one solution to $T(\vec x) = \vec y$. That is, for all $\vec y \in \mathbb{R}^m$ there exists $\vec x \in \mathbb{R}^n$ such that $\vec y = T(\vec x)$, which by definition means $T$ is surjective. \\ \\
        Hence, $T$ is surjective if and only if for all $\vec y$ in the codomain, the equation $A \vec x = \vec y$ has at least one solution.
        
        \item True. This follows from the definition of injectivity (or one-to-one). \\ \\
        Assume that $T$ is injective. Then by definition, for all $\vec x_1, x_2 \in \mathbb{R}^n$ it must be that $T(x_1) = T(x_2) \Longrightarrow x_1 = x_2$. Consider that for any $\vec y$ in the codomain, if there exists $\vec x \in \mathbb{R}^n$ satisfying $T(\vec x) = \vec y$, then $\vec x$ is the only solution to $A \vec x = T(\vec x) = \vec y$. If such a vector $\vec x$ does not exist, then there are no solutions to $A \vec x = T(\vec x) = \vec y$. Hence, there can be at most one solution to the system $A \vec x = \vec y$. 
        Assume that for all $\vec y$ in the codomain, the equation $A\vec x = \vec y$ has at most one solution. That is, for any $\vec y \in \mathbb{R}^m$, if there exist $\vec x \in \mathbb{R}^n$ such that $T(\vec x) = A\vec x = \vec y$, this output must be unique. That is, $T(x_1) = T(x_2) \Longrightarrow x_1 = x_2$, which by definition means $T$ is injective. \\ \\
        Hence, $T$ is injective if and only if for all $\vec y$ in the codomain, the equation $A\vec x = \vec y$ has at most one solution.
        
        \item True. This follows from parts (a) and (b). \\ \\
        Assume that $T$ is bijective. Then $T$ is both injective and surjective. From (a), we know that for all $\vec y$ in the codomain, the equation $A \vec x = \vec y$ has at least one solution, and from (b), we know that for all $\vec y$ in the codomain, the equation $A\vec x = \vec y$ has at most one solution. If every vector $\vec y$ in the codomain has both at least one solution and at most one solution to the equation $A\vec x = \vec y$, then it must be that the equation $A\vec x = \vec y$ has exactly one solution.
        Assume that for all $\vec y$ in the codomain, the equation $A\vec x = \vec y$ has exactly one solution. Then equivalently, for any $\vec y$ in the codomain, the equation $A\vec x = \vec y$ has at least one solution and at most one solution. Using (a) and (b), this means that $T$ is both surjective and injective, which further implies that $T$ is bijective. \\ \\
        Hence, $T$ is bijective if and only if for all $\vec y$ in the codomain, the equation $A\vec x = \vec y$ has exactly one solution.

        \item \begin{enumerate}
            \item False. Using the hint, we obtain that $\rank(T) = 3 < 4 = \dim(\mathbb{R}^4)$, it cannot be that every $\vec y$ in the codomain, the equation $A \vec x = \vec y$ has at least one solution. From (1), it cannot be that $T$ is surjective.  
            \item True. Since every column is a pivot, it must be that for every $\vec y$ in the codomain, the equation $A \vec x = \vec y$ has at most one solution. From (2), it must be that $T$ is injective. 
            \item False. Since $T$ is not surjective, it cannot be bijective.
            \item False. Since $T$ is not bijective, it cannot be invertible.
        \end{enumerate}
	\end{enumerate}
\end{SaveQuestion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{SaveQuestion}[
        key=ch2-injsur-3to4-sbg,
        prompt={Consider the Linear transformation $T:\bbR^3\to \bbR^4$ given by $T(\vec x) = A \vec x$ where \\ $A= \begin{bmatrix} 1 & 1 & 1 \\ -1 & 0 & 1 \\ 2 & -1 & 0 \\ 2 & 0 & 2 \\ \end{bmatrix}$ with REF$(A) = \begin{bmatrix} 1 & 1 & 1\\ 0 & 1 & 2\\ 0 & 0 & 1\\ 0 & 0 & 0\\ \end{bmatrix}$. \begin{enumerate} \item Is $T$ injective, why? If not, give an example of two different input vectors that are mapped to the same output. \item Is $T$ surjective, why? If not, can you give an example of a vector in the codomain which can not be reached by $T$. \item Is $T$ bijective, why? \item Is $T$ invertible, why? \end{enumerate}}
][ch2-CON-surinj] %this is written as a comma seperated list with no spaces between commas
    %[<rubric items>]    %this is written as a comma seperated list with no spaces between commas
    %[<items mark>]      %this is written as a comma seperated list with no spaces between commas
    \begin{enumerate}
            \item Yes since the Rank of $A$ is equal to the number of columns of $A$. That is there is a pivot in every column. Hence $A\vec x=\vec 0$ has a unique solution, or $A\vec x=\vec y$ has at most one solution for any $\vec y$. 
            \item No. Not every row has a pivot. That is there exists a $\vec y$ in the codomain for which $RREF[A|\vec y]$ has a pivot in the augmented column. It is not easy (but possible) to find an example of a vector that can not be mapped. To do so, you can augment $RREF(A)$ with $\vec e_4$. Note that this gives an inconsistent system. Then row reduces back to find a  $\vec y$ in the codomain that makes the system $A\vec x=\vec b$ inconsistent. 
            \item No because it is not sujective
            \item No because it is not bijective. 
        \end{enumerate}
\end{SaveQuestion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{SaveQuestion}[
        key=ch2-matrix-examples6-sbg,
        prompt={Find an example of a $2 \times 2$ matrix A with the given properties for any 4 of the 6 statements below. Think of the underlying linear transformation geometrically. Include a drawing of the effect of $A$ on the standard vectors $e_1$ and $e_2$. Note: Whenever a question asks for a drawing it must be clearly labelled and easy to read, make sure to label both the input and output vectors. \begin{enumerate} \item $A \neq I_2, A^2 = I_2 $ \item $A^2 \neq I_2, A^4 = I_2$  \item $A^2 \neq I_2, A^3 = I_2$  \item $A^2 = A$, all entries of A are nonzero. \item $A^3 =A$, all entries of A are nonzero. \item $A^{10} = \begin{bmatrix} 1 & 1 \\0 & 1 \\ \end{bmatrix}$ \end{enumerate} }
][ch2-VG-comp,chg-CON-exp] %this is written as a comma seperated list with no spaces between commas
    [A drawing that shows their geometrical understanding of why their example is correct*They may get the wrong matrix or transformation*,Correct matrix that satisfies the property*]    %this is written as a comma seperated list with no spaces between commas
    %[<items mark>]      %this is written as a comma seperated list with no spaces between commas
    \begin{enumerate}
        \item Any reflection matrix will work. \\
        $$A=
            \begin{bmatrix} 
	1 & 0 \\
	0 & -1 \\
	\end{bmatrix},
        A^2 =
            \begin{bmatrix} 
	1 & 0 \\
	0 & -1 \\
	\end{bmatrix}
             \begin{bmatrix} 
	1 & 0 \\
	0 & -1 \\
	\end{bmatrix}
        =
            \begin{bmatrix} 
	1 & 0 \\
	0 & 1 \\
	\end{bmatrix}$$
    \begin{center}
        \includegraphics[scale=0.2]{Question Photos/IMG_0942.png}
        \end{center}
    \item The $\pi / 2$ rotation matrix will work.
        \\
        $$A = 
        \begin{bmatrix} 
	\cos(\pi /2) & -\sin(\pi / 2) \\
	\sin(\pi / 2) & \cos(\pi / 2) \\
	\end{bmatrix}
        =
        \begin{bmatrix} 
	0 & -1 \\
	1 & 0 \\
	\end{bmatrix}, 
        A^2 =
        \begin{bmatrix} 
	-1 & 0 \\
	0 & -1 \\
	\end{bmatrix}, 
        A^4 = 
        \begin{bmatrix} 
	1 & 0 \\
	0 & 1 \\
	\end{bmatrix}$$
 \begin{center}
        \includegraphics[scale=0.2]{Question Photos/IMG_0943.png}
        \end{center}
    \item The $2\pi / 3$ rotation matrix will work. \\
        $$A=
        \begin{bmatrix} 
	\cos(2\pi / 3) & -\sin(2\pi /3) \\
	\sin(2\pi /3) & \cos(2\pi /3) \\
	\end{bmatrix}
        = \frac{1}{2}
        \begin{bmatrix} 
	-1 & -\sqrt{3} \\
	\sqrt{3} & -1 \\
	\end{bmatrix},
        A^2 = \frac{1}{2}
        \begin{bmatrix} 
	-1 & \sqrt{3} \\
	-\sqrt{3} & -1 \\
	\end{bmatrix},
        A^3 = 
        \begin{bmatrix} 
	1 & 0 \\
	0 & 1 \\
	\end{bmatrix}$$
 \begin{center}
        \includegraphics[scale=0.2]{Question Photos/IMG_0944.png}
        \end{center}
    \item Any projection matrix with all nonzero entries will work. \\
        If we choose unit vector $\vec{u} = 
        \begin{bmatrix} 
	\frac{1}{\sqrt{2}} \\
	\frac{1}{\sqrt{2}} \\
	\end{bmatrix}$
        the projection matrix will be 
        $$A = 
        \begin{bmatrix} 
	\frac{1}{2} & \frac{1}{2} \\
	\frac{1}{2} & \frac{1}{2} \\
	\end{bmatrix},
        A^2 = 
        \begin{bmatrix} 
	\frac{1}{2} & \frac{1}{2} \\
	\frac{1}{2} & \frac{1}{2} \\
	\end{bmatrix} = A$$
    \begin{center}
        \includegraphics[scale=0.2]{Question Photos/IMG_0945.png}
        \end{center}
    \item  Any reflection matrix with all nonzero entries works, or any projection matrix with all nonzero entries like the one above. \\
        $$A = 
        \begin{bmatrix} 
	\frac{1}{2} & \frac{1}{2} \\
	\frac{1}{2} & \frac{1}{2} \\
	\end{bmatrix},
        A^2 = 
        \begin{bmatrix} 
	\frac{1}{2} & \frac{1}{2} \\
	\frac{1}{2} & \frac{1}{2} \\
	\end{bmatrix} = A,$$
        $$A^3 = A^2A = AA = A^2 = A.$$
        \begin{center}
        \includegraphics[scale=0.2]{Question Photos/IMG_0945.png}
        \end{center}
    \item  $A^{10}=
        \begin{bmatrix} 
	1 & 1 \\
	0 & 1 \\
	\end{bmatrix}$ is a horizontal shear matrix. Since the shears add up when applied multiple times we can choose the $\frac{1}{10}$ shear matrix.
        $$A = 
        \begin{bmatrix} 
	1 & \frac{1}{10} \\
	0 & 1 \\
	\end{bmatrix}, 
        A^2 = 
        \begin{bmatrix} 
	1 & \frac{2}{10} \\
	0 & 1 \\
	\end{bmatrix}, ... ,
        A^{10} = 
        \begin{bmatrix} 
	1 & \frac{10}{10} \\
	0 & 1 \\
	\end{bmatrix} =
        \begin{bmatrix} 
	1 & 1 \\
	0 & 1 \\
	\end{bmatrix}$$
 \begin{center}
        \includegraphics[scale=0.2]{Question Photos/IMG_0946.png}
        \end{center}
    \end{enumerate}
\end{SaveQuestion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%THIS QUESTION NEEDS SOME MORE STANDARDS FOR CONNECTING SURJECTIVITY AND RANK
\begin{SaveQuestion}[
        key=ch2-lintrans-3to3plane-dev,
        prompt={Consider $T:\bbR^3\to\bbR^3$ given by $T(\vec x) = \begin{bmatrix}x_1 + x_2 + x_3\\ x_2\\ x_1 + x_3\end{bmatrix}$. 
        \begin{enumerate} 
        \item Is $T$ linear? If so, what is the matrix $A$ that induces $T$? Why do you think some people call the matrix $A$ the ``coefficient matrix" of $T$? 
        \item What are the domain and codomain of $T$?  
        \item Explain why $\vec b \in \mathbb{R}^3$ is in the image of $T$ if and only if the system of linear equations $A \vec x = \vec b$ is consistent. Hint: What is the definition of image?
        \item The image of $T$ is the set $\{T(\vec x) \ | \ \vec x \in \mathbb{R}^3\}$. For this linear transformation, this set defines a plane in $\mathbb{R}^3$. Find the equation of this plane in normal form. Use what you know about solving linear equations and row reduction. 
        \item Is $T$ invertible? Is its matrix invertible?
        \end{enumerate} }
][ch2-CON-lintranscheck,ch2-CON-domcodom] %this is written as a comma seperated list with no spaces between commas
    [Uses the definition from PCE4 for a linear transformation to prove T is linear.*Correctly identifies the domain (source) and codomain (target) of the map T.*Justifies the iff statement in both directions making reference to linear combinations and the column space and the solution set to the non-homogeneous system.*The correct equation of the plane is written in normal form.*Correctly identifies that T is not invertible and demonstrates understanding of what it means to be invertible.*Hint 1: Justify an iff statement; there are two implications to show here.*Hint 2: What does it mean for vector b to be in the image of T? (Answer: it is a possible output).*Hint 3: Is there a connection between vector b being a possible output and Ax = b being consistent?*]    %this is written as a comma seperated list with no spaces between commas
    %[<items mark>]      %this is written as a comma seperated list with no spaces between commas
    \begin{enumerate}
        \item Yes, $T$ is linear since it can be induced by a matrix. The coefficient matrix of $T$ is $A = \begin{bmatrix} 1 & 1 & 1 \\ 0 & 1 & 0 \\ 1 & 0 & 1 \end{bmatrix}$. 
        
        We call $A$ the coefficient matrix of $T$ since the entries of $A$ correspond to the coefficients of variables used to define $T$. 
        
        \item Since $T$ maps vectors in $\mathbb{R}^3$ to vectors in $\mathbb{R}^3$, both it's domain and codomain are $\mathbb{R}^3$. 
        
        \item Recall that the image of $T$ is defined as the set $\im(T) = \{T(\vec x) \ | \ \vec x \in \mathbb{R}^3\}$. To show that $\vec b \in \mathbb{R}^3$ is in the image of $T$ if and only if the system of linear equations $A \vec x = \vec b$ is consistent, we show that each implication implies the other. \\ \\
        Assume that $\vec b \in \im(T)$. Then there exists $\vec x \in \mathbb{R}^3$ such that $T(\vec x) = \vec b$. Noticing that $A$ induces $T$, we have $A\vec x = T(\vec x) = \vec b$. Hence, the system $A \vec x = \vec b$ is consistent. \\ \\
        Similarly, assume that the system $A \vec x = \vec b$ is consistent. Then there exists $\vec x \in \mathbb{R}^3$ such that $A\vec x = \vec b$. Since $A$ induces $T$, we have that $T(\vec x) = A\vec x$. Therefore, it must be that $\vec b = A\vec x \in \im(T)$. Hence, $\vec b$ is in the image of $T$. \\ \\
        Therefore, we have shown that $\vec b \in \mathbb{R}^3$ is in the image of $T$ if and only if the system of linear equations $A \vec x = \vec b$ is consistent, as needed. 
        
        \item The image is any vector $T(\vec x)$ in $\mathbb{R}^3$; this will be any vector of the form  $\vec b = \begin{bmatrix} x_1 + x_2 + x_3 & x_2 & x_1 +
		x_3\end{bmatrix}^T$. Thus the image will be any $\vec b$ for which we can find an $x_1$, $x_2$ and $x_3$ solving this equality. Row reducing the augmented matrix, we have the following.
		$$\begin{amatrix}{3} 1 & 1 & 1 & {b_1} \\ 0 & 1 & 0 & {b_2} \\ 1 & 0 & 1 & b_3 \end{amatrix} \longrightarrow \begin{amatrix}{3} 1 & 0 & 1 & {b_1 - b_2} \\ 0 & 1 & 0 & {b_2} \\ 0 & 0 & 0 & {b_3 - b_1 + b_2} \end{amatrix}$$
        From this, we see that $0 = -b_1 + b_2 + b_3$, which described the plane in $\mathbb{R}^3$ that passes through the origin and has a normal vector $\begin{bmatrix} -1 \\ 1 \\ 1 \end{bmatrix}$. 
        
        \item We know that $T$ is not invertible since the $T$ is not injective (one-to-one). Consider that for any $k \in \mathbb{R}$, we have the following.
        $$T\left(\begin{bmatrix} k \\ 0 \\ -k \end{bmatrix}\right) = \begin{bmatrix} k + 0 + (-k) \\ 0 \\ k + (-k) \end{bmatrix} = \vec 0$$
        Since there are multiple inputs that share the same output, it cannot be that $T$ is invertible. Furthermore, if a linear transformation is not invertible, it's coefficient matrix cannot be invertible either. 
    \end{enumerate}
\end{SaveQuestion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{SaveQuestion}[
        key=ch3-linearind-definitions-dev,
        prompt={Warm-Up: You should know the definitions of the following terms word by word from your PCE readings. Recite the definitions in your group. \begin{enumerate} \item Kernel and image of a linear transformation \item Injective, surjective and invertible linear transformations \item A subspace of $\mathbb{R}^n$. \item A spanning set for a subspace of $\mathbb{R}^n$. \item A redundant vector in a given set of vectors \item A set of linearly independent vectors in a subspace $V$ \item A set of linearly dependent vectors in a subspace $V$ \end{enumerate} }
][chg-WRIT-matcom] %this is written as a comma seperated list with no spaces between commas
    %[<rubric items>]    %this is written as a comma seperated list with no spaces between commas
    %[<items mark>]      %this is written as a comma seperated list with no spaces between commas
    Check the textbook/definition document
\end{SaveQuestion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{SaveQuestion}[
        key=ch3-kerim-injkerandsurimv1-sbg,
        prompt={\textbf{Theorem} A linear transformation is injective if and only if its kernel is trivial. \\ \textbf{Theorem} A linear transformation is surjective if and only if it image is equal to its codomain. \vspace{0.5 cm} \begin{enumerate} \item Given a linear transformation $T:\mathbb{R}^m\to \mathbb{R}^n$, carefully write down the definition of the terms: kernel of $T$, image of $T$, injective and surjective, subspace and a spanning set and a basis for a subspace. \item What does trivial mean in the above theorem? Write it mathematically. \item Choose one of the two linear transformations to answer the questions below. $$T: \mathbb{R}^2 \rightarrow \mathbb{R}, T\left(\begin{bmatrix} x_1 \\ x_2 \end{bmatrix}\right) = x_1 + 2x_2 \quad T: \mathbb{R}^3 \rightarrow \mathbb{R}^3, T \left(\begin{bmatrix} x_1 \\ x_2 \\ x_3 \end{bmatrix}\right) = \begin{bmatrix} x_1 + x_2 \\ x_2 + x_3 \\ x_3 + x_1 \end{bmatrix}$$ \begin{enumerate} \item Find image and kernel of the linear transformation. Can you give a spanning set for the image and kernel? \item Is your spanning set linearly independent? \item Is your spanning set a basis for the corresponding subspace? \item Use the Theorems above to decide whether the map is injective, surjective or invertible. \end{enumerate} \end{enumerate}}
][ch3-CON-injkersurim,chg-WRIT-matnot]
    [Correct kernel and image*Correct connections*Correct injective surjective decision*,Correct notation for span null space column space kernel and image*] 
    \begin{enumerate}
        \item Here are the necessary definitions.
        \begin{itemize}
            \item[kernel of $T$] The kernel of a linear transformation $T: \mathbb{R}^m \rightarrow \mathbb{R}^n$ is the set of all vectors in the domain that map to the zero vector of the codomain. 
            $$\ker(T) = \{\vec x \in \mathbb{R}^m \ | \ T(\vec x) = \vec 0\}$$
            \item[image of $T$] The image of a linear transformation $T: \mathbb{R}^m \rightarrow \mathbb{R}^n$ is the set of all vectors in the codomain that the map can output.
            $$\im(T) = \{\vec y \in \mathbb{R}^n \ | \ T(\vec x) = \vec y, \text{ for some } \vec x \in \mathbb{R}^m\}$$
            \item[injective] We say a linear transformation $T: \mathbb{R}^m \rightarrow \mathbb{R}^n$ is injective if for all $\vec x_1, \vec x_2 \in \mathbb{R}^m, T(\vec x_1) = T(\vec x_2) \Longrightarrow x_1 = x_2$. That is, every output corresponds to a unique input. 
            \item[surjective] We say a linear transformation $T: \mathbb{R}^m \rightarrow \mathbb{R}^n$ is surjective if for all $\vec y \in \mathbb{R}^n$ there exists $\vec x \in \mathbb{R}^m$ such that $T(\vec x) = \vec y$. 
            \item[subspace] A subspace is a subset of a Euclidean space that contains the zero vector, is closed under addition, and is closed under scalar multiplication. 
            \item[spanning set] A spanning set is a set that spans a given subspace. 
            \item[basis] A basis of a subspace is a linearly independent set that spans the subspace.
        \end{itemize}
        \item In the theorem above, trivial means that only the zero vector is in the kernel. We say the kernel is trivial when it only contains the zero vector since any linear transformation necessarily maps the zero vector of the domain to the zero vector of the codomain. 
        \item 
        \begin{itemize}
            \item[] $T: \mathbb{R}^2 \rightarrow \mathbb{R}$ \\
            \item[(a)] The image of $T$ is $\mathbb{R}$ and the kernel of $T$ is $\spn\left(\left\{\begin{bmatrix} -2 \\ 1 \end{bmatrix}\right\}\right)$.
            \item[(b)]
            \item[(c)]
            \item[(d)] Since the kernel is not trivial, $T$ cannot be injective. Conversely, the image of $T$ is its codomain, so $T$ is surjective. 
            \item[] $T: \mathbb{R}^3 \rightarrow \mathbb{R}^3, T \left(\begin{bmatrix} x_1 \\ x_2 \\ x_3 \end{bmatrix}\right) = \begin{bmatrix} x_1 + x_2 \\ x_2 + x_3 \\ x_3 + x_1 \end{bmatrix}$ \\
            \item[(a)] The image of $T$ is $\mathbb{R}$ and the kernel of $T$ is $\{\vec 0\}$.
            \item[(b)]
            \item[(c)]
            \item[(d)] Since the kernel is trivial $T$ is injective. Moreover, the image of $T$ is its codomain, so $T$ is surjective. More generally, we claim that $T$ is bijective and consequently, invertible.  
        \end{itemize}
    \end{enumerate}
\end{SaveQuestion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{SaveQuestion}[
        key=ch3-kerim-injkerandsurimv2-sbg,
        prompt={\textbf{Theorem} A linear transformation is injective if and only if its kernel is trivial. \\ \textbf{Theorem} A linear transformation is surjective if and only if it image is equal to its codomain. \vspace{0.5 cm} \begin{enumerate} \item What does trivial mean in the above theorem? Write it mathematically. \item Find image and kernel of the following linear transformation. Can you give a spanning set for the image and kernel?  Is your spanning set linearly independent? Is it a basis for the corresponding subspace? Use the Theorems above to decide whether the map is injective, surjective or invertible. \begin{enumerate} \item $T:\bbR^3 \rightarrow \bbR^3$, $T\begin{bmatrix} x_1 \\ x_2 \\ x_3 \end{bmatrix} = \begin{bmatrix} x_1 +x_2  \\ x_2 +x_3 \\x_3 + x_1 \end{bmatrix}$.  \end{enumerate}\end{enumerate} }
][ch3-CON-injkersurim] %this is written as a comma seperated list with no spaces between commas
    %[<rubric items>]    %this is written as a comma seperated list with no spaces between commas
    %[<items mark>]      %this is written as a comma seperated list with no spaces between commas
    \begin{enumerate}
        \item Here trivial means $\{\vec 0\}$ and non trivial means a set that is strictly larger than $\{\vec 0\}$. 
        \item 
    \begin{enumerate}
        \item Standard matrix of $T$ is $A=\begin{bmatrix}
			1&1&0\\0&1&1\\1&0&1
			\end{bmatrix}$. Then $\mathrm{im} T=\mathrm{col} (A)=\mathrm{Sp}(\begin{bmatrix}
			1\\0\\1
			\end{bmatrix},\begin{bmatrix}
			1\\1\\0
			\end{bmatrix}, \begin{bmatrix}
			0\\1\\1 \end{bmatrix})$. 
            We see this span is $\mathbb{R}^3$ because the columns of $A$ are L.I. (row reduce A to see this) and there are three vectors in the spanning set. 
            Any $n$ L.I. set in an n dimensional space is a spanning set for that space. 
            Hence columns of $A$ span $\mathbb{R}^3$. 
            $\ker T= \mathrm{null}(A)=\{\vec 0\}$ 
            (row reduce $A$ to see this!). $T$ is injective and surjective. 
            Since the kernel of $T$ is trivial it is injective. 
            Since the image of $T$ is equal to the codomain $T$ is surjective.
    \end{enumerate}
    \end{enumerate}
\end{SaveQuestion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{SaveQuestion}[
        key=ch3-kerim-injkerandsurimv3-sbg,
        prompt={\textbf{Theorem} A linear transformation is injective if and only if its kernel is trivial. \\ \textbf{Theorem} A linear transformation is surjective if and only if it image is equal to its codomain. \vspace{0.5 cm} \begin{enumerate} \item What does trivial mean in the above theorem? Write it mathematically.  \item Of the seven types of linear transformations $T\colon \mathbb{R}^2\to\mathbb{R}^2$ given in 2.2 (scaling, orthogonal projection, reflection, rotation, rotation combined with scaling, horizontal shear, and vertical shear), which are injective? Which are surjective? Think geometrically, and give a justification using the above theorems (this does not need to be a rigorous proof) for your answers. \end{enumerate} }
][ch3-VG-imker] %this is written as a comma seperated list with no spaces between commas
    %[<rubric items>]    %this is written as a comma seperated list with no spaces between commas
    \begin{enumerate}
        \item Here trivial means $\{\vec 0\}$ and non trivial means a set that is strictly larger than $\{\vec 0\}$. 
        \item Scaling, reflection, rotation, rotation combine with nonzero scaling horizontal and vertical shears (as long as the scalar factors are nonzero) are bijections. Orthogonal projection is neither injective nor surjective. You can compute the kernel and image of each and verify using the theorems above.
    \end{enumerate}
\end{SaveQuestion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{SaveQuestion}[
        key=ch3-subspace-allsubspaces-sbg,
        prompt={\textbf{Definition:} A {\bf subspace} of $\mathbb{R}^n$ is a subset $W \subseteq \mathbb{R}^n$ such that \begin{enumerate} \item [(a)] $\vec 0\in W$ \item[(b)] if $\vec x, \vec y \in W$, then also $\vec x + \vec y \in W$; \item[(c)] if $\vec x  \in W$ and $k$ is any scalar, then  also $k\vec x \in W$. \end{enumerate} We will use this definition to answer the following questions. \begin{enumerate} \item Describe all the subspaces of $\mathbb{R}$, $\mathbb{R}^2$ and $\mathbb{R}^3$. Think Geometrically. Draw an example of each category of subspace in $\bbR^3$. \item Use the definition of a subspace to show that any line through the origin in $\mathbb{R}^n$ is a subspace of $\mathbb{R}^n$. \end{enumerate}}
][ch3-VG-subspace,ch3-CON-subspacecheck]
    [Complete description of all subspaces (correct)*Example drawing of all subspaces in R3*] 
    \begin{enumerate}
        \item Consider that for any $\mathbb{R}^n$, we may categorize the subspaces of $\mathbb{R}^n$ using their dimension. Moreover, for any $\mathbb{R}^n$, we necessarily have two trivial subspaces, these are, the sets $\{\vec 0\}$ and $\mathbb{R}^n$. 
        \begin{itemize}
            \item[$\mathbb{R}$]
            For $\mathbb{R}$, we know that there can only be two types of subspaces using the remark above. Primarily, the 0-dimensional subspace of $\mathbb{R}$ is given by $\{0\}$ and the 1-dimensional subspace of $\mathbb{R}$ is $\mathbb{R}$ itself. 
            \item[$\mathbb{R}^2$]
            For $\mathbb{R}^2$ we again remark that the 0-dimensional subspace of $\mathbb{R}^2$ is given by $\{\vec 0\}$ and the 2-dimensional subspace of $\mathbb{R}^2$ is $\mathbb{R}^2$ itself. Lastly, we know that the 1-dimensional subspace of $\mathbb{R}^2$ is a line through the origin. 
            \item[$\mathbb{R}^3$]
            For $\mathbb{R}^3$ we again remark that the 0-dimensional subspace of $\mathbb{R}^3$ is given by $\{\vec 0\}$ and the 3-dimensional subspace of $\mathbb{R}^3$ is $\mathbb{R}^3$ itself. Lastly, we know that the 1-dimensional subspace of $\mathbb{R}^3$ is a line through the origin and the 2-dimensional subspace of $\mathbb{R}^3$ is a plane through the origin.
        \end{itemize}
        \item We want to use the definition of a subspace to show that any line through the origin in $\mathbb{R}^n$ is a subspace of $\mathbb{R}^n$. \\ \\
        Recall that any line in $\mathbb{R}^n$ can be described as $L = \{\vec u \in \mathbb{R}^n \ | \ \vec u = t\vec d + \vec p, t \in \mathbb{R}\}$, where $\vec d, \vec p \in \mathbb{R}^n$. Assuming that $L$ passes through the origin, we may fix $\vec p = \vec 0$. We will now show that such a line $L$ satisfies the criteria (a) - (c) in the definition of subspace.
        \begin{enumerate}
            \item[(a)] Consider that $L = \{\vec u \in \mathbb{R}^n \ | \ \vec u = t\vec d, t \in \mathbb{R}\}$. Note that when $t = 0$, we obtain that $\vec u = 0 \vec d = \vec 0$ must be in $L$. Thus, we have that $\vec 0 \in L$. 
            \item[(b)] Let $\vec x, \vec y \in L$. Then we have that $\vec x = t_1 \vec d, \vec y = t_2 \vec d$ for some $t_1, t_2 \in \mathbb{R}$. Let us compute $\vec x + \vec y$. 
            $$\vec x + \vec y = t_1 \vec d + t_2 \vec d = (t_1 + t_2) \vec d$$
            Since $t_1 + t_2 \in \mathbb{R}$, it must be that $\vec x + \vec y = (t_1 + t_2)\vec d \in L$. As we selected $\vec x, \vec y$ arbitrarily, we may generally claim that for any $\vec x, \vec y \in L$, it holds that $\vec x, \vec y \in L \Longrightarrow \vec x + \vec y \in L$. 
            \item[(c)] Let $\vec x \in L$ and $k \in \mathbb{R}$. Then we have that $\vec x = t\vec d$ for some $t \in \mathbb{R}$. Let us compute $k \vec x$.
            $$k \vec x = k (t \vec d) = (kt) \vec d$$
            Since $kt \in \mathbb{R}$, it must be that $k \vec x = (kt) \vec d \in L$. As we selected $\vec x$ and $k$ arbitrarily, we may generally claim that for any $\vec x, k \in L \Longrightarrow k \vec x \in L$. 
        \end{enumerate}
        Hence, the line $L$ satisfies (a) - (c) it holds that $L$ is a subspace of $\mathbb{R}^n$. \\ \\
        Therefore, using the definition of a subspace we have shown that any line through the origin in $\mathbb{R}^n$ is a subspace of $\mathbb{R}^n$, as needed. 
    \end{enumerate}
\end{SaveQuestion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{SaveQuestion}[
        key=ch3-subspace-examples4-sbg,
        prompt={\textbf{Definition:} A {\bf subspace} of $\mathbb{R}^n$ is a subset $W \subseteq \mathbb{R}^n$ such that \begin{enumerate} \item [(a)] $\vec 0\in W$ \item[(b)] if $\vec x, \vec y \in W$, then also $\vec x + \vec y \in W$; \item[(c)] if $\vec x  \in W$ and $k$ is any scalar, then  also $k\vec x \in W$. \end{enumerate} \vspace{0.5cm} Decide whether each of the following sets is a subspace of $\bbR^2$. Justify your answer. \begin{enumerate} \item $\{(x,y) \in \bbR^2 \mid x^2+y^2 < 1\}$ \item  $\{(x,y) \in \bbR^2 \mid xy=0\}$ \item  $\{(x,y) \in \bbR^2 \mid x^2+y^2=0\} $ \item  $\{(x,y) \in \bbR^2 \mid x-y=0\} $  \end{enumerate}  }
][ch3-CON-subspacecheck,chg-WRIT-matcom] %this is written as a comma seperated list with no spaces between commas
    [Correct decision on 3 out of 4*,Clear justification using the definition given. Visual justification is acceptable*]    %this is written as a comma seperated list with no spaces between commas
    %[<items mark>]      %this is written as a comma seperated list with no spaces between commas  
        \begin{enumerate}
            \item No, It's not closed under scalar multiplication.
			Consider $\vec{v}=[0.5,0.5] \in \{(x,y) \in \bbR^2 \mid x^2+y^2 < 1\}$ and 
			$10\vec{v}=[5,5] \notin \{(x,y) \in \bbR^2 \mid x^2+y^2 < 1\}$
            \item No, It's not closed under vector addition.
			Consider $\vec{v}=[0,1],\vec{u}=[1,0] \in \{(x,y) \in \bbR^2 \mid xy=0\}$ and 
			$\vec{v}+ \vec{u}=[1,1]\notin  \{(x,y) \in \bbR^2 \mid xy=0\}$
            \item Yes. This set only has one element which is $\vec{0}=[0,0].$ This zero vector gives you a zero dimensional subspace.
            \item Yes, it's a line $y=x$ that pass the origin (This shows it is a nonempty set). The only non-trivial things that we need to prove is the closure properties.
			Let $\vec{u}=[t,t],\vec{v}=[p,p] \in \{(x,y) \in \bbR^2 \mid x-y=0\}$ and $\alpha \in \mathbb{R}.$
			Check the following.
			$$\vec{u}+\alpha\vec{v}=[t+\alpha p,t+\alpha p] \in \{(x,y) \in \bbR^2 \mid x-y=0\} $$
			It shows that it's closed under vector addition and scalar multiplication.
        \end{enumerate}
\end{SaveQuestion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{SaveQuestion}[
        key=ch3-linearind-r3span-dev,
        prompt={Theorem: The vectors $\vec v_1,\cdots, \vec v_n$ are \textbf{linearly independent} if the equation $$x_1\vec v_1+x_2\vec v_2+\cdots+x_n \vec v_n=\vec 0$$ has a unique solution: namely the trivial solution $x_1=x_2=\cdots=x_n=0$ \vspace{0.5 cm} \\ Definition: A \textbf{nontrivial linear relation} or a \textbf{dependency relation}  among $\vec v_1,\cdots, \vec v_n$  is an equation of the form $r_1\vec v_1+r_2\vec v_2+\cdots+r_n \vec v_n=\vec 0$, where at least one $r_i$ is nonzero. \vspace{0.5 cm} \\ Theorem: The vectors $\vec v_1,\cdots, \vec v_n$ are \textbf{linearly dependent} exactly when the vector equation $$x_1\vec v_1+x_2\vec v_2+\cdots+x_n \vec v_n=\vec 0$$ has infinitely many solution. Any nontrivial solution gives a \textbf{dependency relation} among the vectors.	\begin{enumerate} \item Are the following vectors linearly independent? why? \[ \vec v_1=	\begin{bmatrix} 0\\0\\2 \end{bmatrix}, 	\vec v_2=\begin{bmatrix} 0\\5\\-8 \end{bmatrix}, 	\vec v_3=\begin{bmatrix} -3\\4\\1 \end{bmatrix} \] \item If possible write a dependency relation between the given vectors or explain why this is not possible. \item Is there a redundant vector among these vectors? \item Is every vector in $\mathbb{R}^3$ in the $\mathrm {span}\{\vec v_1,\vec v_2,\vec v_3\}$? Describe $\mathrm {span}\{\vec v_1,\vec v_2,\vec v_3\}$ geometrically. \item Can we remove a vector from the set $\{\vec v_1,\vec v_2,\vec v_3\}$ without changing the subspace they span? If yes which one? If no why? \end{enumerate} }
][ch3-COM-linind,ch3-VG-span,ch3-COM-reduclinind,ch3-VG-redunvec] %this is written as a comma seperated list with no spaces between commas
    [Satisfactory: Correct answers with correct justification*,Can Be Improved: Some incorrect answers but only a few*Try Again: Misunderstanding of the question or lots of wrong answers*] 
    \begin{enumerate}
        \item Yes they are linearly independent. We will show that the only linear combination yielding the zero vector is the trivial one. Fix $\alpha_1, \alpha_2, \alpha_3 \in \mathbb{R}$. Notice that we have the following.
        $$\vec 0 = \alpha_1 \begin{bmatrix} 0 \\ 0 \\ 2 \end{bmatrix} + \alpha_2 \begin{bmatrix} 0 \\ 5 \\ -8 \end{bmatrix} + \alpha_3 \begin{bmatrix} -3 \\ 4 \\1 \end{bmatrix} = \begin{bmatrix} -3\alpha_3 \\ 5\alpha_2 + 4\alpha_3 \\ 2\alpha_1 - 8\alpha_2 + \alpha_3 \end{bmatrix} \Longrightarrow \alpha_3 = 0 \Longrightarrow \alpha_2 = 0 \Longrightarrow \alpha_1 = 0$$
        \item No it is not possible to write a dependency relation between the given vectors since they are linearly independent, as shown in (1). 
        \item No there is not a redundant vector among the vectors $\vec v_1, \vec v_2, \vec v_3$ since they are linearly independent, as shown in (1). 
        \item Yes, every vector in $\mathbb{R}^3$ is in the $\spn\{\vec v_1, \vec v_2, \vec v_3\}$. Consider that $\spn\{\vec v_1, \vec v_2, \vec v_3\}$ is a 3-dimensional subspace of $\mathbb{R}^3$. Since $\mathbb{R}^3$ is the only 3-dimensional subspace of $\mathbb{R}^3$, we have that $\spn\{\vec v_1, \vec v_2, \vec v_3\} = \mathbb{R}^3$. 
        \item No we cannot remove a vector from the set $\{\vec v_1, \vec v_2, \vec v_3\}$ without changing the subspace they span since no vector is redundant, as shown in (3). 
    \end{enumerate}
\end{SaveQuestion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{SaveQuestion}[
        key=ch3-kerim-examornex-sbg,
        prompt={In each case below, give an example of a linear map satisfying the given condition or explain why such a map does not exist. \begin{enumerate} 
        \item $T:\bbR^2 \rightarrow \bbR^2$ such that $\ker(T)$ contains the vector $\begin{bmatrix} 5 \\ 1 \end{bmatrix}$. 
        \item $T:\bbR^2 \rightarrow \bbR^3$ such that $\ker(T) = \left\{ \begin{bmatrix} x_1 \\ x_2 \end{bmatrix}: x_1 = 5x_2 \right\}.$ 
        \item $T:\bbR^2 \rightarrow \bbR^2$ such that $\ker(T) = \left\{ \begin{bmatrix} x_1 \\ x_2 \end{bmatrix}: x_1 = 5x_2 +1 \right\}.$ 
        \item $T:\bbR^2 \rightarrow \bbR^2$ such that $\ker(T)$ contains the vector $\begin{bmatrix} 5 \\ 1 \end{bmatrix}$ and the vector $\begin{bmatrix} 4 \\ 2 \end{bmatrix}$. 
        \end{enumerate} }
][chg-CON-exp,ch3-VG-imker,ch3-CON-gsker] %this is written as a comma seperated list with no spaces between commas
    %[<rubric items>]    %this is written as a comma seperated list with no spaces between commas
    %[<items mark>]      %this is written as a comma seperated list with no spaces between commas
    \begin{enumerate}
        \item $$ T([x_1,x_2])=[x_1-5x_2,x_1-5x_2].$$
        \item $$ T([x_1,x_2])=[x_1-5x_2,x_1-5x_2,x_1-5x_2].$$
        \item not possible. Kernel of a linear map must be a subspace of the domain
        \item $$ T([x_1,x_2])=[0,0].$$
    \end{enumerate}
\end{SaveQuestion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{SaveQuestion}[
        key=ch3-basis-definitions-dev,
        prompt={You should know the definitions/description of the following terms word by word from your PCE readings. Recite the definitions in your group. \begin{enumerate} \item A basis of a subspace \item Rank-Nullity Theorem \item $\mathcal B$-Coordinate of a vector in $V$, where $\mathcal B$ is a basis for $V$. \end{enumerate} }
][chg-WRIT-matcom] %this is written as a comma seperated list with no spaces between commas
    %[<rubric items>]    %this is written as a comma seperated list with no spaces between commas
    %[<items mark>]      %this is written as a comma seperated list with no spaces between commas
    Check the textbook/definition document
\end{SaveQuestion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{SaveQuestion}[
        key=ch3-basis-planesinR4-sbg,
        prompt={Recall the definition of a plane and a line, both going through the origin, in $\mathbb R^n$ from your reading 1. 
        A plane through the origin is a set of the form 
        \[
        \mathcal P=\{t\vec v+s\vec w \:|\: t,s\in \mathbb R\}=\spn(\vec v, \vec w)
        \]
       where $\vec v$ and $\vec w$ are linearly independent.
       A line through the origin is a set of the form 
        \[
        \mathcal P=\{t\vec v \:|\: t\in \mathbb R\}=\spn(\vec v)
        \]
       where $\vec v$ is nonzero. 
       We can use the concept of dimension to rephrase these definitions. A plane in $\mathbb R^n$ is a two-dimensional subspace of $\mathbb R^n$ and a line is a 1-dimensional subspace of $\mathbb R^n$. 
        \begin{enumerate}
\item \textbf{(Prediction).} Suppose you have two planes $\mathcal{P}_1$ and $\mathcal{P}_2$ in $\mathbb R^4$. Do not make any computations yet. Intuitively, in what ways can $\mathcal{P}_1$ and $\mathcal{P}_2$ intersect? Can they intersect at a point? or at a line? or at a plane?
\item Consider the following system of linear equations. 
\begin{eqnarray*}
    x+y+z+w&=&0\\
    -y+z-w&=&0
\end{eqnarray*}
and 
\begin{eqnarray*}
    x+2z+w&=&0\\
    2x+y+z+w&=&0
\end{eqnarray*}
Show that the general solution of each system is a plane in $\mathbb R^4$. 
\item Find the intersection of these two planes. Explain why the intersection is a subspace. 
\item Find the dimension of this intersection. 
\item Bonus: Consider a linear transformation $T:\mathbb R^4\to \mathbb R^4$ such that $\ker(T)=\mathcal P_1$ and $\im (T)=\mathcal P_2$. Is $T\circ T $ injective? surjective? Why? Think geometrically. 
\item Once again, suppose you have two planes in $\mathbb R^4$. What are the possibilities for the dimension of their intersection. Give one explicit example of $\mathcal{P}_1$ and $\mathcal{P}_2$ in each scenario and explain why your example works. 
 \end{enumerate}      
        }
][] %this is written as a comma seperated list with no spaces between commas
    %[<rubric items>]    %this is written as a comma seperated list with no spaces between commas
    %[<items mark>]      %this is written as a comma seperated list with no spaces between commas
  
\end{SaveQuestion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{SaveQuestion}[
        key=ch3-subspace-examplesv1-sbg,
        prompt={\textbf{Definition:} A \textbf{basis} of a subspace $W$ is a linearly independent set $S$ that spans the subspace $W$. \\  \\ For the following questions, consider the given subspace $W$ and the given set $S$. With your group, make sure you know why the given set $W$ is a {\bf subspace}. \begin{enumerate} \item $W = \mathbb{R}^4$, \quad $S = \{\vec e_1, \vec e_2, \vec e_3, \vec  e_4+ \vec e_1\}$  \begin{enumerate} \item[(a)] Using the provided definition, determine whether the set $S$ spans the subspace $W$. If $S$ does not span $W$, what is the subspace spanned by $S$. \item[(b)] Determine if the elements of $S$ are linearly independent. If they are linearly dependent, find a nontrivial solution to the zero vector. \item[(c)] Determine if the set $S$ is a basis for the subspace $W$. If $S$ is not a basis, provide a basis for $W$. \end{enumerate} \item $W$ is the  image of the linear map $\mathbb{R}^4 \rightarrow \mathbb{R}^3$ sending $ \begin{bmatrix}  w \\ x \\ y \\ z \end{bmatrix} \mapsto \begin{bmatrix}  x-y  \\ 2y+z \\ x+ y+ z \end{bmatrix}, \quad S = \left\{ \begin{bmatrix} 1  \\ 0 \\ 1 \end{bmatrix}, \begin{bmatrix} 0 \\ 0 \\ 0 \end{bmatrix}, \begin{bmatrix}  -1 \\ 2 \\ 1\end{bmatrix}, \begin{bmatrix}  0  \\ 1 \\ 1 \end{bmatrix} \right\}$ \begin{enumerate} \item[(a)] Determine whether the set $S$ spans the subspace $W$. If $S$ does not span $W$, what is the subspace spanned by $S$. \item[(b)] Determine if the elements of $S$ are linearly independent. If they are linearly dependent, find a nontrivial solution to the zero vector. \item[(c)] Using the provided definition, determine if the set $S$ is a basis for the subspace $W$. If $S$ is not a basis, provide a basis for $W$. \end{enumerate} \end{enumerate}}
][ch3-COM-dim,ch3-COM-linind,ch3-COM-reduclinind,ch3-CON-span] %remove the dimension. Provide the definition of basis, and get them to decide whether the set is indeed a basis. 
    \begin{enumerate}
        \item $W = \mathbb{R}^4$, \quad $S = \{\vec e_1, \vec e_2, \vec e_3, \vec  e_4+ \vec e_1\}$
        \begin{itemize}
            \item[(a)] To determine if the set  $S$ spans the subspace $W$, it is sufficient to verify that any element in $W$ can be written as a linear combination of the elements of $S$. Take $\vec x \in \mathbb{R}^4$ and denote the $i$-th entry of $x$ by $x_i$. Therefore, we have the following.
            $$\vec x = \begin{pmatrix} x_1 \\ x_2 \\ x_3 \\ x_4 \end{pmatrix} = \begin{pmatrix} x_1 - x_4 + x_4 \\ x_2 \\ x_3 \\ x_4 \end{pmatrix} = \begin{pmatrix} x_1 - x_4 \\ 0 \\ 0 \\ 0 \end{pmatrix} + \begin{pmatrix} 0 \\ x_2 \\ 0 \\ 0 \end{pmatrix} + \begin{pmatrix} \frac{x_1}{2} \\ 0 \\ 0 \\ x_3 \end{pmatrix} + \begin{pmatrix} x_4 \\ 0 \\ 0 \\ x_4 \end{pmatrix} = (x_1 - x_4)\vec e_1 + x_2 \vec e_2 + x_3 \vec e_3 + x_4 (\vec e_1 + \vec e_4)$$
            Thus, any vector in $W = \mathbb{R}^4$ can be written as a linear combination of the elements of $S$. This implies that $\spn S = W$.
            \item[(b)] To determine if the elements of $S$ are linearly independent, it is sufficient to see if a nontrivial linear combination to the zero vector exists.
            $$\begin{amatrix}{4} 1 & 0 & 0 & 1 & 0 \\ 0 & 1 & 0 & 0 & 0 \\ 0 & 0 & 1 & 0 & 0 \\ 0 & 0 & 0 & 1 & 0 \end{amatrix} \underset{\text{RREF}}{\rightarrow} \begin{amatrix}{4} 1 & 0 & 0 & 0 & 0 \\ 0 & 1 & 0 & 0 & 0 \\ 0 & 0 & 1 & 0 & 0 \\ 0 & 0 & 0 & 1 & 0 \end{amatrix}$$
            Consequently, the only linear combination of the elements of $S$ that yields the zero vector is the trivial linear combination (all coefficients are zeroes). So the elements of $S$ are linearly independent. 
            \item[(c)] From (a), we know that the set $S$ spans the subspace $W$, and further, from (b), that $S$ is a linearly independent set. Hence, by definition, $S$ is a basis for the subspace $W$. 
        \end{itemize} 
        \item $W$ is the  image of the linear map $\mathbb{R}^4 \rightarrow \mathbb{R}^3$ sending $ \begin{bmatrix}  w \\ x \\ y \\ z \end{bmatrix} \mapsto \begin{bmatrix}  x-y  \\ 2y+z \\ x+ y+ z \end{bmatrix}, \quad S = \left\{ \begin{bmatrix} 1  \\ 0 \\ 1 \end{bmatrix}, \begin{bmatrix} 0 \\ 0 \\ 0 \end{bmatrix}, \begin{bmatrix}  -1 \\ 2 \\ 1\end{bmatrix}, \begin{bmatrix}  0  \\ 1 \\ 1 \end{bmatrix} \right\}$
        \begin{itemize}
            \item[(a)] Consider that $W = \left\{\vec v \in \mathbb{R}^3 \ | \ \vec v = \begin{bmatrix}  x-y  \\ 2y+z \\ x+ y+ z \end{bmatrix}; x,y,z \in \mathbb{R}\right\}$. To determine if the set  $S$ spans the subspace $W$, it is sufficient to verify that any element in $W$ can be written as a linear combination of the elements of $S$. Thus, we fix $\vec u \in W$ such that $\vec u = \begin{bmatrix}  x-y  \\ 2y+z \\ x+ y+ z \end{bmatrix}$, for some $x,y,z \in \mathbb{R}$. Therefore, we have the following.
            $$\vec u =  \begin{bmatrix}  x-y  \\ 2y+z \\ x+ y+ z \end{bmatrix} = \begin{bmatrix} x \\ 0 \\ x \end{bmatrix} + \begin{bmatrix} -y \\ 2y \\ y \end{bmatrix} + \begin{bmatrix} 0 \\ z \\ z \end{bmatrix} = x\begin{bmatrix} 1 \\ 0 \\ 1 \end{bmatrix} + y\begin{bmatrix} -1 \\ 2 \\ 1 \end{bmatrix} + z\begin{bmatrix} 0 \\ 1 \\ 1 \end{bmatrix} = x\begin{bmatrix} 1 \\ 0 \\ 1 \end{bmatrix} + y\begin{bmatrix} -1 \\ 2 \\ 1 \end{bmatrix} + z\begin{bmatrix} 0 \\ 1 \\ 1 \end{bmatrix} + \vec 0$$
            Thus, any vector in $W$ can be written as a linear combination of the elements of $S$. This implies that $\spn S = W$.
            \item[(b)] To determine if the elements of $S$ are linearly independent, it is sufficient to see if a nontrivial linear combination to the zero vector exists. In fact, we know that any set containing the zero vector is necessarily linear dependent, as a nontrivial linear combination yielding the zero vector always exists. Fix $\alpha \in \mathbb{R}$ such that $\alpha \neq 0$. Then we have the following. 
            $$0\begin{bmatrix} 1 \\ 0 \\ 1 \end{bmatrix} + 0\begin{bmatrix} -1 \\ 2 \\ 1 \end{bmatrix} + 0\begin{bmatrix} 0 \\ 1 \\ 1 \end{bmatrix} + \alpha\vec 0 = \vec 0 + \vec 0 + \vec 0 + \vec 0 = \vec 0$$
            Consequently, the elements of $S$ are linearly dependent. 
            \item[(c)] From (a), we know that the set $S$ spans the subspace $W$, and further, from (b), that $S$ is a linearly dependent set. Hence, by definition, $S$ is not a basis for the subspace $W$. We may remove the zero vector from the set $S$ to produce a basis for $W$.   
        \end{itemize}
    \end{enumerate}
\end{SaveQuestion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{SaveQuestion}[
        key=ch3-subspace-examplesv2-sbg,
        prompt={With your group, make sure you know why the given set $W$ is a {\bf subspace.} Then determine whether  the given set $S$ {\bf  spans } the given subspace $W$.  If not, what is the {\bf subspace spanned  by } $S$? Are  the elements of $S$ {\bf  linearly independent} ? If not,  find a {\bf relation.} Is the set $\mathcal B$ a {\bf basis} for the given subspace $W$? What is the {\bf dimension } of $W$?   \begin{enumerate}    \item  $W$ is the kernel of a surjective linear transformation $T: \mathbb{R}^4 \rightarrow \mathbb{R}^3$, and $S$ is the set consisting of just one element of $\vec v$ such that $T\vec v = 0$. [Hint: Rank-Nullity!]   \item   $W$ is the image of an invertible  linear transformation $\mathbb{R}^n \rightarrow \mathbb{R}^n$ and $S$ is the set of standard unit vectors in $\mathbb{R}^n$. \end{enumerate} }
][ch3-CON-kerrank,ch3-CON-surim] %this is written as a comma seperated list with no spaces between commas
    %[<rubric items>]    %this is written as a comma seperated list with no spaces between commas
    %[<items mark>]      %this is written as a comma seperated list with no spaces between commas
    \begin{enumerate}  
        \item Because the map is surjective, the image is $\mathbb{R}^3$, so has dimension 3. By rank nullity, the kernel has dimension 4 - 3 = 1. So any non-zero vector in the kernel will be a basis.
        \item Since the transformation is invertible, it is both surjective and injective. So, the image is all of $\mathbb{R}^n$. We know $S$ is a basis, the "standard basis".
    \end{enumerate}
\end{SaveQuestion}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{SaveQuestion}[
        key=ch3-subspace-examplesv3-sbg,
        prompt={$W$ is the solution space of the equations $x+y+z = 0,\,\, x - y + 2z = 0, $ \,\, $S = \left\{\begin{bmatrix}  1 \\ 1 \end{bmatrix},      \begin{bmatrix}  1 \\  -1 \end{bmatrix},  \begin{bmatrix}  1 \\ 2 \end{bmatrix}    \right\}.$     \begin{enumerate}     \item Write a linear transformation whose kernel is $W$   \item Is $S$ a basis of this subspace? \end{enumerate} }
][ch3-CON-gsker] %this is written as a comma seperated list with no spaces between commas
    %[<rubric items>]    %this is written as a comma seperated list with no spaces between commas
    %[<items mark>]      %this is written as a comma seperated list with no spaces between commas
    \begin{enumerate}
        \item 
        \item NO! The solution space lives in $\mathbb{R}^3$, not $\mathbb{R}^2$, so these are not even in $W$! 
    \end{enumerate}
\end{SaveQuestion}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{SaveQuestion}[
        key=ch3-ranknullity-truefalse-sbg,
        prompt={TRUE or FALSE? Justify your answer. \begin{enumerate} \item If $A$ is a $4\times 5 $ matrix, then it is possible for $\rank(A)$ to be $3$ and $\dim (\im (A))$ to be $4$. \item If $T:\mathbb{R}^5 \rightarrow \mathbb{R}^4$ is given by multiplication by a rank 3 matrix, can $T$ be surjective? \item If $A$ is a $4\times 5 $ matrix, then it is possible for $\rank(A)$ to be $3$ and $\dim (\ker (A))$ to be $3$. \item If $A$ is a $4\times 5 $ matrix, then it is possible for $\rank(A)$ to be $3$ and $\dim (\ker (A))$ to be $2$. \end{enumerate} }
][chg-CON-tf] %this is written as a comma seperated list with no spaces between commas
    %[<rubric items>]    %this is written as a comma seperated list with no spaces between commas
    %[<items mark>]      %this is written as a comma seperated list with no spaces between commas
    \begin{enumerate}
        \item No. The dimension of the image is the rank of $A$.
        \item No.  Surjective means the image is all of $\mathbb{R}^4$, which has dimension 4.
			The dimension of the image is the rank of the matrix, which is  3.
        \item No. $\dim \ker + \dim \im = \dim \, source = 5$. So we would have $3+ 3 = 5$, which is impossible.
        \item True. It is possible and in fact always true by Rank Nullity.
    \end{enumerate}
\end{SaveQuestion}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{SaveQuestion}[
        key=ch3-coordinate-r4standard-sbg,
        prompt={{\bf { Important theorem:} }  If $\{\vec v_1, \vec v_2, \dots \vec v_d\} $  is a basis for $W$, then every element of $W$ can be written in {\sc one and only one } way as a linear combination of the vectors $\vec v_1, \vec v_2, \dots \vec v_d.$ \\  \\ Consider the set $\mathcal B = \{\vec e_1,\vec e_1 + \vec e_2, \vec e_1 + \vec e_2 + \vec e_3, \vec e_1 + \vec e_2 + \vec e_3 + \vec  e_4 \} \in \mathbb{R}^4$ and $\mathcal E.= \{ \vec e_1, \vec e_2, \vec e_3, \vec e_4 \}$. \begin{enumerate} \item Justify why $\mathcal B$ is a basis for $ \mathbb{R}^4$.
        \item Write $\vec x = [0\,\,0\,\, 0\,\, 1]^{T}$ as a linear combination of the elements in $\mathcal B$. Is this unique? Find the   $\mathcal B$-coordinates of $\vec x$. What is $[\vec x]_{\mathcal B}$? \item Same for $\vec y = [1\,\,0\,\, 0\,\, 1]^{T}$. \item Find a matrix $C$ such that $C [{\vec x}]_{\mathcal E} = [{\vec x}]_{\mathcal B}$ \end{enumerate} }
][ch3-COM-basvec,ch3-COM-matbas] %this is written as a comma seperated list with no spaces between commas
    [Correct B coordinates in a vectors form*,Correct change of basis matrix*]    %this is written as a comma seperated list with no spaces between commas
    %[<items mark>]      %this is written as a comma seperated list with no spaces between commas
    \begin{enumerate}
        \item $\mathcal B$ spans all of $\bbR^4$ and all vectors are linearly independent. We can see this if we put it into a matrix and row reduce to find 4 pivot columns and no free variables. 
        \item $\begin{bmatrix}
            0 \\ 0 \\ 0 \\ 1
        \end{bmatrix} = \begin{bmatrix}
            1 \\ 1 \\ 1 \\ 1
        \end{bmatrix} - \begin{bmatrix}
            1 \\ 1 \\ 1 \\ 0
        \end{bmatrix}$ so $\vec x = \vec b_4 - \vec b_3$. This linear combination is unique by the theorem above given in the question. It also determines that $[\vec x]_{\mathcal B} = \begin{bmatrix}
            0 \\ 0 \\ -1 \\ 1
        \end{bmatrix}$.
        \item $\begin{bmatrix}
            1 \\ 0 \\ 0 \\ 1
        \end{bmatrix} = \begin{bmatrix}
            1 \\ 1 \\ 1 \\ 1
        \end{bmatrix} - \begin{bmatrix}
            1 \\ 1 \\ 1 \\ 0
        \end{bmatrix} + \begin{bmatrix}
            1 \\ 0 \\ 0 \\ 0
        \end{bmatrix}$ so $\vec y = \vec b_1 - \vec b_3 + \vec b_4$. This linear combination is unique by the theorem above given in the question. It also determines that $[\vec y]_{\mathcal B} = \begin{bmatrix}
            1 \\ 0 \\ -1 \\ 1
        \end{bmatrix}$.
        \item Matrix $C$ will be the change of basis matrix and is equal to $\begin{bmatrix}
            1 & -1 & 0 & 0 \\
            0 & 1 & -1 & 0 \\
            0 & 0 & 1 & -1 \\
            0 & 0 & 0 & 1
        \end{bmatrix}$
    \end{enumerate}
\end{SaveQuestion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{SaveQuestion}[
        key=ch3-coordinate-r3perp-sbg,
        prompt={\textbf{Important Theorem:}  If $\{\vec v_1, \vec v_2, \dots \vec v_d\} $  is a basis for a subspace $W$, then every element of $W$ can be written in \emph{one and only one} way as a linear combination of the vectors $\vec v_1, \vec v_2, \dots, \vec v_d$. \\ \\ Consider the subspace $W$ defined by the following. $$W =\spn
        \left(\left\{\begin{bmatrix} 1 \\ -1 \\ 0 \\ 2 \end{bmatrix}, \begin{bmatrix} 2 \\ 0 \\ 1 \\ 3 \end{bmatrix}\right\}\right)$$ Answer the following questions about $W$. \begin{enumerate}\item Justify that the set $\mathcal B=\left\{\begin{bmatrix}1\\-1\\0\\2\end{bmatrix}, \begin{bmatrix}2\\0\\1\\3\end{bmatrix}\right\}$ is a basis for $W$.\item Find another basis $\mathcal U$ for $W$ that contains the vector $\begin{bmatrix} 3 \\ -1 \\ 1 \\ 5 \end{bmatrix}$. \item  Let $\vec x =\begin{bmatrix}4\\-2\\1\\7\end{bmatrix}$, and $\vec y=\begin{bmatrix}5\\10\\2\\8\end{bmatrix}$. Find $[\vec x]_{\mathcal B}$, $[\vec y]_{\mathcal B}$, $[\vec x]_{\mathcal U}$, and $[\vec y]_{\mathcal U}$ or explain why this is not possible. \item Find a matrix $C$ such that $C[\vec v]_\mathcal B=[\vec v]_{\mathcal U}$ for any vector $\vec v$ in $W$. \end{enumerate}}
][ch3-COM-basvec,ch3-COM-matbas] %this is written as a comma seperated list with no spaces between commas
    [Correct B and U coordinates in a vectors form*,Correct change of basis matrix*]    %this is written as a comma seperated list with no spaces between commas
    %[<items mark>]      %this is written as a comma seperated list with no spaces between commas
    \begin{enumerate}
        \item Recall that a set $\mathcal B$ is a basis of a subspace $W$ if $\mathcal B$ is linearly independent and $\mathcal B$ spans $W$. By definition, we see that $\mathcal B$ spans $W$, so it is sufficient to verify that $\mathcal B$ is linearly independent. In fact, we know that any set with two vectors is linearly dependent precisely when the two vectors are scalar multiples of each other. Since this is not the case, it must that $\mathcal B$ is linearly independent. We may also verify such by showing that only the trivial linear combination yields the zero vector.
        $$\vec 0 = \alpha_1 \begin{bmatrix} 1 \\ -1 \\ 0 \\ 2 \end{bmatrix} + \alpha_2 \begin{bmatrix} 2 \\ 0 \\ 1 \\ 3 \end{bmatrix} = \begin{bmatrix} \alpha_1 + 2 \alpha _2 \\ - \alpha_1 \\ \alpha_2 \\ 2\alpha_1 + 3\alpha_2 \end{bmatrix} \Longrightarrow \alpha_1, \alpha_2 = 0$$
        \item Notice that the proposed vector is the sum of the two vectors in $\mathcal B$. Consequently, the other vector in $\mathcal U$ must be some linear combination of the elements of $\mathcal B$ where the coefficients are different. That is, for any $\alpha_1, \alpha_2 \in \mathbb{R}, \alpha_1 \neq \alpha_2$, the following is a suitable basis $\mathcal U$.
        $$\mathcal U = \left\{\begin{bmatrix} 3 \\ -1 \\ 1 \\ 5 \end{bmatrix},  \begin{bmatrix} \alpha_1 + 2 \alpha _2 \\ - \alpha_1 \\ \alpha_2 \\ 2\alpha_1 + 3\alpha_2 \end{bmatrix}\right\}$$
        For questions (3) and (4) we consider the case when $\alpha_1 = 1, \alpha_2 = 0$, which yields the following. 
        $$\mathcal U = \left\{\begin{bmatrix} 3 \\ -1 \\ 1 \\ 5 \end{bmatrix},  \begin{bmatrix} 1 \\ -1 \\ 0 \\ 2 \end{bmatrix}\right\}$$
        \item Fix $\mathcal B = \{\vec b_1, \vec b_2\}, \mathcal U = \{\vec u_1, \vec u_2\}$. Notice that for any vector $\vec v \in W$, we define $[\vec v]_{\mathcal B}, [\vec v]_{\mathcal U}$ as the following.
        $$\begin{array}{cr}
            \vec v = c_1 \vec b_1 + c_2 \vec b_2 & \Longrightarrow [\vec v]_{\mathcal B} = \begin{bmatrix} c_1 \\ c_2 \end{bmatrix} \\ \\
            \vec v = c_3 \vec u_1 + c_4 \vec u_2 & \Longrightarrow [\vec v]_{\mathcal U} = \begin{bmatrix} c_3 \\ c_4 \end{bmatrix}
        \end{array}$$
        Briefly, we remark that $\vec y \not\in W$, so the quantities $[\vec y]_{\mathcal B}, [\vec y]_{\mathcal U}$ cannot be computed in this case. 
        $$\alpha_1 \begin{bmatrix} 1 \\ -1 \\ 0 \\ 2 \end{bmatrix} + \alpha_2 \begin{bmatrix} 2 \\ 0 \\ 1 \\ 3 \end{bmatrix} = \begin{bmatrix} \alpha_1 + 2 \alpha _2 \\ - \alpha_1 \\ \alpha_2 \\ 2\alpha_1 + 3\alpha_2 \end{bmatrix} \Longrightarrow, \alpha_1 = -10, \alpha_2 = 2 \Longrightarrow  \begin{bmatrix} -6 \\ 10 \\ 2 \\ -14 \end{bmatrix} \neq \vec y$$
        Conversely, we have the following for $\vec x \in W$. 
        $$\begin{array}{cr}
            \vec x = 2 \vec b_1 + 1 \vec b_2 & \Longrightarrow [\vec x]_{\mathcal B} = \begin{bmatrix} 2 \\ 1 \end{bmatrix} \\ \\
            \vec x = 1 \vec u_1 + 1 \vec u_2 & \Longrightarrow [\vec x]_{\mathcal U} = \begin{bmatrix} 1 \\ 1 \end{bmatrix}
        \end{array}$$
        Hence, we have computed $[\vec x]_{\mathcal B}$ and $[\vec x]_{\mathcal U}$, and justified why $[\vec y]_{\mathcal B}$ and $[\vec y]_{\mathcal U}$ cannot exists, as needed. 
        \item 
        $$C = \begin{bmatrix} | & | \\ [\vec b_1]_{\mathcal U} & [\vec b_2]_{\mathcal U} \\ | & | \end{bmatrix} = \begin{bmatrix} 0 & 1 \\ 1 & -1 \end{bmatrix}$$
    \end{enumerate}
    %         \item A basis is a set of vectors that spans a set and is linearly independent. Since $W$ is defined to be the span of the two vectors in $\mathcal B$, we know that the first property holds. To check that they are linearly independent, we check if one can be written as a linear combination of the other:
    %         $$\begin{bmatrix}
    %             1 \\ -1 \\ 0 \\ 2
    %         \end{bmatrix} = k \begin{bmatrix}
    %             2 \\ 0 \\ 1 \\ 3
    %         \end{bmatrix}$$ $$1 = 2k, -1 = 0k, 0 = k, 2 = 3k$$ $$k = \frac{1}{2}, -1 = 0, k = 0, k = \frac{2}{3}$$ Since all 4 equations can not be true (and one of them is nonsense) we say the linear combination is not possible and they two vectors must be linearly independent. This shows that $\mathcal B$ is a basis for $W$.
    %         \item Since $\begin{bmatrix}
    %             3 \\ -1 \\ 1 \\ 5
    %         \end{bmatrix}$ is equal to $\begin{bmatrix}
    %             1 \\ -1 \\ 0 \\ 2
    %         \end{bmatrix} + \begin{bmatrix}
    %             2 \\ 0 \\ 1 \\ 3
    %         \end{bmatrix}$, adding either of the original vectors creates a new basis, so consider $\mathcal U = \left( \begin{bmatrix}
    %             3 \\ -1 \\ 1 \\ 5
    %         \end{bmatrix}, \begin{bmatrix}
    %             1 \\ -1 \\ 0 \\ 2
    %         \end{bmatrix} \right)$.
    %         \item $\begin{bmatrix}
    %             4 \\ -2 \\ 1 \\ 7
    %         \end{bmatrix} = 2 \begin{bmatrix}
    %             1 \\ -1 \\ 0 \\ 2
    %         \end{bmatrix} + \begin{bmatrix}
    %             2 \\ 0 \\ 1 \\ 3
    %         \end{bmatrix}$ so $[\vec x]_{\mathcal B} = \begin{bmatrix}
    %             2 \\ 1
    %         \end{bmatrix}$ and $[\vec x]_{\mathcal U} = \begin{bmatrix}
    %             1 \\ 1
    %         \end{bmatrix}$. $\vec y$ is not in the subset $W$ since it is not contained in the span of $\mathcal B$ or $\mathcal U$. This means that it is not possible to write $[\vec y]_{\mathcal B}$ or $[\vec y]_{\mathcal U}$
    %         \item C = \begin{bmatrix}
    %             0 & 1 \\ 1 & -1
    %         \end{bmatrix}
    %     \end{enumerate}
\end{SaveQuestion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{SaveQuestion}[
        key=ch3-coordinate-wimage-sbg,
        prompt={\textbf{Important Theorem:}  If $\{\vec v_1, \vec v_2, \dots \vec v_d\} $  is a basis for a subspace $W$, then every element of $W$ can be written in \emph{one and only one} way as a linear combination of the vectors $\vec v_1, \vec v_2, \dots, \vec v_d$. \\ \\ Let  $W$ be the image of a transformation whose standard matrix is $\begin{bmatrix} 1 & 2 & 3 & 5 &  0\\   1& 0 & 1 & 1 & -2\\ 1 & 6 & 7 & 13 & 4 \end{bmatrix}$. \\\begin{enumerate}\item Justify that the set $\mathcal B = \left\{\begin{bmatrix} 1 \\ 1 \\ 1 \end{bmatrix}, \begin{bmatrix} 2 \\ 0 \\ 6 \end{bmatrix}\right\}$ is a basis for $W$.\item Find another basis $\mathcal U$ for $W$ that contains the vector $\begin{bmatrix} 5 \\ 1 \\ 13 \end{bmatrix}$. 
        \item Let $\vec x=\begin{bmatrix}   2 \\    0\\ 6 \end{bmatrix}$, $\vec y=\begin{bmatrix}   3 \\    1\\ 7 \end{bmatrix}$, $\vec z=\begin{bmatrix}   5\\   1\\ 13 \end{bmatrix}$. Find the $\mathcal B$, and $\mathcal U$ coordinates of $\vec x$, $\vec y$, $\vec z$, or explain why this is not possible. \item Find a matrix $C$ such that $C[\vec v]_{\mathcal B}=[\vec v]_{\mathcal U}$.
        \end{enumerate} }
][ch3-COM-basvec,ch3-COM-matbas] %this is written as a comma seperated list with no spaces between commas
    [Correct B and U coordinates in a vectors form*,Correct change of basis matrix*]    %this is written as a comma seperated list with no spaces between commas
    %[<items mark>]      %this is written as a comma seperated list with no spaces between commas
     \begin{enumerate}
         \item The matrix has rank 2, which we see by starting to row-reduce and observing (without wasting time going all the way to the rref) that the rref will have two leading ones. This means that the dimension of the image $W$ is two (This is an important theorem; see the book Theorem 3.3.6. Know this one!). So any two linearly independent vectors in $W$ will be a basis. The columns of the matrix span $W$ (another important book theorem from the same section), so we can pick any two linearly independent columns. The first two work.
         \item Notice that the proposed vector is another column of the matrix. As argued above, we know that the basis of $W$ must include two linearly independent columns of the matrix. In this case, any of the four other columns and the vector are linearly independent. Here are some example bases.
         $$\begin{array}{ll}
             \mathcal B_1 = \left\{\begin{bmatrix} 1 \\ 1 \\ 1 \end{bmatrix},\begin{bmatrix} 5 \\ 1 \\ 13 \end{bmatrix}\right\} & \mathcal B_2 = \left\{\begin{bmatrix} 2 \\ 0 \\ 6 \end{bmatrix},\begin{bmatrix} 5 \\ 1 \\ 13 \end{bmatrix}\right\} \\ \\
             \mathcal B_3 = \left\{\begin{bmatrix} 5 \\ 1 \\ 13 \end{bmatrix},\begin{bmatrix} 3 \\ 1 \\ 7 \end{bmatrix}\right\} & \mathcal B_4 = \left\{\begin{bmatrix} 5 \\ 1 \\ 13 \end{bmatrix},\begin{bmatrix} 0 \\ -2 \\ 4 \end{bmatrix}\right\}
         \end{array}$$\\ 
         For questions (3) and (4) we consider the case when $\mathcal U := \mathcal U_3$.
         \item Fix $\mathcal B = \{\vec b_1, \vec b_2\}, \mathcal U = \{\vec u_1, \vec u_2\}$. Notice that for any vector $\vec v \in W$, we define $[\vec v]_{\mathcal B}, [\vec v]_{\mathcal U}$ as the following.
        $$\begin{array}{cr}
            \vec v = c_1 \vec b_1 + c_2 \vec b_2 & \Longrightarrow [\vec v]_{\mathcal B} = \begin{bmatrix} c_1 \\ c_2 \end{bmatrix} \\ \\
            \vec v = c_3 \vec u_1 + c_4 \vec u_2 & \Longrightarrow [\vec v]_{\mathcal U} = \begin{bmatrix} c_3 \\ c_4 \end{bmatrix}
        \end{array}$$
        This implies that we must find linear combinations of the elements of $\mathcal B, \mathcal U$, respectively, that yield the vectors $\vec x, \vec y$, and $\vec z$. 
        $$\begin{array}{rlrlrl}
            \vec x = b_2 &\Longrightarrow [\vec x]_{\mathcal B} =  \begin{bmatrix} 0 \\ 1 \end{bmatrix} & \vec y = b_1 + b_2 &\Longrightarrow [\vec y]_{\mathcal B} =  \begin{bmatrix} 1 \\ 1 \end{bmatrix} & \vec z = b_1 + 2b_2 &\Longrightarrow [\vec z]_{\mathcal B} =  \begin{bmatrix} 1 \\ 2 \end{bmatrix} \\ \\
            \vec x = -b_1 + b_2 &\Longrightarrow [\vec x]_{\mathcal U} =  \begin{bmatrix} -1 \\ 1 \end{bmatrix} & \vec y = b_1 &\Longrightarrow [\vec y]_{\mathcal B} =  \begin{bmatrix} 1 \\ 0 \end{bmatrix} & \vec z = b_2 &\Longrightarrow [\vec z]_{\mathcal B} =  \begin{bmatrix} 0 \\ 1 \end{bmatrix} 
        \end{array}$$
        \item $C$ is the change of basis matrix and is equal to the following.
        $$C = \begin{bmatrix} | & | \\ [\vec b_1]_{\mathcal U} & [\vec b_2]_{\mathcal U} \\ | & | \end{bmatrix} = \begin{bmatrix} 1 & -1 \\-1 & 2 \end{bmatrix}$$
     \end{enumerate}
\end{SaveQuestion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{SaveQuestion}[
        key=ch3-kerim-6matrices-dev,
        prompt={Consider the matrices $$C= \begin{bmatrix} 1&1&1\\1&0&0\\1&1&1\\ \end{bmatrix}, H= \begin{bmatrix} 1&0&1\\1&1&1\\1&0&1\\ \end{bmatrix}, L= \begin{bmatrix} 1&0&0\\1&0&0\\1&1&1\\ \end{bmatrix},$$ \\ $$T= \begin{bmatrix} 1&1&1\\0&1&0\\0&1&0\\ \end{bmatrix}, X= \begin{bmatrix} 1&0&1\\0&1&0\\1&0&1\\ \end{bmatrix}, Y= \begin{bmatrix} 1&0&1\\0&1&0\\0&1&0\\ \end{bmatrix}$$ 
        \begin{enumerate} 
            \item Without row reducing, are the columns of each matrix linearly independent? If not, write one column as a linear combination of the other columns for each matrix.
            \item Using your results in part 1, find at least one vector in the kernel of each matrix.
            \item Give a basis for the kernel of each matrix. What is the dimension of each kernel? 
            \item Which of the matrices in this list have the same kernel as matrix $C$? 
            \item What is the dimension of each image? Give a basis for the image of each matrix. 
            \item Which of the matrices in this list have the same image as matrix $C$?  
            \item Which of these matrices has an image that is different from the images of all the other matrices in the list? 
        \end{enumerate} }
][ch3-CON-kerlinind,ch3-WRIT-ker,ch3-VG-imker,ch3-WRIT-im,ch3-COM-bases] %this is written as a comma seperated list with no spaces between commas
    [Satisfactory: Allow for up to 2 mistakes (6 matrices is a lot)*Can Be Improved: More than 2 mistakes*Try Again: Conceptual misunderstanding*]    %this is written as a comma seperated list with no spaces between commas
    \begin{enumerate}
        \item All have one linearly dependent column vector, all of which are an exact copy of another column. \\
        $C:$ column 2 = column 3, $H:$ column 1 = column 3, $L:$ column 2 = column 3, $T:$ column 1 = column 3, $X:$ column 1 = column 3, $Y:$ column 1 = column 3. 
        \item $\begin{pmatrix}
            0 \\ 1 \\ -1
        \end{pmatrix} \in \ker C, \begin{pmatrix}
            1 \\ 0 \\ -1
        \end{pmatrix} \in \ker H, \\ \begin{pmatrix}
            0 \\ 1 \\ -1
        \end{pmatrix} \in \ker L, \begin{pmatrix}
            1 \\ 0 \\ -1
        \end{pmatrix} \in \ker T, \\ \begin{pmatrix}
            1 \\ 0 \\ -1
        \end{pmatrix} \in \ker X, \begin{pmatrix}
            1 \\ 0 \\ -1
        \end{pmatrix} \in \ker Y$
        \item $\ker C = \left \{ t \begin{pmatrix}
		    0\\1\\-1\\
		\end{pmatrix} | t \in \mathbb{R} \right \}, 
        \ker H = \left \{ t \begin{pmatrix}
		    1\\0\\-1\\
		\end{pmatrix} | t \in \mathbb{R} \right \}, \\
        \ker L = \left \{ t \begin{pmatrix}
		    0\\1\\-1\\
		\end{pmatrix} | t \in \mathbb{R} \right \}, 
        \ker T = \left \{ t \begin{pmatrix}
		    1\\0\\-1\\
		\end{pmatrix} | t \in \mathbb{R} \right \}, \\
        \ker X = \left \{ t \begin{pmatrix}
		    1\\0\\-1\\
		\end{pmatrix} | t \in \mathbb{R} \right \}, 
        \ker Y = \left \{ t \begin{pmatrix}
		    1\\0\\-1\\
		\end{pmatrix} | t \in \mathbb{R} \right \}$. \\
        Each kernel has a dimension of $1$
        \item $L$
        \item $\im C = \left \{ t \begin{pmatrix}
		    1\\0\\1
		\end{pmatrix} + s \begin{pmatrix}
		    1\\1\\1
		\end{pmatrix}| t,s \in \mathbb{R} \right \}, 
            \im H = \left \{ t \begin{pmatrix}
		    0\\1\\0
		\end{pmatrix} + s \begin{pmatrix}
		    1\\1\\1
		\end{pmatrix}| t,s \in \mathbb{R} \right \}, \\
            \im L = \left \{ t \begin{pmatrix}
		    0\\0\\1\\
		\end{pmatrix} + s \begin{pmatrix}
		    1\\1\\1
		\end{pmatrix}| t,s \in \mathbb{R} \right \}, 
            \im T = \left \{ t \begin{pmatrix}
		    1\\0\\0\\
		\end{pmatrix} + s \begin{pmatrix}
		    1\\1\\1
		\end{pmatrix}| t,s \in \mathbb{R} \right \}, \\
            \im X = \left \{ t \begin{pmatrix}
		    1\\0\\1\\
		\end{pmatrix} + s \begin{pmatrix}
		    0\\1\\0
		\end{pmatrix}| t,s \in \mathbb{R} \right \}, 
            \im Y = \left \{ t \begin{pmatrix}
		    1\\0\\0\\
		\end{pmatrix} + s \begin{pmatrix}
		    0\\1\\1
		\end{pmatrix}| t,s \in \mathbb{R} \right \}$ \\
  The dimension of each image is $2$
        \item  $H, X$
        \item $L$
    \end{enumerate}
\end{SaveQuestion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{SaveQuestion}[
        key=ch3-diagonal-examples4-sbg,
        prompt={In each part, find the standard basis of the described linear transformation $T$, that is $[T]_\mathcal E$. Then find a basis $\mathcal B$ such that $[T]_\mathcal B$ is a diagonal matrix. To do so, you need to find vectors that go to multiple of themselves under $T$. Finally find the change of basis $C$, from $\mathcal B$ to $\mathcal E$. What is the relation between $[T]_\mathcal E$ and $[T]_\mathcal B $. \begin{enumerate} \item $T$ is the orthogonal projection onto the line in $\mathbb{R}^2$ spanned by $\begin{bmatrix} 1\\2 \end{bmatrix}$. \item  $T$ is the reflection about the line in $\mathbb{R}^2$ spanned by $\begin{bmatrix} 2\\3 \end{bmatrix}$. \item $T$ is the orthogonal projection onto the plane $3x_1+x_2+2x_3=0$ in $\mathbb{R}^3$ \item $T$ is the reflection about the plane $3x_1+x_2+2x_3=0$ in $\mathbb{R}^3$. \end{enumerate} }
][ch3-CON-th347] %this is written as a comma seperated list with no spaces between commas
    %[<rubric items>]    %this is written as a comma seperated list with no spaces between commas
    %[<items mark>]      %this is written as a comma seperated list with no spaces between commas
    \begin{enumerate}
        \item  We need two linearly independent vectors that go to multiple of themselves under the projection. Thinking geometrically, any vector on the line spanned by $\begin{bmatrix}
        1\\2
    \end{bmatrix}$ goes to one time itself and every vector in the orthogonal complement of the line goes to zero times itself. Take $\mathcal B=(\begin{bmatrix}
        2\\4
    \end{bmatrix}, \begin{bmatrix}
        -2\\1
    \end{bmatrix})$. Then 
    \[
[T]_\mathcal B=\begin{bmatrix}
    1&0\\0&0
\end{bmatrix},\quad C_{\mathcal B\to \mathcal E}= \begin{bmatrix}
    2&-2\\4&1
\end{bmatrix},\quad \quad [T]_\mathcal E=C [T]_{\mathcal B}C^{-1}
    \]
        \item We need two linearly independent vectors that go to multiple of themselves under the reflection. Thinking geometrically, any vector on the line spanned by $\begin{bmatrix}
        2\\3
    \end{bmatrix}$ goes to one time itself and every vector in the orthogonal complement of the line goes to negative one time itself.Take $\mathcal B=(\begin{bmatrix}
        -2\\-3
    \end{bmatrix}, \begin{bmatrix}
        6\\-4
    \end{bmatrix})$. (note that there are infinitely many basis you can pick!

     \[
[T]_\mathcal B=\begin{bmatrix}
    1&0\\0&-1
\end{bmatrix},\quad C_{\mathcal B\to \mathcal E}= \begin{bmatrix}
    -2&6\\-3&-4
\end{bmatrix},\quad \quad [T]_\mathcal E=C[T]_{\mathcal B}C^{-1}
    \]
    \item We need three linearly independent vectors that go to multiple of themselves under the projection. Thinking geometrically, any vector on the given plane goes to one time itself. We can find two linearly independent vectors on the plane as the dimension of the plane is 2. Thinking geometrically again, every vector in the orthogonal complement of the plane goes to zero time itself. We can take our third vector from the orthogonal complement.  Take $\mathcal B=(\begin{bmatrix}
        -1\\3\\0
    \end{bmatrix}, \begin{bmatrix}
        0\\4\\-2
    \end{bmatrix},\begin{bmatrix}
        3\\1\\2
    \end{bmatrix} )$. (note that there are infinitely many basis you can pick!

     \[
[T]_\mathcal B=\begin{bmatrix}
    1&0&0\\0&1&0\\0&0&0
\end{bmatrix},\quad C_{\mathcal B\to \mathcal E}= \begin{bmatrix}
    -1&0&3\\3&4&1\\0&-2&2
\end{bmatrix},\quad \quad [T]_\mathcal E=C[T]_{\mathcal B}C^{-1}
    \]
    \item We need three linearly independent vectors that go to multiple of themselves under the reflection. Thinking geometrically, any vector on the given plane goes to one time itself. We can find two linearly independent vectors on the plane as the dimension of the plane is 2. Thinking geometrically again, every vector in the orthogonal complement of the plane goes to $-1$ time itself. We can take our third vector from the orthogonal complement.  Take $\mathcal B=(\begin{bmatrix}
        -1\\3\\0
    \end{bmatrix}, \begin{bmatrix}
        0\\4\\-2
    \end{bmatrix},\begin{bmatrix}
        3\\1\\2
    \end{bmatrix} )$. (note that there are infinitely many basis you can pick!

     \[
[T]_\mathcal B=\begin{bmatrix}
    1&0&0\\0&1&0\\0&0&-1
\end{bmatrix},\quad C_{\mathcal B\to \mathcal E}= \begin{bmatrix}
    -1&0&3\\3&4&1\\0&-2&2
\end{bmatrix},\quad \quad [T]_\mathcal E=C[T]_{\mathcal B}C^{-1}
    \]
    \end{enumerate}
\end{SaveQuestion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{SaveQuestion}[
        key=ch3-ranknullity-truefalse4-dev,
        prompt={Using the Rank-Nullity theorem, justify whether each statement is True or False. \begin{enumerate} \item If $A$ is a $m \times n$ matrix, then it is possible for $\rank A$ to be $m$ and $\dim(\im(A))$ to be $m-1$. \item There exists a $5 \times 5$ matrix who's kernel and image are both planes in $\mathbb{R}^5$ \item If $A$ is a $4 \times 4$ matrix, then it is possible for $\rank A$ to be $2$ and $\dim(\ker(A))$ to be $2$. \end{enumerate}}
][chg-CON-tf,chg-WRIT-matcom,ch3-CON-kerrank] %this is written as a comma seperated list with no spaces between commas
    [Correct T/F answers*,Correct part 1*,Correct part 2 and 3*]    %this is written as a comma seperated list with no spaces between commas
    \begin{enumerate}
        \item False. If $m>n$ then it is impossible for $\rank A = m$ but more specifically using rank-nullity, the rank of A and the dimension of the image of A are the same, so $\rank A = \dim(\im A)$ but $m \neq m-1$.
        \item False. A kernel and image which are both planes in $\mathbb{R}^5$ would mean that they are both 2 dimensional. If that was the case then $\dim(\ker A) = 2$ and $\dim(\im A) = 2$ and the rank-nullity theorem would say that $\dim(\im A) + \dim(\ker A) = 5$ but $2+2 \neq 5$. 
        \item True. $\rank A = \dim(\im A)$ and $\dim(\im A) + \dim(\ker A) = 2+2 =4$ following the rank nullity theorem.
    \end{enumerate}
\end{SaveQuestion}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{SaveQuestion}[
        key=ch6-det-inv-sbg,
        prompt={Suppose $c\in\bbR$, and let $A=\begin{bmatrix} 1 & 2 & -1 \\ 2 & 3 & c \\ 0 & c & -15 \end{bmatrix}$. For which values of $c$ is $A$ invertible?}
][ch6-CON-invcheck,chg-WRIT-matcom] %this is written as a comma seperated list with no spaces between commas
    [Correct c values using determinant*,Why we are looking at determinant*Correct determinant notation*correct cofactor expansion if used*full sentences and coherence*]    %this is written as a comma seperated list with no spaces between commas
    %[<items mark>]      %this is written as a comma seperated list with no spaces between commas
    Recall the following fact: \begin{center}
			$det(A)\neq0$ if and only if $A$ is invertible.
		\end{center} 
		Therefore,
		$\begin{bmatrix} 1 & 2 & -1 \\ 2 & 3 & c \\ 0 & c & -15 \end{bmatrix}$ is invertible if 
		$$det(\begin{bmatrix} 1 & 2 & -1 \\ 2 & 3 & c \\ 0 & c & -15 \end{bmatrix})=-c^2-2c+15\neq 0$$
		$\Rightarrow$
		$$ c\neq =-5,3.$$
\end{SaveQuestion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{SaveQuestion}[
        key=ch6-det-invelem-sbg,
        prompt={Consider the following matrix $A$. $$A=\begin{bmatrix} 1 & 2 & -1 \\ 2 & 3 & 1 \\ 0 & 1& -15 \end{bmatrix}$$ Note that we can use three elementary row reduction steps to reduce $A$ into the following matrix $A_2$. $$A_2=\begin{bmatrix} 1 & 2 & -1 \\ 0 & 1 & -3 \\ 0 & 0 & -12 \end{bmatrix}$$ \begin{enumerate}\item Find elementary matrices $E_1, E_2$ and $E_3$ such that $E_3 E_2 E_1 A = A_2$. \item What is $\det E_1$, $\det E_2$, $\det E_3$, and $\det A_2$, and how are these related to $\det A$? \item Use elementary row operations to compute $\det A$. \end{enumerate} }
][ch6-CON-rowred]
%list with no spaces between commas
    [All three elementary matrices are correctly found.*The determinants of the respective matrices are computed correctly.*Using the multiplicative property of determinants, the det(A) is correctly calculated.*]    %this is written as a comma seperated list with no spaces between commas
    %[<items mark>]      %this is written as a comma seperated list with no spaces between commas
    Recall that an elementary matrix induces an elementary row operation (e.g., adding columns, multiplying columns). 
    \begin{enumerate}
        \item To find the elementary matrices $E_1, E_2$ and $E_3$, we may first determine the elementary row operations required to reduce $A$ to $A_2$, and then take $E_1$ and $E_2$ to represent those row operations. Notably, we have the following.
        $$A = \begin{bmatrix} 1 & 2 & -1 \\ 2 & 3 & 1 \\ 0 & 1& -15 \end{bmatrix} \underset{\rightarrow}{R_2: -2R_1 + R_2} \begin{bmatrix} 1 & 2 & -1 \\ 0 & -1 & 3 \\  0 & 1 & -15 \end{bmatrix} \underset{\rightarrow}{R_3: R_3 + R_2} \begin{bmatrix} 1 & 2 & -1 \\ 0 & -1 & 3 \\ 0 & 0 & -12 \end{bmatrix} \underset{\rightarrow}{R_2: -R_2} \begin{bmatrix} 1 & 2 & -1 \\ 0 & 1 & -3 \\ 0 & 0 & -12 \end{bmatrix} = A_2$$
        Consequently, it must be that $E_1$ induces the row operation $R_2: -2R_1 + R_2$, $E_2$ induces the row operation $R_3: R_2 + R_3$, and $E_3$ induces the row operation $R_2: -R_2$. This yields the following elementary matrices.
        $$E_1 = \begin{bmatrix} 1 & 0 & 0 \\ -2 & 1 & 0 \\ 0 & 0 & 1 \end{bmatrix} \quad E_2 = \begin{bmatrix} 1 & 0 & 0 \\ 0 & 1 & 0 \\ 0 & 1 & 1 \end{bmatrix} \quad E_3 = \begin{bmatrix} 1 & 0 & 0 \\ 0 & -1 & 0 \\ 0 & 0 & 1 \end{bmatrix}$$
        Hence, we have found elementary matrices $E_1, E_2, E_3$ such that $E_3 E_2 E_1 A = A_2$, as needed.
        
        \item Recall the following. The determinant of an elementary matrix inducing a row addition is 1, whereas, if it induces scaling a row the determinant is the value of the scalar. Thus, we know the $\det E_1 = 1, \det E_2 = 1$ (row addition), and $\det E_3 = -1$ (scaling row). Furthermore, we remark that $A_2$ is a triangular matrix. Moreover, we know that the determinant of a triangular matrix is the product of its columns, so $\det A_2 = -12$. \\ \\ 
        Generally, we know that the product of determinants is equal to the determinant of the product, that is, $\det(AB) = \det A \det B$.  Since $E_3 E_2 E_1 A = A_2$, this implies the following.
        \begin{align*}
            \det(E_3 E_2 E_1 A)                 &= \det A_2                                     &\text{By Definition.} \\
            \det E_3 \det E_2 \det E_1 \det A   &= \det A_2                                     &\text{Product Rule.} \\
            \det A                              &= \frac{\det A_2}{\det E_3 \det E_2 \det E_1}  &\text{Cancelation Propety.}
        \end{align*}

        \item Note that we have completed the necessary steps to compute $\det A$ using elementary row operations. Notably, in the previous part we showed that,
        $$\det A = \frac{\det A_2}{\det E_3 \det E_2 \det E_1},$$
        where $E_1, E_2, E_3$ are elementary matrices used to reduce $A$ to $A_2$. Therefore, we have the following.
        $$\det A = \frac{\det A_2}{\det E_3 \det E_2 \det E_1} = \frac{-12}{-1 \cdot 1 \cdot 1} = 12$$
        Hence, we have computed that $\det A = -12$ using elementary row operations, as needed. 
    \end{enumerate}
\end{SaveQuestion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{SaveQuestion}[
        key=ch6-det-vecaddition-sbg,
        prompt={Let $\vec{a},\vec{b},\vec{c},\vec{d}\in\bbR^2$. Can you find expressions for the determinants below so that there are no sums of vectors inside the matrices? Justify your reasoning. 
	\begin{enumerate}
		\item $\det [ \, \vec{a}+\vec{b} \ \ \vec{c} \, ]$
		\item $\det [ \, \vec{a} \ \ \vec{b}+\vec{c} \, ]$
		\item $\det [ \, \vec{a}+\vec{b} \ \ \vec{c}+\vec{d} \, ]$
	\end{enumerate}}
][ch6-CON-bilin] %this is written as a comma seperated list with no spaces between commas
    %[<rubric items>]    %this is written as a comma seperated list with no spaces between commas
    %[<items mark>]      %this is written as a comma seperated list with no spaces between commas
    \begin{enumerate}
	\item $\det [ \, \vec{a} \ \ \vec{c} \, ]+\det [ \, \vec{b} \ \ \vec{c} \, ]$
	\item $\det [ \, \vec{a} \ \ \vec{b} \, ]+\det [ \, \vec{a} \ \ \vec{c} \, ]$
	\item $\det [ \, \vec{a} \ \ \vec{c} \, ]+\det [ \, \vec{a} \ \ \vec{d} \, ]+\det [ \, \vec{b} \ \ \vec{c} \, ]+\det [ \, \vec{b} \ \ \vec{d} \, ]$
    \end{enumerate}
\end{SaveQuestion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{SaveQuestion}[
        key=ch6-det-operationstf-sbg,
        prompt={Decide whether each statement is true or false. Justify. If you think the statement is false, give a counterexample. 
	\begin{enumerate}
		\item[(a)] $\det(A^T)=\det(A)$
		\item[(b)] $\det(kA)=k\cdot \det(A)$ for all $k\in\bbR$
		\item[(c)] $\det(A+B)=\det(A)+\det(B)$
		\item[(d)] $\det(AB)=\det(A)\cdot\det(B)$ 
	\end{enumerate}}
][chg-CON-tf,ch6-COM-detprop] %this is written as a comma seperated list with no spaces between commas
        %%%%MUST GET ALL 4 PARTS CORRECT TO EARN STANDARD 6.5%%%%
    %[<rubric items>]    %this is written as a comma seperated list with no spaces between commas
    %[<items mark>]      %this is written as a comma seperated list with no spaces between commas
    \begin{enumerate}
			\item[(a)] True. We can expand along the first row of $A$ which will be the first column of $A^T$
			\item[(b)] False. $\det (kA)=k^n\det A$ where $n$ is the size of the matrix. Find a counter example. 
			\item[(c)] False. Find a counterexample 
			\item[(d)] True. We saw this in class
		\end{enumerate}	
\end{SaveQuestion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{SaveQuestion}[
        key=ch6-det-compute-sbg,
        prompt={Choose either questions (A) and (B), or (1) and (2), find the determinant of the given matrices and show your work. \begin{enumerate} \item[(A)] $\begin{bmatrix} 6 & 3 & 2 & 4 & 0 \\ 9 & 0 & -4 & 1 & 0 \\ 8 & -5 & 6 & 7 & 1 \\ 3 & 0 & 0 & 0 & 0 \\ 4 & 2 & 3 & 2 & 0 \end{bmatrix}$   \item[(B)] $\begin{bmatrix} 3 & 2 & 1 \\ 0 & -1 & 2 \\ 0 & 0 & 5 \end{bmatrix}$ \\ \\ \textbf{Or} \item[(1)] $\begin{bmatrix} 0 & 5 & 1 \\ 4 & -3 & 0 \\ 2 & 4 & 1 \end{bmatrix}$
         \item[(2)] $\begin{bmatrix} 4 & 0 & 0 & 0 \\ 7 & -1 & 0 & 0 \\ 2 & 6 & 3 & 0 \\ 5 & -8 & 4 & -3 \end{bmatrix}$ \end{enumerate}}
][ch6-COM-det,chg-WRIT-matnot] %this is written as a comma seperated list with no spaces between commas
    [Correct determinant with justification*,Good determinant notation*]    %this is written as a comma seperated list with no spaces between commas
    %[<items mark>]      %this is written as a comma seperated list with no spaces between commas
    \begin{enumerate}
        \item[(A)] $det \begin{bmatrix} 6 & 3 & 2 & 4 & 0 \\ 9 & 0 & -4 & 1 & 0 \\ 8 & -5 & 6 & 7 & 1 \\ 3 & 0 & 0 & 0 & 0 \\ 4 & 2 & 3 & 2 & 0 \end{bmatrix}
        = 0(1)det \begin{bmatrix} 9 & 0 & -4 & 1 \\ 8 & -5 & 6 & 7 \\ 3 & 0 & 0 & 0 \\ 4 & 2 & 3 & 2 \end{bmatrix}
        + 0(-1)det \begin{bmatrix} 6 & 3 & 2 & 4 \\ 8 & -5 & 6 & 7 \\ 3 & 0 & 0 & 0 \\ 4 & 2 & 3 & 2 \end{bmatrix}
        + 1(1)det \begin{bmatrix} 6 & 3 & 2 & 4 \\ 9 & 0 & -4 & 1 \\ 3 & 0 & 0 & 0 \\ 4 & 2 & 3 & 2 \end{bmatrix}
        + 0(-1)det \begin{bmatrix} 6 & 3 & 2 & 4 \\ 9 & 0 & -4 & 1 \\ 8 & -5 & 6 & 7 \\ 4 & 2 & 3 & 2 \end{bmatrix}
        + 0(1)det \begin{bmatrix} 6 & 3 & 2 & 4 \\ 9 & 0 & -4 & 1 \\ 8 & -5 & 6 & 7 \\ 3 & 0 & 0 & 0 \end{bmatrix}$
        \\ 
        $ = det \begin{bmatrix} 6 & 3 & 2 & 4 \\ 9 & 0 & -4 & 1 \\ 3 & 0 & 0 & 0 \\ 4 & 2 & 3 & 2 \end{bmatrix} $
        \\ 
        $= 3(1)det \begin{bmatrix} 3 & 2 & 4 \\ 0 & -4 & 1 \\ 2 & 3 & 2 \end{bmatrix}
        = 3\left( 3(1)det\begin{bmatrix} -4 & 1 \\ 3 & 2 \end{bmatrix} + 2(1)det\begin{bmatrix} 2 & 4 \\ -4 & 1 \end{bmatrix}   \right) = 3( 3((-4)(2)-(1)(3)) + 2((2)(1)-(4)(-4))   ) = 9
        $ 
        \item[(B)] $ det\begin{bmatrix} 3 & 2 & 1 \\ 0 & -1 & 2 \\ 0 & 0 & 5 \end{bmatrix} = 3det\begin{bmatrix} -1 & 2 \\ 0 & 5 \end{bmatrix}$ \\ $ = 3((-1)(5)-(2)(0)) = (3)(-1)(5) = -15$ \\ 
        Note: In upper or lower triangular matrices the determinant turns out to be the diagonal entries multiplied together, as shown.
        \item[(1)] $det\begin{bmatrix} 0 & 5 & 1 \\ 4 & -3 & 0 \\ 2 & 4 & 1 \end{bmatrix} = det\begin{bmatrix} 4 & -3 \\ 2 & 4 \end{bmatrix} + det\begin{bmatrix} 0 & 5 \\ 4 & -3 \end{bmatrix} $ \\
        $= (4)(4)-(2)(-3)+(0)(-3)-(5)(4) = 16 + 6 - 20 = 2$
        \item[(2)] $det\begin{bmatrix} 4 & 0 & 0 & 0 \\ 7 & -1 & 0 & 0 \\ 2 & 6 & 3 & 0 \\ 5 & -8 & 4 & -3 \end{bmatrix} = 4det\begin{bmatrix} -1 & 0 & 0 \\ 6 & 3 & 0 \\ -8 & 4 & -3 \end{bmatrix} = 4(-1)det\begin{bmatrix} 3 & 0 \\ 4 & -3 \end{bmatrix}$ \\ $ = (4)(-1)((3)(-3)-(0)(4)) = (4)(-1)(3)(-3) = 36$ \\
        Note: In upper or lower triangular matrices the determinant turns out to be the diagonal entries multiplied together, as shown.
    \end{enumerate}
\end{SaveQuestion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{SaveQuestion}[
        key=ch6-det-bilinear-dev,
        prompt={Let $k\in\bbR$ and let $A=\begin{bmatrix} a & b \\ c & d \end{bmatrix}$, $B=\begin{bmatrix} u & v \\ c & d \end{bmatrix}$, and $C=\begin{bmatrix} q & b \\ s & d \end{bmatrix}$.
        \begin{enumerate}
        \item Use the formula for the determinant of a $2\times 2$ matrix to compute the following determinants in terms of $\det A, \det B, \det C$ (when applicable).  
        \begin{enumerate}
        \item[(a)] $\det\begin{bmatrix} ka & b \\ kc & d \end{bmatrix}$ 
        \item[(b)] $\det\begin{bmatrix} a & b \\ kc & kd \end{bmatrix}$ 
        \item[(c)] $\det\begin{bmatrix} c & d \\ a & b \end{bmatrix}$ 
        \item[(d)] $\det\begin{bmatrix} b & a \\ d & c \end{bmatrix}$ 
        \item[(e)] $\det\begin{bmatrix} a+u & b+v \\ c & d \end{bmatrix}$
        \item[(f)] $\det\begin{bmatrix} a+q & b \\ c+s & d \end{bmatrix}$
        \end{enumerate}
        \item Generalize the results from (a)-(d) for a $n \times n$ matrix by providing a written description. 
        \item If $A$ is an $n\times n$ matrix, what is the relation between $\det A$ and $\det(-A)$?
        \item If $A$ is an $n \times n$ invertible matrix, what is the relation between $\det A$ amd $\det A^{-1}$
        \end{enumerate}
        \textbf{DEV Hints}
        \begin{itemize}
            \item What effect will multiplying a row or column of a matrix by a scalar have on the determinant of the matrix? Generalize this.
            \item Is there a theorem from the PCE that confirms the previous hint's generalization? State it.
            \item Given $\det A$, which rows or columns of A would you have to multiply in order to get $\det (-A)$?
        \end{itemize}}
][ch6-CON-bilin, ch6-COM-detprop] %this is written as a comma seperated list with no spaces between commas
    [Satisfactory: Correctly generalizes results from part 1 in addition to drawing conclusions about the relationship between the determinant of A/-A/the inverse of A.*Can be improved: Somewhat correct yet solution contains some errors.*Try Again: Mostly incorrect or no attempt is made.*]    %this is written as a comma seperated list with no spaces between commas
    %[<items mark>]      %this is written as a comma seperated list with no spaces between commas
    \begin{enumerate}
        \item Briefly, we note that $\det A = ad - bc$. 
        \begin{enumerate}
            \item[(a)] $\det\begin{bmatrix} ka & b \\ kc & d \end{bmatrix} = (ka)(d) - (kc)(b) = k(ad) - k(bc) = k(ad - bc) = k\det A$. 

            \item[(b)] $\det\begin{bmatrix} a & b \\ kc & kd \end{bmatrix} = a(kd) - b(kc) = k(ad) - k(bc) = k(ad - bc) = k\det A$. 

            \item[(c)] $\det\begin{bmatrix} c & d \\ a & b \end{bmatrix} = cb - da = bc - ad = -(ad - bc) = -\det A$. 

            \item[(d)] $\det\begin{bmatrix} b & a \\ d & c \end{bmatrix} = bc - ad = -(ad - bc) = -\det A$.

            \item[(e)] $\det\begin{bmatrix} a+u & b+v \\ c & d \end{bmatrix} = (a + u)(d) - (b + v)(c) = ad + ud - bc - bv = (ad - bc) + (ud - bv) = \det A + \det B$. 

            \item[(f)] $\det\begin{bmatrix} a+q & b \\ c+s & d \end{bmatrix} = (a + q)(d) - (b)(c + s) = ad + qd - bc - bs = (ad - bc) + (qd - bs) = \det A + \det C$. 
        \end{enumerate}
        \item
        \begin{itemize}
            \item[(a)] Scaling a matrix column by $k$ changes the determinant by a factor of $k$.
            \item[(b)] Scaling a matrix row by $k$ changes the determinant by a factor of $k$. 
            \item[(c)] Swapping two matrix columns changes the determinant by a factor of $-1$. 
            \item[(d)] Swapping two matrix rows changes the determinant by a factor of $-1$.
        \end{itemize}
        \item To derive a relationship between $\det A$ and $\det (-A)$, consider the property from (a) or (b). Notice that to obtain $(-A)$ is equivalent to multiplying each row (or column) by $-1$. Since there are $n$ rows (or columns), we obtain that $\det(-A) = (-1)^n \det A$. 

        \item To derive a relationship between $\det A$ and $\det A^{-1}$, consider that by definition $ A^{-1} A = I_n$ where $I_n$ is the $n \times n$ matrix. Moreover, we know that $\det A^{-1} \det A = \det (A^{-1}A) = \det I_n = 1$. Therefore, we may equivalently write the following.
        $$\det A^{-1} = \frac{1}{\det A}$$
        Moreover, this condition is necessarily true since $\det A$ is never zero if $A$ is invertible. 
    \end{enumerate}
\end{SaveQuestion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{SaveQuestion}[
        key=ch6-det-elem-dev,
        prompt={Let $A$ be a $2\times 2$ matrix, and suppose $B$ is obtained from $A$ by performing a single elementary row operation. Can you describe $\det B$ in terms of $\det A$?  Remember that you have three different types of elementary row operations to consider.}
][ch6-CON-rowred] %this is written as a comma seperated list with no spaces between commas
    %[<rubric items>]    %this is written as a comma seperated list with no spaces between commas
    %[<items mark>]      %this is written as a comma seperated list with no spaces between commas
    read sec 6.1/6.2 for solution
\end{SaveQuestion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{SaveQuestion}[
        key=ch6-det-elemcompute-sbg,
        prompt={Use elementary row operations to help compute the determinant of the following matrix. $$A = \begin{bmatrix} \frac{1}{2} & -\frac{3}{2} & -\frac{1}{2} & \frac{5}{2} \\ 2 & -4 & -2 & 8 \\ -1 & 3 & 6 & -1 \\ 1 & -3 & -1 & 2 \end{bmatrix}$$ Reminder, we only need to reduce to row echelon form.}
][ch6-CON-rowred]
    [Performs a correctly-applied sequence of row operations.*Correctly identifies each of the elementary matrices.*]
    
    Recall that if we can find elementary matrices $E_1, ..., E_k$ that induce the reduction of the matrix $A$ to REF form, we can find the determinant of the matrix. 
    $$A = \begin{bmatrix} \frac{1}{2} & -\frac{3}{2} & -\frac{1}{2} & \frac{5}{2} \\ 2 & -4 & -2 & 8 \\ -1 & 3 & 6 & -1 \\ 1 & -3 & -1 & 2 \end{bmatrix} \underset{R_2: -4R_1 + R_2}{\rightarrow} \begin{bmatrix} \frac{1}{2} & -\frac{3}{2} & -\frac{1}{2} & \frac{5}{2} \\ 0 & 2 & 0 & -2 \\ -1 & 3 & 6 & -1 \\ 1 & -3 & -1 & 2 \end{bmatrix} \underset{R_3: 2R_1 + R_3}{\rightarrow} \begin{bmatrix} \frac{1}{2} & -\frac{3}{2} & -\frac{1}{2} & \frac{5}{2} \\ 0 & 2 & 0 & -2 \\ 0 & 0 & 5 & 4 \\ 1 & -3 & -1 & 2 \end{bmatrix} \underset{R_4: -2R_1 + R_4}{\rightarrow} \begin{bmatrix} \frac{1}{2} & -\frac{3}{2} & -\frac{1}{2} & \frac{5}{2} \\ 0 & 2 & 0 & -2 \\ 0 & 0 & 5 & 4 \\ 0 & 0 & 0 & -3\end{bmatrix}$$
    Fix $B$ to be the REF of $A$, and let $E_1, E_2, E_3$ represent the row operations above, respectively.
    $$E_1 = \begin{bmatrix} 1 & 0 & 0 & 0 \\ -4 & 1 & 0 & 0 \\ 0 & 0 & 1 & 0 \\ 0 & 0 & 0 & 1 \end{bmatrix} \quad E_2 = \begin{bmatrix} 1 & 0 & 0 & 0 \\ 0 & 1 & 0 & 0 \\ 0 & 2 & 1 & 0 \\ 0 & 0 & 0 & 1 \end{bmatrix} \quad E_4 = \begin{bmatrix} 1 & 0 & 0 & 0 \\ 0 & 1 & 0 & 0 \\ 0 & 0 & 1 & 0 \\ -2 & 0 & 0 & 1 \end{bmatrix}$$
    Since $E_3 E_2 E_1 A = B$, it holds that $\det E_3 \det E_2 \det E_1 \det A = \det B$. Therefore, we have the following $\det A = \frac{\det B}{\det E_3 \det E_2 \det E_1} = \frac{-15}{1 \cdot 1 \cdot 1} = -15$
\end{SaveQuestion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{SaveQuestion}[
        key=ch6-det-eigenvec-sbg,
        prompt={Let $A= \begin{bmatrix} -7 & 6 & 6 \\ 0 & -1 & 0 \\ -12 & 12 & 11 \end{bmatrix}$, and let $\lambda\in\bbR$.
        \begin{enumerate} 
            \item What is the relationships between the invertibility of a matrix and it's determinant? 
            \item Use determinants to find all values of $\lambda$ for which the matrix $A -\lambda I_3$ is \emph{not} invertible. Note that $I_3$ is the $3 \times 3$ identity matrix.
        \end{enumerate}}
][ch6-CON-invcheck] %this is written as a comma seperated list with no spaces between commas
    [Correct $\lambda$ values using determinant calculations.*]
    \begin{enumerate}
        \item For any square matrix $A$, we know that $A$ is invertible if and only $\det A \neq 0$. 
        \item Using the relationship above, we know that $A$ is not invertible precisely for values $\lambda$ that satisfy $\det \left(A - \lambda I_3\right) = 0$. First, we compute $A - \lambda I_3$.
        $$A - \lambda I_3 = \begin{bmatrix} -7 & 6 & 6 \\ 0 & -1 & 0 \\ -12 & 12 & 11 \end{bmatrix} - \begin{bmatrix} \lambda & 0 & 0 \\ 0 & \lambda & 0 \\ 0 & 0 & \lambda \end{bmatrix} = \begin{bmatrix} -7 - \lambda & 6 & 6 \\ 0 & -1 - \lambda & 0 \\ -12 & 12 & 11 - \lambda \end{bmatrix}$$
        Next, we must compute the determinant of $\det\left(A - \lambda I_3\right)$. Noting that the middle row is primarily zeroes, we will use cofactor expansion along this row.
        $$\det\left(A - \lambda I_3\right) = (-1 - \lambda) \det \begin{bmatrix}  -7 - \lambda & 6 \\ -12 & 11 - \lambda \end{bmatrix} = (-1 - \lambda)((-7 - \lambda)(11 - \lambda) - (6)(-12)) = -\lambda^3 + 3\lambda^2 + 9\lambda + 5$$
        Consequently, we know that the roots of $ -\lambda^3 + 3\lambda^2 + 9\lambda + 5$ correspond to the values of $\lambda$ for which $A - \lambda I_3$ is not invertible. This occurs precisely when $\lambda = -1, 5$.  
    \end{enumerate}
\end{SaveQuestion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{SaveQuestion}[
        key=ch7-diagonal-eigenbasis-dev,
        prompt={Let $A=\begin{bmatrix} -7 & 6 & 6 \\ 0 & -1 & 0 \\ -12 & 12 & 11 \end{bmatrix}$, and let $\lambda\in\bbR$. \begin{enumerate} \item Use determinants to find all values of $\lambda$ for which the matrix $A-\lambda I_3$ is \emph{not} invertible. \item For each value of $\lambda$ you found in (1), find a basis $\mathcal{B}_{\lambda}$ of $\ker(A-\lambda I_3)$. \item For each value of $\lambda$ that you found in (1), find a nonzero vector $\vec{v}\in\bbR^3$ such that $A\vec{v}=\lambda\vec{v}$. How many such vectors can you find? how many linearly independent such vectors can you find. \item Verify that the union $\mathcal{B}$ of the bases $\mathcal{B}_\lambda$ that you found in (2) form a basis of $\bbR^3$. Find the $\mathcal{B}$-matrix --- call it $D$ --- of the linear transformation $T_A$ given by $A$ (recall that $\mathcal{B}$-matrix of the linear transformation $T_A$ has $\mathcal B$-coordinates of image of vectors in $\mathcal B$ as its columns) \item Write an equation showing that $A$ and $D$ are similar; that is, find an invertible matrix $P$ such that $A=PDP^{-1}$. \item Calculate $A^{99}$. \end{enumerate} }
][ch7-CON-diaglintrans,ch7-COM-algmult,ch7-COM-eigenbas] %this is written as a comma seperated list with no spaces between commas
    [Satisfactory: Mostly correct with some computation mistakes*Can Be Improved: Mistakes that are not conceptual*Try Again: Wrong Concepts*]    %this is written as a comma seperated list with no spaces between commas
    %[<items mark>]      %this is written as a comma seperated list with no spaces between commas
    \begin{enumerate}
        \item We just need to find the values of $\lambda$ such that $ det(A-\lambda I_3)=0.$ (ie: Zero determinant means non-invertible.)
		$$ \det(\begin{bmatrix} -7 & 6 & 6 \\ 0 & -1 & 0 \\ -12 & 12 & 11 \end{bmatrix}-\lambda I_3)=0$$
		$\Leftrightarrow$
		$$ \det(\begin{bmatrix} -7-\lambda & 6 & 6 \\ 0 & -1-\lambda & 0 \\ -12 & 12 & 11-\lambda \end{bmatrix})=0$$
		$\Leftrightarrow$
		$$-{\lambda}^3+3{\lambda}^2+9{\lambda}+5=0$$
		$\Leftrightarrow$
		$$(\lambda+1)(\lambda+1)(\lambda-5)=0$$
		So the values are $-1,-1,5$.
        \item For $\lambda=5,$ consider the following homogeneous system.
		$$ (A-\lambda I_3)\vec{x}=0 $$
		$\Leftrightarrow$
		$$\begin{bmatrix} -12 & 6 & 6 \\ 0 & -6 & 0 \\ -12 & 12 & 6 \end{bmatrix}\vec{x}=0$$
		$\Leftrightarrow$
		$$\begin{bmatrix} -12 & 6 & 6 \\ 0 & -6 & 0 \\ 0 & 0 & 0 \end{bmatrix}(\vec{x}=\begin{bmatrix} x_1  \\ x_2 \\ x_3 \end{bmatrix})=0$$
		This shows the $x_3$ is a free variable and we may let $x_3=s,s\in \mathbb{R}.$
		$\Rightarrow$
		$x_2=0,x_1=0.5s,x_3=s$ The solution space is spanned by 
		$$\vec{x}=\begin{bmatrix} x_1  \\ x_2 \\ x_3 \end{bmatrix}=s\begin{bmatrix} 0.5  \\ 0 \\ 1 \end{bmatrix} $$
		The basis vector just 
		$$\mathcal{B}_{5}=\{\begin{bmatrix} 0.5  \\ 0 \\ 1 \end{bmatrix} .\}$$
		You can use the same way to compute a basis for $\lambda=-1.$. 
		
			$$\mathcal{B}_{-1}=\{\begin{bmatrix} 1  \\ 0 \\ 1 \end{bmatrix} , \begin{bmatrix} 1  \\ 1 \\ 0 \end{bmatrix}\}$$
        \item For $\lambda=-1$,  $\vec{v}_1=[1 ,0, 1] ,\vec{v}_2=[1 ,1 ,0].$
		For $\lambda=5$, $\vec{v}_3=[1, 0, 2] .$
		
		For each $\lambda$ we can find infinity many such vectors. The number of linearly independent such vectors depends on the dimension of $\ker (A-\lambda I)$.
        \item $$\mathcal{B}=\{\begin{bmatrix} 0.5  \\ 0 \\ 1 \end{bmatrix}, \begin{bmatrix} 1  \\ 0 \\ 1 \end{bmatrix} , \begin{bmatrix} 1  \\ 1 \\ 0 \end{bmatrix}\}$$
		
We can use row reduction to veify $\mathcal B$ is linearly independent. Three linearly independent vectors in $\mathbb{R}^3$ make a basis for $\mathbb{R}^3$. 
		
		$$[T]_\mathcal B=\begin{bmatrix} -1 & 0 & 0 \\ 0 & -1 & 0 \\ 0 & 0 & 5 \end{bmatrix}$$
        \item Let $P=\begin{bmatrix} | & | & | \\ \vec{v}_1 & \vec{v}_2 & \vec{v}_3 \\ | & | & | \end{bmatrix}=\begin{bmatrix} 1 & 1 & 1 \\ 0 & 1 & 0 \\ 1 & 0 & 2 \end{bmatrix}$\\
		and\\
		$D=\begin{bmatrix} -1 & 0 & 0 \\ 0 & -1 & 0 \\ 0 & 0 & 5 \end{bmatrix}$
        \item $$ A^{99}=(PDP^{-1})^{99}$$
		$\Leftrightarrow$
		$$ A^{99}=(PDP^{-1})(PDP^{-1})\underbrace{...}_{\text{99 times}}(PDP^{-1})$$
		$$ =PD(P^{-1}P)D(P^{-1}P)D(P^{-1}\underbrace{...}_{\text{99 times}}(P^{-1}P)DP^{-1}$$
		$$=PD^{99}P^{-1}$$
		$$=P\begin{bmatrix} (-1)^{99} & 0 & 0 \\ 0 & (-1)^{99} & 0 \\ 0 & 0 & (5)^{99} \end{bmatrix}P^{-1}.$$
    \end{enumerate}
\end{SaveQuestion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{SaveQuestion}[
        key=ch7-eigen-geomexamples-sbg,
        prompt={Review the following definitions \\ \noindent{\bf Definition.} Let $V \overset{T}\longrightarrow V$ be a linear transformation. An {\bf eigenvector} of $T$ is a {\it non-zero} vector $\vec v \in V$ such that $T(\vec v) = \lambda \vec v$ for some scalar $\lambda$. The scalar $\lambda$ is  the {\bf eigenvalue} of the eigenvector $\vec v$. \\ \noindent We say $\lambda$ is an eigenvalue of $T$ if there is some non-zero vector in $V$ which is an eigenvector of $T$ with eigenvalue $\lambda$. \\ \noindent{\bf Definition.} An {\bf eigenbasis} for a linear transformation $T$ is a basis for $V$ consisting of eigenvectors of $T$.  \begin{enumerate} \item Find all eigenvectors of the {\it identity map} $V \rightarrow V$. What are the associated eigenvalues? \item Find all eigenvectors of the {\it zero  map} $V \rightarrow V$. What are the associated eigenvalues? \item  Let $T: \mathbb{R}^2 \rightarrow  \mathbb{R}^2$ be the map "scale by 2". What is the (standard)  matrix of $T$? What are the eigenvectors of $T$? What are the associated eigenvalues? \item  Let $T: \mathbb{R}^2 \rightarrow  \mathbb{R}^2$  be multiplication by $\begin{bmatrix} 3 & 0 \\ 0 & 4 \end{bmatrix}$. Explain why any non-zero vector in the span of $\vec e_1$ is an eigenvector. What are the corresponding  eigenvalues? Find all eigenvectors with eigenvalue 4.  Are there any  eigenvectors with eigenvalue zero. Can $k \neq 3, 4$ be an eigenvalue? \end{enumerate} }
][ch7-VG-geotrans] %this is written as a comma seperated list with no spaces between commas
    %[<rubric items>]    %this is written as a comma seperated list with no spaces between commas
    %[<items mark>]      %this is written as a comma seperated list with no spaces between commas
    \begin{enumerate}
        \item[(1-3)] Every non-zero vector is an eigenvector of the identity map, with eigenvalue 1. \\  Every non-zero vector is an eigenvector of the zero map, with eigenvalue 0. \\
		Every non-zero vector is an eigenvector of the ``scale by $k$" map, with eigenvalue $k. $
        \item[(4)] Note that $T(k\vec e_1) = 3k \vec e_1$, so $k\vec e_1$ is an eigenvector with eigenvalue 3. The eigenvectors with eigenvalue $4$ are the vectors  $\begin{bmatrix} a \\ b \end{bmatrix}$ such that $T(\begin{bmatrix} a \\ b \end{bmatrix}) = 4 \begin{bmatrix} a \\ b \end{bmatrix}$. To find them,  we solve $ \begin{bmatrix} 3a  \\ 4 b \end{bmatrix} = 
		4 \begin{bmatrix} a \\ b \end{bmatrix} =   \begin{bmatrix} 4a \\ 4b \end{bmatrix} $. We must have $a = 0$, but $b$ can be arbitrary. So the eigenvectors with eigenvalues $4$ are exactly the span of $\vec e_2$ (except for $\vec 0)$.
    \end{enumerate}
\end{SaveQuestion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{SaveQuestion}[
        key=ch7-diagonal-3eigenvalues-sbg,
        prompt={Suppose $A$ is an $n \times n$ matrix for the following theorems. \\ \textbf{Theorem 1:}    $A$ is diagonalizable if and only if $A$ has an eigenbasis. \\
        \textbf{Theorem 2:} $A$ is diagonalizable if and only if $A$ is similar to a diagonal matrix. \\ \vspace{0.5} \\ Let $A=\begin{bmatrix} -1&4&-2\\-3&4&0\\-3&1&3 \end{bmatrix}$. \begin{enumerate} \item Find $\mathrm{Char}(A)$. \item We know $\lambda=1$ is an eigenvalue of $A$. Find all eigenvalues of $A$. \item Is $A$ diagonalizable, why? (You don't need any calculation to answer to this question.) \item Find two different eigenbasis for $A$. What subspace are these a basis of? \item Find an invertible matrix $P$ and a diagonal matrix $D$ such that $A=PDP^{-1}$. \item Find a different matrix $P'$ such that $A=P'DP'^{-1}$. \item What is a relationship between each column of $P$ and the corresponding column of $P'$?\end{enumerate} }
][ch7-CON-diaglintrans,ch7-CON-diagcmat] %this is written as a comma seperated list with no spaces between commas
    [Correct parts 1-4*,Correct parts 5-7*]    %this is written as a comma seperated list with no spaces between commas
    %[<items mark>]      %this is written as a comma seperated list with no spaces between commas
    \begin{enumerate}
			\item $Char(A) = \det (A-\lambda I) = -\lambda^3 + 6\lambda^2 - 11\lambda + 6$
			\item If we know $\lambda = 1$ is an eigenvalue, then we know $(1-\lambda)$ is a factor of $Char(A)$\\
			Therefore, $Char(A) =-\left(\lambda-1\right)\left(\lambda-2\right)\left(\lambda-3\right)$. Hence, $\lambda_1 = 1,\ \lambda_2 = 2,\ \lambda_3 = 3$
			\item $A$ is diagonalizable because it has n (= 3) distinct eigenvalues.
			\item $RREF(A-\lambda_1I) = \begin{bmatrix}
			1&0&-1\\0&1&-1\\0&0&0
			\end{bmatrix} \leftrightarrow {E_{\lambda}}_1 = \left\{\begin{bmatrix}
			1\\1\\1
			\end{bmatrix}\right\}$\\
			$RREF(A-\lambda_2I) = \begin{bmatrix}
			1&0&-2/3\\0&1&-1\\0&0&0
			\end{bmatrix} \leftrightarrow {E_{\lambda}}_2 = \left\{\begin{bmatrix}
			2\\3\\3
			\end{bmatrix}\right\}$\\
			$RREF(A-\lambda_3I) = \begin{bmatrix}
			1&0&-1/4\\0&1&-3/4\\0&0&0
			\end{bmatrix} \leftrightarrow {E_{\lambda}}_3 = \left\{\begin{bmatrix}
			1\\3\\4
			\end{bmatrix}\right\}$ \\
            Basis 1: $\left\{\begin{bmatrix}
			1\\1\\1
			\end{bmatrix},
            \begin{bmatrix}
			2\\3\\3
			\end{bmatrix},
            \begin{bmatrix}
			1\\3\\4
			\end{bmatrix}
            \right\}$ \\
            Basis 2: $\left\{\begin{bmatrix}
			2\\2\\2
			\end{bmatrix},
            \begin{bmatrix}
			6\\9\\9
			\end{bmatrix},
            \begin{bmatrix}
			-1\\-3\\-4
			\end{bmatrix}
            \right\}$ \\
            These are both a basis for the subspace $\bbR^3$
			\item $P = \begin{bmatrix}
			\vert &\vert &\vert\\ {\vec{v_{\lambda}}}_1 & {\vec{v_{\lambda}}}_2  &{\vec{v_{\lambda}}}_3\\ \vert &\vert &\vert
			\end{bmatrix} = \begin{bmatrix}
			1&2&1\\1&3&3\\1&3&4
			\end{bmatrix}$ and $D = \begin{bmatrix}
			\lambda_1 & 0 & 0 \\ 0 & \lambda_2 & 0 \\ 0 & 0 & \lambda_3
			\end{bmatrix} = \begin{bmatrix}
			1 & 0 & 0 \\ 0 & 2 & 0 \\ 0 & 0 & 3
			\end{bmatrix}$
			\item Take column vectors of $P'$ to be any scalar multiple of column of $P$.
			$P' =\begin{bmatrix}
			\vert &\vert &\vert\\ 2{\vec{v_{\lambda}}}_1 & 3{\vec{v_{\lambda}}}_2  & -{\vec{v_{\lambda}}}_3\\ \vert &\vert &\vert
			\end{bmatrix}$\\
			\item They are scalar multiples of eachother.
		\end{enumerate}
\end{SaveQuestion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{SaveQuestion}[
        key=ch7-diagonal-2eigenvalues-sbg,
        prompt={Suppose $A$ is an $n \times n$ matrix for the following theorems. \\ \textbf{Theorem 1:}    $A$ is diagonalizable if and only if $A$ has an eigenbasis. \\
        \textbf{Theorem 2:} $A$ is diagonalizable if and only if $A$ is similar to a diagonal matrix.  \\ \vspace{0.5} \\ Let $A=\begin{bmatrix} 4&0&-2\\2&5&4\\0&0&5 \end{bmatrix}$. \begin{enumerate} \item Find $\mathrm{Char}(A)$. \item We know $\lambda=5$ is an eigenvalue of $A$. Find all eigenvalues of $A$. \item Can you tell whether $A$ is diagonalizable without any calculation? why? \item Find the geometric multiplicity and algebraic multiplicity of each eigenvalue. \item Is $A$ diagonalizable? \item Find two different eigenbasis for $A$. What subspace are these a basis of? \item Find an invertible matrix $P$ and a diagonal matrix $D$ such that $A=PDP^{-1}$. \item Find a different matrix $P'$ such that $A=P'DP'^{-1}$. At least one column of $P'$ shouldn't be multiple of a column of $P$. \item What is a relationship between each column of $P$ and the corresponding column of $P'$? \end{enumerate}}
][ch7-CON-diaglintrans,ch7-CON-diagcmat] %this is written as a comma seperated list with no spaces between commas
    [Correct parts 1-5*,Correct parts 6-9*]    %this is written as a comma seperated list with no spaces between commas
    %[<items mark>]      %this is written as a comma seperated list with no spaces between commas
    \begin{enumerate}
			\item $Char(A) = (4-\lambda)(5-\lambda)^2$
			\item We know $(5-\lambda)$ is a factor of $Char(A)$. Therefore, $Char(A) = (4-\lambda)(5-\lambda)^2$.\\
			Hence, $\lambda_1 = 4,\ \lambda_2 = 5$
			\item We can't because we do not have n (=3) distinct eigenvalues. We must check the algebraic and geometric multiplicity of each eigenvalue.
			\item $RREF(A-\lambda_1I) = \begin{bmatrix}
			1&1/2&0\\0&0&1\\0&0&0
			\end{bmatrix} \leftrightarrow {E_{\lambda}}_1 = \left\{\begin{bmatrix}
			-1\\2\\0
			\end{bmatrix}\right\}$\\
			$RREF(A-\lambda_{2}I) = \begin{bmatrix}
			1&0&2\\0&0&0\\0&0&0
			\end{bmatrix} \leftrightarrow {E_{\lambda}}_{2} = \left\{\begin{bmatrix}
			0\\1\\0
			\end{bmatrix},\ \begin{bmatrix}
			-2\\0\\1
			\end{bmatrix}\right\}$\\
			Hence, $dim({E_{\lambda}}_{1}) 1$ which is the geometric multiplicity, and $\alpha(\lambda_1) = 1$ which is the algebraic multiplicity. Also, $dim({E_{\lambda}}_{2} )= 2$ which is the geometric multiplicity, and $\alpha(\lambda_{2}) = 2$ which is the algebraic multiplicity. This shows that the algebraic and geometric multiplicity is the same for each eigenvalue.
			
            \item $A$ is diagonalizable because the sum of the geometric multiplicity = n (=3).
			\item $\mathcal E = \left\{\begin{bmatrix}
			-1\\2\\0
			\end{bmatrix},\ \begin{bmatrix}
			0\\1\\0
			\end{bmatrix},\ \begin{bmatrix}
			-2\\0\\1
			\end{bmatrix}\right\}$, $\mathcal E' = \left\{\begin{bmatrix}
			-2\\4\\0
			\end{bmatrix},\ \begin{bmatrix}
			0\\2\\0
			\end{bmatrix},\ \begin{bmatrix}
			2\\0\\-1
			\end{bmatrix}\right\}$ \\
            Both are a basis for the subspace $\bbR^3$.
			\item $P = \begin{bmatrix}
			-1&0&-2\\2&1&0\\0&0&1
			\end{bmatrix},\ D = \begin{bmatrix}
			4&0&0\\0&5&0\\0&0&5
			\end{bmatrix}$
			\item $P = \begin{bmatrix}
			-1&-2&0\\2&0&1\\0&1&0
			\end{bmatrix},\ D = \begin{bmatrix}
			4&0&0\\0&5&0\\0&0&5
			\end{bmatrix}$
			\item The columns corresponding to eigenvalue 5 are interchanged.
		\end{enumerate}	
\end{SaveQuestion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{SaveQuestion}[
        key=ch7-diagonal-nonexample-sbg,
        prompt={Suppose $A$ is an $n \times n$ matrix for the following theorems. \\ \textbf{Theorem 1:}    $A$ is diagonalizable if and only if $A$ has an eigenbasis. \\
        \textbf{Theorem 2:} $A$ is diagonalizable if and only if $A$ is similar to a diagonal matrix. \\ \vspace{0.5} \\ Let $A=\begin{bmatrix} 4&1&1&1\\0&4&0&1\\0&0&5&1\\0&0&0&5 \end{bmatrix}$. \begin{enumerate} \item Find $\mathrm{Char}(A)$. \item Can you tell whether $A$ is diagonalizbale without any calculation? why? \item Find the geometric multiplicity and algebraic multiplicity of each eigenvalue. \item Is $A$ diagonalizable? Why? Explain using geometric and algebraic multiplicity in your reasoning. \item Find an eigenbasis for $A$ or explain why it is not possible. \end{enumerate}}
][ch7-CON-diagmult,ch7-CON-diaglintrans] %this is written as a comma seperated list with no spaces between commas
    [Correct parts 1-4*,Correct part 5 connecting to diagonalizability*]    %this is written as a comma seperated list with no spaces between commas
    %[<items mark>]      %this is written as a comma seperated list with no spaces between commas
    \begin{enumerate}
			\item $Char(A) = (4-\lambda)^2(5-\lambda)^2$
			\item No, we dont have distinct eigenvalues.
			\item $RREF(A-\lambda_1I) = \begin{bmatrix}
			0&1&0&0\\0&0&1&0\\0&0&0&1\\0&0&0&0
			\end{bmatrix} \leftrightarrow {E_{\lambda}}_1 = \left\{\begin{bmatrix}
			1\\0\\0\\0
			\end{bmatrix}\right\}$\\
			$RREF(A-\lambda_2I) = \begin{bmatrix}
			1&0&-1&0\\0&1&0&0\\0&0&0&1\\0&0&0&0
			\end{bmatrix} \leftrightarrow {E_{\lambda}}_1 = \left\{\begin{bmatrix}
			1\\0\\1\\0
			\end{bmatrix}\right\}$\\
			Hence, $dim({E_{\lambda}}_{1}) = 1$ is the geometric multiplicity and $\alpha(\lambda_1) = 2$ is the algebraic multiplicity, and they are not the same. Also, $dim({E_{\lambda}}_{2} ) = 1$ is the geometric multiplicity and $\alpha(\lambda_{2}) = 2$ is the algebraic multiplicity, and they are also not the same.
			\item The sum of the geometric multiplicity is not n (=3) thus it is not diagonalizable.
            \item The theorem at the beginning of the question states that A is diagonalizable if and only if it has an eigenbasis. Since we already know that it is not diagonalizable this must mean it also does not have an eigenbasis. 
			
		\end{enumerate}
\end{SaveQuestion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{SaveQuestion}[
        key=ch7-eigen-tf-sbg,
        prompt={Let $T: V \rightarrow V $ be a linear transformation.  Prove or disprove each statement: \begin{enumerate} \item Any non-zero element in the kernel of   $V \overset{T}\longrightarrow V$  is an eigenvector of $T$. \item The linear transformation $V \overset{T}\longrightarrow V$ is injective if and only if zero is not an eigenvalue of $T$. \item If $\vec v$ is an an eigenvector  of $T$, then $\vec v$ is an eigenvector of $T^2$ as well. \item Every linear transformation has an eigenbasis. \item If $T$ has no real eigenvalues, then also $T^2$ has no real eigenvalues. \item If $\lambda$ is an eigenvalue of some linear transformation $T: V \rightarrow V$, then $\lambda^n$ is a eigenvalue of $T^n: V \rightarrow V$. \end{enumerate}}
][chg-CON-tf,chg-WRIT-matcom] %this is written as a comma seperated list with no spaces between commas
    %[<rubric items>]    %this is written as a comma seperated list with no spaces between commas
    %[<items mark>]      %this is written as a comma seperated list with no spaces between commas
    \begin{enumerate}
        \item Proof: Suppose $\vec v$ is in the kernel of $T$. Then $T(\vec v) = \vec 0 = 0 \vec v$ so $\vec v$ is an eigenvector corresponding to eigenvalue $0$. (Indeed, the $0$-eigenvectors are exactly the  (non-zero) elements in the kernel of $T$. Can you prove it?).
        \item Proof: (This basically restates 1, remembering that $T$ is injective if and only if $\ker T$ is zero.) Suppose $T$ is injective, then $\ker T$ is trivial. Hence, there is no nonzero vector $\vec v$ such that $T(\vec v)=0\vec v=\vec 0$. Hence zero is not an eigenvalue of $T$. Conversely, suppose $0$ is not an eigenvalue for $T$. Hence there is no nonzero vector $\vec v$ such that $T(\vec v)=0\vec v=\vec 0$. Hence $\ker T$ is trivial.
        \item Proof: If $T(\vec v) = \lambda \vec v$ for some nonzero $\vec v$ in $V$, then $T^2(\vec v) =  T(T(\vec v))  =  T (\lambda \vec v)  = \lambda  T(\vec v)  = \lambda^2 \vec v$. So $\vec  v$ is an eigenvector for $T$ also (though  the corresponding eigenvalue could be different.)
        \item Disprove! Rotation by $\pi/6$ in $\mathbb{R}^2$ has no eigenvectors! So it can't have an eigenbasis.
        \item False. Let $T$ be rotation through $\pi/2$. There are no real eigenvalues because no vector is taken to a parallel vector by $T$. However $T^2$ is rotation by $\pi$. This takes $\vec e_1$ to $-\vec e_1$, so $-1$ is a real eigenvalue of $T^2$.
        \item Proof by induction.  We did the case $n = 2$ in (3). Inductive hypothesis: $T^{n-1} (\vec v) = \lambda^{n-1} \vec v$. Apply $T$ to both sides to get  $T^{n} (\vec v) = \lambda^{n-1} T( \vec v) = \lambda^{n} \vec v$.
   
    \end{enumerate}
\end{SaveQuestion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% TEXTBOOK QUESTIONS %

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{SaveQuestion}[
        key=ch1-generalsol-sec1.1ex32-sbg,
        prompt={Find a polynomial of degree $\leq 2$ of the form $f(t) = a + bt + ct^2$ whose graph goes through the points $(1,p), (2,q), (3,r)$, where $p,q,r$ are arbitrary constants. Does such a polynomial exist for all values of $p,q,r$? \\ Note: When we say $(1,p), (2,q), (3,r)$ we are giving the value $f(1)$ the name $p$ e.t.c., and so $p = f(1), q = f(2)$ and $r = f(3)$.}
][ch1-COM-augset] %this is written as a comma seperated list with no spaces between commas
    [Used the augmented matrix correctly*Got the correct final answer with minimal mistakes*]    %this is written as a comma seperated list with no spaces between commas
    Write $f(t)=a+bt+ct^2$. If $(1,p)$, $(2,q)$, and $(3,r)$ lie on the graph of $f$, then $p,q,r$ satisfy the linear equations
    $$
    \left|\begin{array}{ccccccc}
    a & + & b & + & c & = & p \\
    a & + & 2b & + & 4c & = & q \\
    a & + & 3b & + & 9c & = & r \\
    \end{array}\right|
    $$
    Solving this linear system by row reducing its augmented matrix, we find that 
    $$
    a = 3p-3q+r, \quad b = -\frac{5}{2}p+4q-\frac{3}{2}r, \quad\text{and}\quad c = \frac{1}{2}p-q+\frac{1}{2}r,
    $$
    so $f(t)=(3p-3q+r)+(-\frac{5}{2}p+4q-\frac{3}{2}r)t+(\frac{1}{2}p-q+\frac{1}{2}r)t^2$. This solution is valid for all values of $p,q,r$.
\end{SaveQuestion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

 \begin{SaveQuestion}[
         key=ch1-generalsol-sec1.1ex40-sbg,
         prompt={Find the ellipse centered at the origin that runs through the points $(1,2), (2,2),$ and $(3,1)$. Write your equation in the form $ax^2+bxy+cy^2 =1$.}
 ][ch1-COM-augset] %this is written as a comma seperated list with no spaces between commas
    [Used the augmented matrix correctly*Correct final answer with minimal mistakes*]    %this is written as a comma seperated list with no spaces between commas
     The system of equations corresponding to the ellipse $ax^2+bxy+cy^2=1$ going through the points $(1,2)$, $(2,2)$ and $(3,1)$ is:
\[\left[\begin{array}{ccc@{\;=\;}c}
a & +2b & +4c & 1 \\  4a & +4b & +4c & 1 \\ 9a & +3b & +c & 1
\end{array}\right].\]
Using the first equation to eliminate the $a$ variable in the second and third equations gives:
\[\left[\begin{array}{ccc@{\;=\;}c}
a & +2b & +4c & 1 \\  4a & +4b & +4c & 1 \\ 9a & +3b & +c & 1
\end{array}\right]\to
\left[\begin{array}{ccc@{\;=\;}c}
a & +2b & +4c & 1 \\  & -4b & -12c & -3 \\  & -15b & -35c & -8
\end{array}\right]\to
\left[\begin{array}{ccc@{\;=\;}c}
a & +2b & +4c & 1 \\  & b & +3c & \frac{3}{4} \\  & 15b & +35c & 8
\end{array}\right],\]
after multiplying the second equation by $-1/4$ and the third equation by $-1$. Using the second equation to eliminate the $b$ variable in the third equation gives:
\[\left[\begin{array}{ccc@{\;=\;}c}
a & +2b & +4c & 1 \\  & b & +3c & \frac{3}{4} \\  &  & -10c & -\frac{13}{4}
\end{array}\right].\]
The third equation yields $c = 13/40$. From the second equation we obtain:
\[ b = \frac{3}{4} - 3c = -\frac{9}{40}.\] From the first equation we get:
\[ a = 1 - 2b - 4c = \frac{3}{20}.\]

Thus, the ellipse that goes through the points $(1,2)$, $(2,2)$ and $(3,1)$ is
\[ \frac{3}{20}x^2 - \frac{9}{40}xy + \frac{13}{40}y^2 = 1.\]
 \end{SaveQuestion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

 \begin{SaveQuestion}[
         key=ch1-generalsol-sec1.2ex12-sbg,
         prompt={Find all solutions of the equations with paper and pencil using Gauss-Jordan elimination. Show all your work.    
    $$
    \left|\begin{array}{ccccccccccccc}
        2x_1 &  &  & - & 3x_3 &  &  & + & 7x_5 & + & 7x_6 & = & 0 \\
        -2x_1 & + & x_2 & + & 6x_3 &  &  & - & 6x_5 & - & 12x_6 & = & 0 \\
          &  & x_2 & - & 3x_3 &  &  & + & x_5 & + & 5x_6 & = & 0 \\
          & - & 2x_2 &  &  & + & x_4 & + & x_5 & + & x_6 & = & 0 \\
        2x_1 & + & x_2 & - & 3x_3 &  &  & + & 8x_5 & + & 7x_6 & = & 0 \\
    \end{array}\right|
    $$}
 ][ch1-COM-augset] %this is written as a comma seperated list with no spaces between commas
     [Correct final answer*They either indicate free variables or put it in vector parametric form and mention that the coefficients are real numbers*]    %this is written as a comma seperated list with no spaces between commas
The sequence of steps to transform the augmented matrix of the system to its
reduced row-echelon form is:
\begin{align*}
\begin{amatrix}{6} 2 & 0 & -3 & 0 & 7 & 7 & 0 \\
-2 & 1 & 6 & 0 & -6 & -12 & 0 \\
0 & 1 & -3 & 0 & 1 & 5 & 0 \\
0 & -2 & 0 & 1 & 1 & 1 & 0 \\
2 & 1 & -3 & 0 & 8 & 7 & 0
\end{amatrix}&\to
\begin{amatrix}{6} 2 & 0 & -3 & 0 & 7 & 7 & 0 \\
0 & 1 & 3 & 0 & 1 & -5 & 0 \\
0 & 1 & -3 & 0 & 1 & 5 & 0 \\
0 & -2 & 0 & 1 & 1 & 1 & 0 \\
0 & 1 & 0 & 0 & 1 & 0 & 0
\end{amatrix}\to
\\
\begin{amatrix}{6} 2 & 0 & -3 & 0 & 7 & 7 & 0 \\
0 & 1 & 3 & 0 & 1 & -5 & 0 \\
0 & 0 & -6 & 0 & 0 & 10 & 0 \\
0 & 0 & 6 & 1 & 3 & -9 & 0 \\
0 & 0 & -3 & 0 & 0 & 5 & 0
\end{amatrix}&\to
\begin{amatrix}{6} 2 & 0 & -3 & 0 & 7 & 7 & 0 \\
0 & 1 & 3 & 0 & 1 & -5 & 0 \\
0 & 0 & -6 & 0 & 0 & 10 & 0 \\
0 & 0 & 0 & 1 & 3 & 1 & 0 \\
0 & 0 & 0 & 0 & 0 & 0 & 0
\end{amatrix}\to \\
\begin{amatrix}{6} 1 & 0 & -\frac{3}{2} & 0 & \frac{7}{2} & \frac{7}{2} & 0 \\
0 & 1 & 3 & 0 & 1 & -5 & 0 \\
0 & 0 & 1 & 0 & 0 & -\frac{5}{3} & 0 \\
0 & 0 & 0 & 1 & 3 & 1 & 0 \\
0 & 0 & 0 & 0 & 0 & 0 & 0
\end{amatrix} &\to
\begin{amatrix}{6} 1 & 0 & 0 & 0 & \frac{7}{2} & 1 & 0 \\
0 & 1 & 0 & 0 & 1 & 0 & 0 \\
0 & 0 & 1 & 0 & 0 & -\frac{5}{3} & 0 \\
0 & 0 & 0 & 1 & 3 & 1 & 0 \\
0 & 0 & 0 & 0 & 0 & 0 & 0
\end{amatrix}
\end{align*}
Solving for the leading variables in each row of the reduced row-echelon form gives:
\[ \begin{aligned}
x_4 & = -3x_5 - x_6,\\
x_3 & = \frac{5}{3}x_6,\\
x_2 & = -3x_3-x_5+5x_6 ,\\
x_1 & = -\frac{7}{2}x_5 - x_6.
\end{aligned}
\]

The infinitely many solutions of the system are given by:
\[
\begin{bmatrix} x_1\\x_2\\x_3\\x_4\\x_5\\x_6 \end{bmatrix} = 
\begin{bmatrix} -\frac{7}{2} \\ -1 \\ 0 \\ -3 \\ 1 \\ 0 \end{bmatrix}s +
\begin{bmatrix} -1 \\ 0 \\ \frac{5}{3} \\ -1 \\ 0 \\ 1 \end{bmatrix}t \qquad 
\mbox{for } s,t\in\mathbb{R}.
\]
 \end{SaveQuestion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{SaveQuestion}[
        key=ch0-vecarith-sec1.2ex36-sbg,
        prompt={The dot product of two vectors 
        $$ \vec x = 
        \begin{bmatrix}
            x_1 \\ x_2 \\ \vdots \\ x_n    
        \end{bmatrix} 
        \text{ and }
        \vec y = 
        \begin{bmatrix}
            y_1 \\ y_2 \\ \vdots \\ y_n
        \end{bmatrix}
        $$
        in $\mathbb{R}^n$ is defined by 
        $$\vec x \cdot \vec y = x_1y_1 + x_2y_2 + ... + x_ny_n. $$
        Note that the dot product of two vectors is a scalar. We say that the vectors $\vec x$ and $\vec y$ are \MathCite{perpendicular} if $\vec x \cdot \vec y = 0$. \\ Use set builder notation to describe the vectors in $\mathbb{R}^3$ perpendicular to 
        $$\vec w = \begin{bmatrix}
            1 \\ 3 \\ -1
        \end{bmatrix}$$
        Draw a sketch.
        }
][ch0-WRIT-sets] 
    [Must have correct components of set-builder notation, forming a correct solution*Proper set notation with braces*Include, as a necessary and sufficient condition, the equation of the plane in normal form*] 
    Let $S \subseteq \mathbb{R}^3$ be the set of all vectors perpendicular to $\vec w$. First, let's visualize the set $S$ of all vectors perpendicular to a given vector in $\mathbb{R}^3$. Relying on our intuition in $\mathbb{R}^3$ we see that this set forms a plane (see the sketch \href{https://www.geogebra.org/3d/wawvs2cp}{\textbf{here}} or below)\PullLS*[2]. 

    \begin{center}
        \includegraphics[width=0.75\textwidth]{Question Photos/MAT188F2024TUT1Q2.png}
    \end{center}
    By definition, a vector $\begin{bmatrix} x \\ y \\ z \end{bmatrix}$ in $\mathbb{R}^3$ is perpendicular to $\begin{bmatrix} 1 \\ 3 \\ -1 \end{bmatrix}$ if $\begin{bmatrix} x \\ y \\ z \end{bmatrix} \cdot \begin{bmatrix} 1 \\ 3 \\ -1 \end{bmatrix} = x+3y-z=0$. \\
    Hence we can describe $S$ as the following\PullLS*[1].
$$S = \left\{\begin{bmatrix} x \\ y \\ z \end{bmatrix} \in \mathbb{R}^3 \ | \ x+3y-z=0\right\}$$
    
    Now, we will express the same set in vector form. We need two nonzero vectors $\vec d_1$ and $\vec d_2$, that entirely lie on the plane, and the position vector of a point $\vec p$ on the plane.
    $$S = \{s\vec d_1 + t\vec d_2 + \vec p \ | \ s,r \in \mathbb{R}\}$$

    First note that $\vec 0$, as $0 + 3(0) - 0 = 0$. Hence, this plane passes through the origin.   For the position vector of a point $\vec p$ we can simply pick the zero vector. 

    To find $\vec d_1, \vec d_2$, we will find two solutions to $x + 3y - z = 0$. Note that since $\vec 0$ is on this plane, the direction vector lie on the plane. We also need that $\vec d_1$ and $\vec d_2$ are not scalar multiples of each other (otherwise we would be mapping a line). 
    
    Fixing $z = 0$, we obtain $x + 3y - 0 = 0 \Longrightarrow x = -3y \Longrightarrow \vec d_1 = \begin{bmatrix} -3 \\ 1 \\ 0 \end{bmatrix}$.
    
    Fixing $y = 0$, we obtain $x + 0 - z = 0 \Longrightarrow x = z \Longrightarrow \vec d_2 = \begin{bmatrix} 1 \\ 0 \\ 1 \end{bmatrix}$.

    
    
    Therefore the $S$ set of all vectors in $\mathbb{R}^3$ perpendicular to $\begin{bmatrix} 1 \\ 3 \\ -1 \end{bmatrix}$ is the following:
    $$S = \left\{\begin{bmatrix} x \\ y \\ z \end{bmatrix} \in \mathbb{R}^3 \ | \ x+3y-z=0\right\} = \left\{s \begin{bmatrix} -3 \\ 1 \\ 0 \end{bmatrix} + t \begin{bmatrix} 1 \\ 0 \\ 1 \end{bmatrix} | s,t \in \mathbb{R}\right\}$$
\end{SaveQuestion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{SaveQuestion}[
        key=ch1-generalsol-sec1.2ex38-sbg,
        prompt={Find all solutions $x_1, x_2, x_3$ of the equation
        $$\vec b = x_1 \vec v_1 + x_2 \vec v_2 + x_3 \vec v_3,$$
        where
        $$\vec b = 
        \begin{bmatrix}
            -8 \\ -1 \\ 2 \\ 15
        \end{bmatrix}, \vec v_1 = 
        \begin{bmatrix}
            1 \\ 4 \\ 7 \\ 5
        \end{bmatrix}, \vec v_2 =
        \begin{bmatrix}
            2 \\ 5 \\ 8 \\ 3
        \end{bmatrix}, \vec v_3 = 
        \begin{bmatrix}
            4 \\ 6 \\ 9 \\ 1
        \end{bmatrix}.$$
        }
][ch1-COM-augset] %this is written as a comma seperated list with no spaces between commas
    [They used an augmented matrix/system of linear equations to solve*Got the correct final answer*]    %this is written as a comma seperated list with no spaces between commas
    This translates to the system of equations
\[{x_1+2x_2+4x_3=-8, 4x_1+5x_2+6x_3=-1, 7x_1+8x_2+9x_3=2, 5x_1+3x_2+1x_3=15.}\]
Putting this in matrix form, the augmented matrix is
\[\begin{amatrix}{3}1&2&4&-8\\ 4&5&6&-1\\ 7&8&9&2\\ 5&3&1&15\end{amatrix}.\]
Row reducing, subtracting multiples of the first row from the others, yields
\[\begin{amatrix}{3}1&2&4&-8\\ 0&-3&-10&31\\ 0&-6&-19&58\\ 0&-7&-19&55\end{amatrix}.\]
Dividing row 2 by $-3$:
\[\begin{amatrix}{3}1&2&4&-8\\ 0&1&10/3&-31/3\\ 0&-6&-19&58\\ 0&-7&-19&55\end{amatrix}.\]
Using row 2 to clear out column 2:
\[\begin{amatrix}{3}1&0&-8/3&38/3\\ 0&1&10/3&-31/3\\ 0&0&1&-4\\ 0&0&13/3&-52/3\end{amatrix}.\]
And, finally, using row 3 to clear out column 3:
\[\begin{amatrix}{3}1&0&0&2\\ 0&1&0&3\\ 0&0&1&-4\\ 0&0&0&0\end{amatrix}.\]
The system is consistent and all three variables are leading, thus there is exactly one solution: $x_1=2$, $x_2=3$, and $x_3=-4$.
\end{SaveQuestion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{SaveQuestion}[
        key=ch1-generalsol-sec1.2ex48-sbg,
        prompt={Consider the equations 
        $$
    \left|\begin{array}{ccccccc}
         &  & y & + & 2kz & = & 0 \\
        x & + & 2y & + & 6z & = & 2 \\
        kx &  &  & + & 2z & = & 1 \\
    \end{array}\right|
    $$
    where k is an arbitrary constant.
    \begin{enumerate}
        \item[a)] For which values of the constant k does this system have a unique solution?
        \item[b)] When is there no solution?
        \item[c)] When are there infinitely many solutions?
    \end{enumerate}
        }
][ch1-CON-augsoltype] %this is written as a comma seperated list with no spaces between commas
    [Correct answers for all 3 parts*Used row reductions and RREF form to come up with their solution*]    %this is written as a comma seperated list with no spaces between commas
    The augmented matrix of this linear system is $\begin{bmatrix} 0 & 1 & 2k & 0 \\ 1 & 2 & 6 & 2 \\ k & 0 & 2 & 1 \end{bmatrix}$, which can be row-reduced to the matrix
\[
\begin{bmatrix} 1 & 0 & 6-4k & 2 \\ 0 & 1 & 2k & 0 \\ 0 & 0 & 2(k-1)(2k-1) & 1-2k \end{bmatrix}.
\]
From this we see that:
\begin{enumerate}
	\item[(a)] The system has a unique solution if and only if $k\ne 1$ and $k\ne\frac{1}{2}$.
	\item[(b)] The system is inconsistent if and only if $k=1$, since in this case the last column of the  augmented matrix is a pivot column.
	\item[(c)] The system has infinitely many solutions if and only if $k=\frac{1}{2}$, since in this case the last column of the augmented matrix is not a pivot column (so the system is consistent), but the third column is also not a pivot column and therefore corresponds to a free variable.
\end{enumerate}
\end{SaveQuestion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%was originally a DEV
\begin{SaveQuestion}[
        key=ch1-generalsol-sec1.3ex47-sbg, 
        prompt={A linear system of the form 
        $$ A \vec x = \vec 0 $$
        is called homogeneous. Justify the following facts:
        \begin{enumerate}
            \item All homogeneous systems are consistent.
            \item If $\vec c_1$ and $\vec c_2$ are solutions of the homogeneous system $A \vec x = \vec 0$, then $\vec c_1 + \vec c_2$ is a solution as well.
            \item If $\vec c$ is a solution of the homogeneous system $A \vec x = \vec 0$ and $k$ is an arbitrary constant, then $k \vec c$ is a solution as well.
            \item Suppose $\vec c_1$ and $\vec c_2$ are solutions of the homogeneous system $A \vec x = \vec 0$ and $r$ and $s$ are two scalars, what can you say about $A(r\vec c_1 + s\vec c_2)$?
            \item Suppose $A$ is a square matrix, that is, the system has an equal number of equations and unknowns. Then the solution is either uniquely the zero vector, or, there are infinitely many solutions.
            % \item Now suppose a homogeneous system with fewer unknowns than equations. The zero vector is the only solution.
            \item A homogeneous system with fewer equations than unknowns has infinitely many solutions.
        \end{enumerate}
        }
][ch1-CON-augsoltype,chg-WRIT-matcom] %this is written as a comma seperated list with no spaces between commas
    [Justification of the solution set using arguments mentioning pivots and free variables.*The forenamed facts are justified for arbitrary objects and specific examples are not used.*,Solution makes use of matrix and vector properties to demonstrate that linear combinations of solutions are also indeed solutions to the system.*Logical line of thinking and reasoning is employed for the justification of each statement and starts with what is given in order to reach the conclusion in a step-by-step manner.*]    %this is written as a comma seperated list with no spaces between commas
    \begin{enumerate}
        \item Since $\vec{x}=\vec{0}$ is necessarily a solution, the system is consistent.
        
        \item We assume that $A\vec c_1 = \vec 0, A \vec v_2 = \vec 0$. We want to show that $A(\vec c_1 + \vec c_2) = \vec 0$. Therefore, we have the following.
        \begin{align*}
            A(\vec c_1 + \vec c_2)  &= A\vec c_1 + A\vec c_2    &\text{Linear Property.} \\
                                    &= \vec 0 + A\vec c_2       &\text{Since $A\vec c_1
                                    = \vec 0$.} \\
                                    &= \vec 0 + \vec 0          &\text{Since $A\vec c_2
                                    = \vec 0$.} \\
                                    &= \vec 0                   &\text{Simplifying.}
        \end{align*}
        Hence, $\vec c_1 + \vec c_2$ is indeed a solution, as $A(\vec c_1 + \vec c_2) = \vec 0$. 
        
        \item We assume that $A\vec c = \vec 0, k \in \mathbb{R}$. We want to show that $A(k\vec c) = \vec 0$. Therefore, we have the following.
        \begin{align*}
            A(k\vec c)  &= k A\vec c                            &\text{Linear Property.} \\
                                    &= k\vec 0                  &\text{Since $A\vec c = \vec 0$.} \\
                                    &= \vec 0                   &\text{Simplifying.}
        \end{align*}
        Hence, $k \vec c$ is indeed a solution, as $A(k\vec c) = \vec 0$.

        \item We assume that $A\vec c_1, A\vec c_2 = \vec 0$ and $r,s \in \mathbb{R}$. Using the previous two parts, we claim that $A(r \vec c_1 + s \vec c_2)$ is always a solution to the system. We want to show that $A(r \vec c_1 + s \vec c_2) = \vec 0$ Therefore, we have the following.
        \begin{align*}
            A(r \vec c_1 + s \vec c_2)  &= A(r\vec c_1) + A(s \vec c_2)               &\text{Linear Property.} \\
                                        &= r A\vec c_1 + s A\vec c_2    &\text{Linear Property.} \\
                                        &= r \vec 0 + s \vec 0          &\text{By Assumption.} \\
                                        &= \vec 0 + \vec 0              &\text{Simplifying.} \\
                                        &= \vec 0                       &\text{Simplifying.}
        \end{align*}
        Hence, $r \vec c_1 + s \vec c_2$ is indeed a solution, as $A(r \vec c_1 + s \vec c_2) = \vec 0$.

        \item Briefly, from the first part we know that the zero vector is necessarily a solution to the homogeneous linear system. Thus, there are two possibilities, either that zero vector is the only solution, or different $\vec c$ exists such that $A\vec c = 0$. Using the result from Part (3), we can argue that for any nonzero $k \in \mathbb{R}$, we obtain a new unique solution. This implies there are infinitely many solutions. Hence, we either only have the zero vector as a solution or infinitely many solutions. 
        
        \item To determine that there are infinitely many solutions, we first consider the possible solution types of a linear system, namely: no solution, one solution, or infinitely many solutions. Using the first part, there clearly is at least one solution. Thus, we either have one solution or infinitely many. Next, consider that the RREF version of this matrix can have at most 1 pivot per row. Since there are more columns (variables) than rows (equations), one of there must be a least one free variable, and further, there must be infinitely many solutions.  
	\end{enumerate}
\end{SaveQuestion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{SaveQuestion}[
        key=ch1-generalsol-sec1.3ex48-dev,
        prompt={Consider a solution $\vec x_1$ of a linear system $A \vec x = \vec b$. 
        Justify the facts stated in parts (1) and (2):
        \begin{enumerate}
            \item If ${\vec x}_h$ is a solution of the system $A \vec x = \vec 0$, then ${\vec x}_1 + {\vec x}_h$ is a solution of the system $A \vec x = \vec b$.
            \item If ${\vec x}_2$ is another solution of the system $A\vec x = \vec b$, then ${\vec x}_2 - {\vec x}_1$ is a solution of the system $A\vec x = \vec 0$.
            \item Now suppose $A$ is a $2 \times 2$ matrix. A solution vector ${\vec x}_1$ of the system $A \vec x = \vec b$ is shown in the accompanying figure. We are told that the solutions of the system $A\vec x = \vec 0$ form the line shown in the sketch. Draw the line consisting of all solutions of the system $A \vec x = \vec b$.
        \end{enumerate}
        \begin{center}
        \includegraphics[scale=0.5]{Question Photos/sec1.3q48.png}
        \end{center}
        If you are puzzled by the generality of this problem, think about an example first:
        $$
        A = \begin{bmatrix} 1 & 2 \\ 3 & 6 \end{bmatrix}, \ \ \ \vec b = \begin{bmatrix} 3 \\ 9 \end{bmatrix}, \ \ \ and \ \ \ {\vec x}_1 = \begin{bmatrix} 1 \\ 1 \end{bmatrix}
        $$
        }
][ch1-VG-gslinsys] %this is written as a comma seperated list with no spaces between commas
    [Correct drawing in part 3 and the presence of a hint is manifest.*Hint 1: Use Theorem (Algebraic Rules for Ax) from PCE2.*Hint 2: Find vectors x3 and x4 such that Ax3 = 0 and Ax4 = 0; draw them.*Hint 3: Use vectors x3 and x4 and x1 to find two more solutions to Ax = b; draw them.*]    %this is written as a comma seperated list with no spaces between commas
    \begin{enumerate}
	\item We assume that $A\vec x_h = \vec 0, A \vec x_1 = \vec b$. We want to show that $A(\vec x_1 + \vec x_h) = \vec b$. Therefore, we have the following.
        \begin{align*}
            A(\vec x_1 + \vec x_h)  &= A\vec x_1 + A\vec x_h    &\text{Linear Property.} \\
                                    &= \vec b + A\vec x_h       &\text{Since $A\vec c_1
                                    = \vec b$.} \\
                                    &= \vec b + \vec 0          &\text{Since $A\vec c_2
                                    = \vec 0$.} \\
                                    &= \vec b                   &\text{Simplifying.}
        \end{align*}
        Hence, we have shown that if $A\vec x_h = \vec 0$ and $A \vec x_1 = \vec b$, then $A(\vec x_1 = \vec x_h)$, as needed. 

        \item We assume that $A\vec x_1 = \vec b, A \vec x_2 = \vec b$. We want to show that $A(\vec x_2 - \vec x_1) = \vec 0$. Therefore, we have the following.
        \begin{align*}
            A(\vec x_2 - \vec x_1)  &= A\vec x_2 - A \vec x_1   &\text{Linear Property.} \\           
                                    &= \vec b - A \vec x_1      &\text{Since $A\vec x_2 = \vec b$.} \\
                                    &= \vec b - \vec b          &\text{Since $A\vec x_1 = \vec b$.} \\
                                    &= \vec 0                   &\text{Additive Inverses.}
        \end{align*}
        Hence, we have shown that if $A\vec x_1 = \vec b$ and $A \vec x_2 = \vec b$, then $A(\vec x_2 - \vec x_1) = \vec 0$, as needed.
        
        \item It is the line parallel to the line of homogeneous solutions shown in the figure that passes through the vertex of the vector $\vec x_1$. To understand why this is the case, we are utilizing the fact that we proved in part (1). 
    \end{enumerate}
\end{SaveQuestion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{SaveQuestion}[
        key=ch2-generalsol-sec2.1ex24-tbd,
        prompt={Consider the circular face in the accompanying figure. Given the matrix $\begin{pmatrix} 0 & -1 \\ 1 & 0 \end{pmatrix}$, draw a sketch showing the effect of the linear transformation $T(\vec x) = A \vec x$ on this face.
        \begin{center}
        \includegraphics[scale=0.5]{Question Photos/sec2.1q242526.png}
        \end{center}
        }
][] %this is written as a comma seperated list with no spaces between commas
    []    %this is written as a comma seperated list with no spaces between commas
\end{SaveQuestion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{SaveQuestion}[
        key=ch2-generalsol-sec2.1ex25-tbd,
        prompt={Consider the circular face in the accompanying figure. Given the matrix $\begin{pmatrix} 2 & 0 \\ 0 & 2 \end{pmatrix}$, draw a sketch showing the effect of the linear transformation $T(\vec x) = A \vec x$ on this face.
        \begin{center}
        \includegraphics[scale=0.5]{Question Photos/sec2.1q242526.png}
        \end{center}
        }
][] %this is written as a comma seperated list with no spaces between commas
    []    %this is written as a comma seperated list with no spaces between commas
\end{SaveQuestion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{SaveQuestion}[
        key=ch2-generalsol-sec2.1ex26-tbd,
        prompt={Consider the circular face in the accompanying figure. Given the matrix $\begin{pmatrix} 0 & 1 \\ 1 & 0 \end{pmatrix}$, draw a sketch showing the effect of the linear transformation $T(\vec x) = A \vec x$ on this face.
        \begin{center}
        \includegraphics[scale=0.5]{Question Photos/sec2.1q242526.png}
        \end{center}
        }
][] %this is written as a comma seperated list with no spaces between commas
    []    %this is written as a comma seperated list with no spaces between commas
\end{SaveQuestion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{SaveQuestion}[
        key=ch2-matrix-sec2.2ex5-dev,
        prompt={The matrix
        $$\begin{bmatrix}
            -0.8 & -0.6 \\
            0.6 & -0.8
        \end{bmatrix}$$
        represents a rotation. Find the angle of rotation (in radians).
        }
][ch2-VG-geotrans] %this is written as a comma seperated list with no spaces between commas
    [Correct angle in radians*]    %this is written as a comma seperated list with no spaces between commas
    A rotation matrix must necessarily be of the form $\begin{bmatrix}\cos\theta & -\sin\theta \\ \sin\theta & \cos\theta\end{bmatrix}$, so if the matrix $\begin{bmatrix}-0.8 & -0.6 \\ 0.6 & -0.8\end{bmatrix}$ is a rotation, then it must be the case that the angle $\theta$ of the rotation satisfies $\sin\theta=0.6$ and $\cos\theta=-0.8$. The fact that the cosine is negative and the sine positive means that we're looking for an angle that lies in the second quadrant, now since $\arcsin(0.6)=\arccos(0.8)=0.64351$, and our angle needs to lie in the second quadrant, we can readily conclude that $\theta=\pi-0.64351$.
\end{SaveQuestion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{SaveQuestion}[
        key=ch2-matrix-sec2.2ex12-sbg,
        prompt={Consider a reflection matrix $A$ (reflection over a line through the origin) and a vector $\vec x$ in $\mathbb{R}^2$. We define $\vec v = \vec x + A \vec x$ and $\vec w = \vec x - A \vec x$.  Illustrate all parts of this exercise with a sketch showing $\vec x, A \vec x, A(A \vec x), \vec v, \vec w,$ and the line $L$. Hint: You can use the matrix representation of a reflection over any line through the origin which is given as $\begin{bmatrix}
            a & b \\ b & -a
        \end{bmatrix}$ with the property that $a^2+b^2=1$.
        \begin{enumerate}
            \item[a)] Using the matrix A and matrix-vector arithmetic, express $A(A \vec x)$ in terms of $\vec x$. 
            \item[b)] Express $A \vec v$ in terms of $\vec v$. Show your work using arithmetic that does not rely on your drawing.
            \item[c)] Express $A \vec w$ in terms of $\vec w$. Show your work using arithmetic that does not rely on your drawing.
            \item[d)] If the vectors $\vec v$ and $\vec w$ are both nonzero, what is the angle between $\vec v$ and $\vec w$? Refer to your drawing for justification.
            \item[e)] If the vector $\vec v$ is nonzero, what is the relationship between $\vec v$ and the line $L$ of reflection? Refer to your drawing for justification. 
        \end{enumerate}
        }
][ch2-VG-geotrans,ch2-COM-matarith] %this is written as a comma seperated list with no spaces between commas
    [Correct or close enough drawings*,Correct matrix multiplication in part a*Correct use of distributive property in matrix-vector multiplication in parts b and c*]    %this is written as a comma seperated list with no spaces between commas
    \begin{center}
        \includegraphics[scale=0.2]{Question Photos/IMG_0947.png}
        \end{center}
    \begin{enumerate}
			\item[(a)] Since $A$ is the matrix associated to a reflection, it must be of the form $A=\begin{bmatrix}a &b \\ b & -a\end{bmatrix}$ for some $a,b\in\mathbb{R}$ such that $a^2+b^2=1$. Thus, letting $x=\begin{bmatrix}x_1 \\ x_2\end{bmatrix}$, we get that 
			\begin{eqnarray*}
				A(A\vec{x}) & = & \begin{bmatrix}a &b \\ b & -a\end{bmatrix}\begin{bmatrix}a &b \\ b & -a\end{bmatrix}\begin{bmatrix}x_1 \\ x_2\end{bmatrix} \\
				& = & \begin{bmatrix}a &b \\ b & -a\end{bmatrix}\begin{bmatrix}ax_1+bx_2 \\ bx_1-ax_2\end{bmatrix} \\
				& = & \begin{bmatrix}a^2x_1+abx_2+b^2x_1-abx_2 \\ abx_1+b^2x_2-abx_1+a^2x_2\end{bmatrix} \\
				& = & \begin{bmatrix}x_1(a^2+b^2) \\ x_2(b^2+a^2)\end{bmatrix}=\begin{bmatrix}x_1 \\ x_2\end{bmatrix}=\vec{x}.
			\end{eqnarray*}
			\item[(b)] $A\vec{v}=A(\vec{x}+A\vec{x})=A\vec{x}+A(A\vec{x})=A\vec{x}+\vec{x}=\vec{v}$.
			\item[(c)] $A\vec{w}=A(\vec{x}-A\vec{x})=A\vec{x}-A(A\vec{x})=A\vec{x}-\vec{x}=-(\vec{x}-A\vec{x})=-\vec{w}$.
			\item[(d)] Looking at the sketch, we see that the angle must be $\frac{\pi}{2}$ (i.e. $\vec{v}$ is perpendicular to $\vec{w}$).
			\item[(e)] Looking at the sketch, we see that $\vec{v}$ is parallel to the line of reflection.
		\end{enumerate}
\end{SaveQuestion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{SaveQuestion}[
        key=ch2-lintrans-sec2.2ex19-sbg,
        prompt={Find the matrix of the linear transformation which goes from $\mathbb{R}^3$ to $\mathbb{R}^3$. The transformation may not be formally defined in the textbook, use common sense. You may assume that the transformation is linear. \textbf{The Linear Transformation:} The orthogonal projection onto the $x-y$-plane.}
][ch2-COM-standmat] %this is written as a comma seperated list with no spaces between commas
    [Correct matrix found using the standard vectors*]    %this is written as a comma seperated list with no spaces between commas
    The orthogonal projection onto the x-y-plane.
		\[
		\begin{bmatrix}
			1&0&0\\
			0&1&0\\
			0&0&0
		\end{bmatrix}
		\]
\end{SaveQuestion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{SaveQuestion}[
        key=ch2-lintrans-sec2.2ex20-sbg,
        prompt={Find the matrix of the linear transformation which goes from $\mathbb{R}^3$ to $\mathbb{R}^3$. The transformation may not be formally defined in the textbook, use common sense. You may assume that the transformation is linear. \\ \textbf{The Linear Transformation:} The reflection about the $x-z$-plane.}
][ch2-COM-standmat] %this is written as a comma seperated list with no spaces between commas
    [Correct matrix found using the standard vectors*]    %this is written as a comma seperated list with no spaces between commas
    The reflection about the x-z-plane.
		
		\[
		\begin{bmatrix}
			1&0&0\\
			0&-1&0\\
			0&0&1
		\end{bmatrix}
		\]
\end{SaveQuestion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{SaveQuestion}[
        key=ch2-lintrans-sec2.2ex21-sbg,
        prompt={Find the matrix of the linear transformation which goes from $\mathbb{R}^3$ to $\mathbb{R}^3$. The transformation may not be formally defined in the textbook, use common sense. You may assume that the transformation is linear. \\ \textbf{The Linear Transformation:} The rotation about the $z$-axis through an angle of $\pi / 2$, counterclockwise as viewed from the positive $z$-axis.}
][ch2-COM-standmat] %this is written as a comma seperated list with no spaces between commas
    [Correct matrix found using the standard vectors*]    %this is written as a comma seperated list with no spaces between commas
    The rotation about the z-axis through an angle of $\pi /2$, 
		counterclockwise as viewed from the positive z-axis.
		
		\[
		\begin{bmatrix}
			0&-1&0\\
			1&0&0\\
			0&0&1
		\end{bmatrix}
		\]
\end{SaveQuestion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{SaveQuestion}[
        key=ch2-lintrans-sec2.2ex22-sbg,
        prompt={Find the matrix of the linear transformation which goes from $\mathbb{R}^3$ to $\mathbb{R}^3$. The transformation may not be formally defined in the textbook, use common sense. You may assume that the transformation is linear. \\ \textbf{The Linear Transformation:} The rotation about the $y$-axis through an angle $\theta$, counterclockwise as viewed from the positive $y$-axis.}
][ch2-COM-standmat] %this is written as a comma seperated list with no spaces between commas
    [Correct matrix found using the standard vectors*]    %this is written as a comma seperated list with no spaces between commas
    The rotation about the y-axis through an angle $\theta$, counterclockwise as viewed from the positive y-axis.
		
		\[
		\begin{bmatrix}
			\cos \theta &0&\sin \theta \\
			0&1&0\\
			-\sin \theta &0&\cos \theta 
		\end{bmatrix}
		\]

\end{SaveQuestion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{SaveQuestion}[
        key=ch2-lintrans-sec2.2ex23-sbg,
        prompt={Find the matrix of the linear transformation which goes from $\mathbb{R}^3$ to $\mathbb{R}^3$. The transformation may not be formally defined in the textbook, use common sense. You may assume that the transformation is linear. \\ \textbf{The Linear Transformation:} The reflection about the plane $y=z$.}
][ch2-COM-standmat] %this is written as a comma seperated list with no spaces between commas
    [Correct matrix found using the standard vectors*]    %this is written as a comma seperated list with no spaces between commas
    The reflection about the plane y = z.
		
		
		\[
		\begin{bmatrix}
			1&0&0\\
			0&0&1\\
			0&1&0
		\end{bmatrix}
		\]

\end{SaveQuestion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{SaveQuestion}[
        key=ch2-matrix-sec2.2ex26v1-tbd,
        prompt={Find the scaling matrix $A$ that transforms 
        $\begin{bmatrix}
            2 \\ -1
        \end{bmatrix}$
        into 
        $\begin{bmatrix}
            8 \\ -4
        \end{bmatrix}$.
        }
][ch2-CON-geotrans] %this is written as a comma seperated list with no spaces between commas
    [Correct matrix*]    %this is written as a comma seperated list with no spaces between commas
    The effect of the scaling matrix $\begin{bmatrix}k & 0 \\ 0 & k\end{bmatrix}$ on a vector is the same as multiplying the vector by the scalar $k$. The scalar $k$ satisfying $k\begin{bmatrix} 2 \\ -1 \end{bmatrix}=\begin{bmatrix}8 \\ -4\end{bmatrix}$ is $k=4$, thus the matrix that we're seeking is $\begin{bmatrix}4 & 0 \\ 0 & 4\end{bmatrix}$.
\end{SaveQuestion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{SaveQuestion}[
        key=ch2-matrix-sec2.2ex26v2-tbd,
        prompt={Find the orthogonal projection matrix $B$ that transforms $\begin{bmatrix} 2 \\ 3 \end{bmatrix}$ into $\begin{bmatrix} 2 \\ 0 \end{bmatrix}$.}
][ch2-CON-geotrans] %this is written as a comma seperated list with no spaces between commas
    [Correct matrix*]    %this is written as a comma seperated list with no spaces between commas
    If an orthogonal projection sends $\begin{bmatrix}2 \\ 3\end{bmatrix}$ to $\begin{bmatrix}2 \\ 0\end{bmatrix}$, then it must be the projection onto the $x$-axis, whose matrix is given by $\begin{bmatrix}1 & 0 \\ 0 & 0\end{bmatrix}$.
\end{SaveQuestion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{SaveQuestion}[
        key=ch2-matrix-sec2.2ex26v3-tbd,
        prompt={Find the rotation matrix $C$ that transforms $\begin{bmatrix} 0 \\ 5 \end{bmatrix}$ into $\begin{bmatrix} 3 \\ 4 \end{bmatrix}$.}
][ch2-CON-geotrans] %this is written as a comma seperated list with no spaces between commas
    [Correct matrix*]    %this is written as a comma seperated list with no spaces between commas
    If a rotation sends $\begin{bmatrix}0 \\ 5\end{bmatrix}$, which lies in the $x$-axis, to the vector $\begin{bmatrix}3 \\ 4\end{bmatrix}$, then it must be a rotation by the angle determined by the latter vector, which is given by $\theta=\arctan\frac{4}{3}$. Thus the corresponding rotation matrix will be given by $\begin{bmatrix}\cos\arctan\frac{4}{3} & -\sin\arctan\frac{4}{3} \\ \sin\arctan\frac{4}{3} & \cos\arctan\frac{4}{3}\end{bmatrix}$.
\end{SaveQuestion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{SaveQuestion}[
        key=ch2-matrix-sec2.2ex26v4-tbd,
        prompt={Find the shear matrix $D$ that transforms $\begin{bmatrix} 1\\3 \end{bmatrix}$ into $\begin{bmatrix} 7 \\ 3 \end{bmatrix}$.}
][ch2-CON-geotrans] %this is written as a comma seperated list with no spaces between commas
    [Correct matrix*]    %this is written as a comma seperated list with no spaces between commas
    A shear leaves one coordinate unchanged, and replaces the other with a linear combination of both. If such a shear maps $\begin{bmatrix}1 \\ 3\end{bmatrix}$ to $\begin{bmatrix}7 \\ 3\end{bmatrix}$, then it leaves the $y$-coordinate unchanged --thus it's a horizontal shear, and we must be able to write the other as $1+3k$, so we see that $k=2$ and the matrix must be $\begin{bmatrix}1 & 2 \\ 0 & 1\end{bmatrix}$.
\end{SaveQuestion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{SaveQuestion}[
        key=ch2-matrix-sec2.2ex26v5-tbd,
        prompt={Find the reflection matrix $E$ that transforms $\begin{bmatrix} 7 \\ 1 \end{bmatrix}$ into $\begin{bmatrix} -5 \\ 5 \end{bmatrix}$.}
][ch2-CON-geotrans] %this is written as a comma seperated list with no spaces between commas
    [Correct matrix*]    %this is written as a comma seperated list with no spaces between commas
    We have a reflection that maps $\begin{bmatrix}7 \\ 1\end{bmatrix}$ to $\begin{bmatrix}-5 \\ 5\end{bmatrix}$, so by adding these two vectors we should obtain a vector that is parallel to the line on which we are reflecting. This vector is $\begin{bmatrix}2 \\ 6\end{bmatrix}$, which when normalized results in $\frac{1}{\sqrt{10}}\begin{bmatrix}1 \\ 3\end{bmatrix}$. We can now appeal to the formula for a reflection along a line, which we call $T$, in terms of the orthogonal projection along that line, which we call $P$, applied to each of the unit vectors:
			\begin{eqnarray*}
				T(\vec{e_1}) & = & 2P(\vec{e_1})-\vec{e_1}=2\left(\vec{e_1}\cdot\begin{bmatrix}\frac{1}{\sqrt{10}} \\ \frac{3}{\sqrt{10}}\end{bmatrix}\right)\begin{bmatrix}\frac{1}{\sqrt{10}} \\ \frac{3}{\sqrt{10}}\end{bmatrix}-\vec{e_1} \\
				& = & \frac{2}{10}\begin{bmatrix}1 \\ 3\end{bmatrix}-\vec{e_1}=\begin{bmatrix}-\frac{4}{5} \\ \frac{3}{5}\end{bmatrix},
			\end{eqnarray*}
			and
			\begin{eqnarray*}
				T(\vec{e_2}) & = & 2P(\vec{e_2})-\vec{e_2}=2\left(\vec{e_2}\cdot\begin{bmatrix}\frac{1}{\sqrt{10}} \\ \frac{3}{\sqrt{10}}\end{bmatrix}\right)\begin{bmatrix}\frac{1}{\sqrt{10}} \\ \frac{3}{\sqrt{10}}\end{bmatrix}-\vec{e_2} \\
				& = & \frac{6}{10}\begin{bmatrix}1 \\ 3\end{bmatrix}-\vec{e_2}=\begin{bmatrix}\frac{3}{5} \\ \frac{4}{5}\end{bmatrix},
			\end{eqnarray*}
			and therefore the matrix that we're seeking is
			\begin{equation*}
				\begin{bmatrix}-\frac{4}{5} & \frac{3}{5} \\ \frac{3}{5} & \frac{4}{5}\end{bmatrix}
			\end{equation*}
\end{SaveQuestion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{SaveQuestion}[
        key=ch2-matrix-sec2.3ex34-sbg,
        prompt={Compute $A^2 = AA, A^3 = AAA$, and $A^4$. Describe the pattern that emerges, and use this pattern to find $A^{1001}$. Interpret your answer geometrically, in terms of rotations, reflections, shears, or orthogonal projections. \\ Let $A = \begin{bmatrix}
            1 & 1 \\ 0 & 1
        \end{bmatrix}$.}
][ch2-VG-comp] %this is written as a comma seperated list with no spaces between commas
    [Correct matrix for each exponent*Correct geometrical description*]    %this is written as a comma seperated list with no spaces between commas
    $A=\begin{bmatrix}1 & 1 \\ 0 & 1\end{bmatrix}$
			
			$A^2=\begin{bmatrix}1 & 2 \\ 0 & 1\end{bmatrix}$
			
			$A^3=\begin{bmatrix}1 & 3 \\ 0 & 1\end{bmatrix}$
			
			$A^4=\begin{bmatrix}1 & 4 \\ 0 & 1\end{bmatrix}$,
			
			so following the pattern,
			
			$A^{1001}=\begin{bmatrix}1 & 1001 \\ 0 & 1\end{bmatrix}$.

\end{SaveQuestion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{SaveQuestion}[
        key=ch2-matrix-sec2.3ex36-sbg,
        prompt={Compute $A^2 = AA, A^3 = AAA$, and $A^4$. Describe the pattern that emerges, and use this pattern to find $A^{1001}$. Interpret your answer geometrically, in terms of rotations, reflections, shears, or orthogonal projections. \\ Let $A = \begin{bmatrix}
            1 & 0 \\ 0 & -1
        \end{bmatrix}$.}
][ch2-VG-comp] %this is written as a comma seperated list with no spaces between commas
    [Correct matrix for each exponent*Correct geometrical description*]    %this is written as a comma seperated list with no spaces between commas
    $A=\begin{bmatrix}1 & 0 \\ 0 & -1\end{bmatrix}$
			
			$A^2=\begin{bmatrix}1 & 0 \\ 0 & 1\end{bmatrix}$
			
			$A^3=\begin{bmatrix}1 & 0 \\ 0 & -1\end{bmatrix}$
			
			$A^4=\begin{bmatrix}1 & 0 \\ 0 & 1\end{bmatrix}$,
			
			so following the pattern (indicating that even powers equal $I_2$, and odd powers equal $A$), we get that 
			
			$A^{1001}=A=\begin{bmatrix}1 & 0 \\ 0 & -1\end{bmatrix}$, since $1001$ is odd.

\end{SaveQuestion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{SaveQuestion}[
        key=ch2-matrix-sec2.3ex40-sbg,
        prompt={Compute $A^2 = AA, A^3 = AAA$, and $A^4$. Describe the pattern that emerges, and use this pattern to find $A^{1001}$. Interpret your answer geometrically, in terms of rotations, reflections, shears, or orthogonal projections. \\ Let $A = \begin{bmatrix}
            0 & -1 \\ 1 & 0
        \end{bmatrix}$.}
][ch2-VG-comp] %this is written as a comma seperated list with no spaces between commas
    [Correct matrix for each exponent*Correct geometrical description*]    %this is written as a comma seperated list with no spaces between commas
    $A=\begin{bmatrix}0 & -1 \\ 1 & 0\end{bmatrix}$
			
			$A^2=\begin{bmatrix}-1 & 0 \\ 0 & -1\end{bmatrix}$
			
			$A^3=\begin{bmatrix}0 & 1 \\ -1 & 0\end{bmatrix}$
			
			$A^4=\begin{bmatrix}1 & 0 \\ 0 & 1\end{bmatrix}$.
			
			The pattern seems to be that $A^n$ is either $A,A^2,A^3,I_2$, according to whether the remainder of dividing $n$ by $4$ is $1,2,3$ or $0$. (The technical lingo here would be that $A$ generates a cyclic group of order $4$.) So if we follow the pattern, since $1001\equiv 1\mod 4$, we have that
			
			$A^{1001}=A=\begin{bmatrix}0 & -1 \\ 1 & 0\end{bmatrix}$.

\end{SaveQuestion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{SaveQuestion}[
        key=ch2-matrix-sec2.3ex44-sbg,
        prompt={Find a $2 \times 2$ matrix $A$ with the property $A^2 \neq I_2, A^4 = I_2$. Hint: It helps to think of geometrical examples.}
][ch2-VG-comp,chg-CON-exp] %this is written as a comma seperated list with no spaces between commas
    [Correct example*Correct geometrical description*]    %this is written as a comma seperated list with no spaces between commas
    Geometrically, it looks like a rotation by $\frac{\pi}{2}$ satisfies that its square isn't the identity, but its fourth power is. So we just need to write down the matrix for such a rotation, $A=\begin{bmatrix}\cos\frac{\pi}{2} & -\sin\frac{\pi}{2} \\ \sin\frac{\pi}{2} & \cos\frac{\pi}{2} \end{bmatrix}=\begin{bmatrix}0 & -1 \\ 1 & 0 \end{bmatrix}$.
\end{SaveQuestion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{SaveQuestion}[
        key=ch2-matrix-sec2.3ex46-sbg,
        prompt={Find a $2 \times 2$ matrix $A$ with the property $A^2 = A$, and all entries of $A$ are nonzero. Hint: It helps to think of geometrical examples.}
][ch2-VG-comp,chg-CON-exp]
    [Correct example*Correct geometrical description*]
    Geometrically, it looks like applying an orthogonal projection twice is the same as applying it once. If we want all entries nonzero, we better project onto a vector with both entries nonzero, so for example $\begin{bmatrix}1 \\ 1\end{bmatrix}$ works. It is easy to see, after applying the relevant computations, that 
			\begin{equation*}
				\left(\begin{bmatrix}x_1 \\ x_2\end{bmatrix}\cdot\begin{bmatrix}\frac{1}{\sqrt{2}} \\ \frac{1}{\sqrt{2}}\end{bmatrix}\right)\begin{bmatrix}\frac{1}{\sqrt{2}} \\ \frac{1}{\sqrt{2}}\end{bmatrix}=\frac{1}{2}\begin{bmatrix}x_1+x_2 \\ x_1+x_2\end{bmatrix}=\begin{bmatrix}\frac{1}{2} & \frac{1}{2} \\ \frac{1}{2} & \frac{1}{2}\end{bmatrix}\begin{bmatrix}x_1 \\ x_2\end{bmatrix}.
			\end{equation*}
\end{SaveQuestion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{SaveQuestion}[
        key=ch6-det-sec6.1ex43-sbg,
        prompt={If $A$ is an $n \times n$ matrix, what is the relationship between $\det A$ and $\det (-A)$?}
][ch6-COM-detprop] %this is written as a comma seperated list with no spaces between commas
    [Correct formula or the correct comment on even vs odd n values*]    %this is written as a comma seperated list with no spaces between commas
    \[
	\det(-1 A)=(-1)^n\det A
	\]
\end{SaveQuestion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{SaveQuestion}[
        key=ch6-det-sec6.1ex46-sbg,
        prompt={If $A$ is an invertible $2 \times 2$ matrix, what is the relationship between $\det A$ and $\det (A^{-1})$?}
][ch6-COM-detprop] %this is written as a comma seperated list with no spaces between commas
    [Correct formula*]    %this is written as a comma seperated list with no spaces between commas
    \[
	\det( A^{-1})=\frac{1}{\det A}
	\]
\end{SaveQuestion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{SaveQuestion}[
        key=ch6-det-sec6.2ex39-sbg,
        prompt={If $A$ is an invertible matrix, what can you say about the sign of $\det (A^TA)$?}
][ch6-COM-detprop] %this is written as a comma seperated list with no spaces between commas
    [Correct answer with reasoning to back it up*]    %this is written as a comma seperated list with no spaces between commas
    Suppose $A$ is invertible. Then $\det (A^TA)=\det A^T\det A=\det A^2\geq 0$. 
\end{SaveQuestion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{SaveQuestion}[
        key=ch6-det-sec6.2ex43-sbg,
        prompt={Consider two vectors $\vec v$ and $\vec w$ in $\bbR^n$. Form the matrix $A = \begin{bmatrix} \vec v & \vec w \end{bmatrix}$. Express $\det (A^TA)$ in terms of $\| \vec v \|, \| \vec w \|$, and $\vec v \cdot \vec w$. What can you say about the sign of the result?}
][ch6-COM-detprop] %this is written as a comma seperated list with no spaces between commas
    [Correct final answer with work shown*]    %this is written as a comma seperated list with no spaces between commas
    First, let's compute $A^TA$. Let $A-[\vec v\:\vec w]$ then 
	\[
	A^TA=\begin{bmatrix}
		\vec v\\\vec w
	\end{bmatrix}\begin{bmatrix}
		\vec v&\vec w
	\end{bmatrix}=\begin{bmatrix}\vec v\cdot \vec v&\vec v\cdot \vec w\\\vec w\cdot \vec v&\vec w\cdot\vec w\end{bmatrix}
	\]
	Hence 
	\[
	\det(A^TA)=\det \begin{bmatrix}\vec v\cdot \vec v&\vec v\cdot \vec w\\\vec w\cdot \vec v&\vec w\cdot\vec w\end{bmatrix}=\|\vec v\|\|\vec w\|-\vec v\cdot \vec w
	\]		
	Let $\theta$ be the angle between $\vec v$ and $\vec w$. Then $1\leq \cos\theta\leq 1$. Note that $\vec v\cdot \vec w=\|\vec v\|\|\vec w\|\cos \theta$, and that norm of vectors are non-negative. Therefore $-\|\vec v\|\|\vec w\|\leq \|\vec v\|\|\vec w\|\cos \theta		\leq \|\vec v\|\|\vec w\|$. This guarantees that $\|\vec v\|\|\vec w\|-\vec v\cdot \vec w\geq 0$.
\end{SaveQuestion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%       CHAPTER 5 QUESTIONS          %%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{SaveQuestion}[
        key=ch5-orthogonal-definitions-dev,
        prompt={Write down a complete definition or complete mathematical characterization for each of the following.
        \begin{enumerate}
            \item Orthogonal decomposition of a vector $\vec u$ in $\bbR^n$.
            \item Orthogonal complement of a subspace $W$ in $\bbR^n$.
            \item An orthogonal basis for a subspace $W$ of $\bbR^n$.
            \item An orthonormal basis for a subspace $W$ of $\bbR^n$.
        \end{enumerate}}
][chg-WRIT-matcom] %this is written as a comma seperated list with no spaces between commas
    []    %this is written as a comma seperated list with no spaces between commas
    Verify the definitions in the textbook.
\end{SaveQuestion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{SaveQuestion}[
        key=ch5-subspace-orthobasisv1-sbg,
        prompt={\begin{enumerate}
            \item Let $V$ be a subsapce of $\bbR^4$ given by
            $$x_1 - x_2 - 2x_3 = 0.$$ $$x_2 + x_3 - 2x_4 = 0.$$
            Find a basis of $V$. Find an orthonormal basis of $V$.
            \item Let $\vec w$ be the vector 
            $$\vec w = \begin{bmatrix} 1 \\ 2 \\ -1 \\ 2 \end{bmatrix} \in \bbR^4.$$
            Find the orthogonal projection of $\vec w$ onto the subspace $V$.
        \end{enumerate}}
][ch5-CON-orthotype,ch5-COM-vecdecomp] %this is written as a comma seperated list with no spaces between commas
    [Correctly found an orthonormal basis for V*,Correctly found the projection*]    %this is written as a comma seperated list with no spaces between commas
    \begin{enumerate}
		\item 
		Writing the equations as rows yields the matrix $\begin{bmatrix} 1 & -1 & -2 & 0 \\ 0 & 1 & 1 & -2 \end{bmatrix}$. Letting the last two columns be the free variables $r, s$, the nullspace is given by $[(-s+2r)+2s, -s+2r, s, r]$, which is spanned by the following two vectors: 
			\[
			(\vec{u},\vec{v}) \ = \ \left(\begin{bmatrix} 1 \\ -1 \\ 1 \\ 0 \end{bmatrix}, \begin{bmatrix} 2 \\ 2 \\ 0 \\ 1 \end{bmatrix}\right),
			\]
			These are already orthogonal, so normalizing gives the orthonormal basis $\left(\frac{1}{\sqrt{3}}\vec{u},\frac{1}{3}\vec{v}\right)$.
			\item 	Letting $\vec{u},\vec{v}$ be as in the solution to Problem 1, we have
			\[
			\text{proj}_{V}(\vec{w}) \ = \ \left(\vec{w}\cdot\frac{1}{\sqrt{3}}\vec{u}\right)\frac{1}{\sqrt{3}}\vec{u} + \left(\vec{w}\cdot\frac{1}{3}\vec{v}\right)\frac{1}{3}\vec{v} \ = \ \frac{1}{9}\begin{bmatrix} 10 \\ 22 \\ -6 \\ 8 \end{bmatrix}.
			\]
		\end{enumerate}
\end{SaveQuestion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{SaveQuestion}[
        key=ch5-subspace-orthobasisv2-sbg,
        prompt={\begin{enumerate}
            \item Let $V$ be the subspace of $\bbR^4$ given by
            $$x_1 + x_2 - x_3 - 2x_4 = 0.$$
            Find a basis of $V$. Find an orthonormal basis of $V$.
            \item Let $\vec w$ be the vector 
            $$\vec w = \begin{bmatrix} 1 \\ 2 \\ -1 \\ 2 \end{bmatrix} \in \bbR^4.$$
            Find the orthogonal projection of $\vec w$ onto the subspace $V$.
        \end{enumerate}}
][ch5-COM-gram,ch5-COM-vecdecomp] %this is written as a comma seperated list with no spaces between commas
    [Correctly found an orthonormal basis for V using the Gram-Schmit process*,Correctly found the projection*]    %this is written as a comma seperated list with no spaces between commas
    \begin{enumerate}
			\item 	By inspection, $\vec{u}=\begin{bmatrix} 1 \\ 0 \\ 1 \\ 0 \end{bmatrix}$ and $\vec{v}=\begin{bmatrix} 0 \\ 2 \\ 0 \\ 1 \end{bmatrix}$ are orthogonal vectors in $V$, and $\vec{z}=\begin{bmatrix} 1 \\ 0 \\ -1 \\ 1 \end{bmatrix}\in V$ is independent of $\vec{u}$ and $\vec{v}$ (e.g. the zeros in components do not match) and orthogonal to $\vec{u}$. So
			\[
			\left(\vec{u},\vec{v},\vec{z}-\text{proj}_{\vec{v}}(\vec{z})\right) \ = \ \left(\vec{u},\vec{v},\vec{z}-\frac{\vec{z}\cdot\vec{v}}{\vec{v}\cdot\vec{v}}\vec{v}\right) \ = \ \left(\begin{bmatrix} 1 \\ 0 \\ 1 \\ 0 \end{bmatrix}, \begin{bmatrix} 0 \\ 2 \\ 0 \\ 1 \end{bmatrix}, \begin{bmatrix} 1 \\ -\frac{2}{5} \\ -1 \\ \frac{4}{5} \end{bmatrix} \right)
			\]
			is an orthogonal set in $V$ (e.g. $\vec z_{\vec{v}^\perp} = z - \text{proj}_{\vec v}(\vec z)$, so this vector is orthogonal to $\vec v$, and since $\text{proj}_{\vec v}(\vec z)$ is parallel to $\vec v$ which is orthogonal to $\vec u$, and since $\vec z$ is orthogonal to $\vec u$, therefore $\vec{z}_{\vec{v}^\perp} \cdot \vec u = \vec z \cdot \vec u - \text{proj}_{\vec v}(\vec z) \cdot u = 0 - 0 = 0$), and by normalizing we get an orthonormal basis of $V$.
			\item 	Letting $\vec{u},\vec{v}$ be as in the solution to Problem 1, we have
			\[
			\text{proj}_{V}(\vec{w}) \ = \ \begin{bmatrix} 1 \\ 2 \\ -1 \\ 2 \end{bmatrix}.
			\]
		
		\end{enumerate}
\end{SaveQuestion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{SaveQuestion}[
        key=ch5-subspace-orthobasisv3-sbg,
        prompt={\begin{enumerate}
            \item Let $V$ be a subspace of $\bbR^4$ given by
            $$x_1 - x_2 - 2x_3 = 0$$ $$x_2 + x_3 - 2x_4 = 0$$ $$x_1 - x_2 + x_3 = 0$$
            \begin{enumerate}
                \item Find a basis for $V$, find an orthonormal basis for $V$.
                \item Write the definition for $V^{\perp}$. Find a basis for $V^{\perp}$. Find an orthonormal basis for $V^{\perp}$.
            \end{enumerate}
            \item Let $\vec w$ be the vector 
            $$\vec w = \begin{bmatrix} 1 \\ 2 \\ -1 \\ 2 \end{bmatrix} \in \bbR^4.$$
            \begin{enumerate}
            \item Find the orthogonal projection of $\vec w$ onto the subspace $V$, call it $\vec w_1$.
            \item Find the orthogonal projection of $\vec w$ onto the subspace $V^{\perp}$, call it $\vec w_2$.
            \item What is $\vec w_1 + \vec w_2$?
            \end{enumerate}
        \end{enumerate}}
][ch5-COM-gram,ch5-COM-vecdecomp] %this is written as a comma seperated list with no spaces between commas
    [Correctly found an orthonormal basis for V and V perp using the Gram-Schmit process*,All correct answers for part 2 (a b and c)*]    %this is written as a comma seperated list with no spaces between commas
    \begin{enumerate}
    \begin{enumerate}
    
		\item 
		Writing the equations as rows yields the matrix $\begin{bmatrix} 1 & -1 & -2 & 0 \\ 0 & 1 & 1 & -2 \\ 1 & -1 & 1 & 0 \end{bmatrix}$. Since we are looking for the kernel we write the augmented matrix $\begin{amatrix}{4} 1 & -1 & -2 & 0 & 0 \\ 0 & 1 & 1 & -2 & 0 \\ 1 & -1 & 1 & 0 & 0 \end{amatrix}$, which row reduces to $\begin{amatrix}{4} 1 & 0 & 0 & -2 & 0 \\ 0 & 1 & 0 & -2 & 0 \\ 0 & 0 & 1 & 0 & 0 \end{amatrix}$. This means
        $$x_1 - 2x_4 = 0 $$ $$x_2 - 2x_4 = 0$$ and $$x_3 = 0$$ Since $x_4$ is our free variable, this gives us $$x_1 = 2x_4$$  $$x_2 = 2x_4$$ and $$x_3=0$$, and choosing a value of $x_4=1$ gives us the vector $\begin{bmatrix}
            2 \\ 2 \\ 0 \\ 1
        \end{bmatrix}$ as a vector in $V$ and the only vector in the basis for $V$. \\
        Now that I have a basis for $V$, I must normalize it to get the vector $\vec v = \begin{bmatrix}
            2/3 \\ 2/3 \\ 0 \\ 1/3
        \end{bmatrix}$.
        \item $V^{\perp} =$ the set of all vectors perpendicular to $V$. A basis for $V^{\perp}$ can be found using the coefficients of the normal equations used to define $V$. We get basis $= \{ \begin{bmatrix}
            1 \\ -1 \\ -2 \\ 0
        \end{bmatrix}, \begin{bmatrix}
            0 \\ 1 \\ 1 \\ -2
        \end{bmatrix}, \begin{bmatrix}
            1 \\ -1 \\ 1 \\ 0
        \end{bmatrix} \}$ and to get an orthonormal basis we need to perform Gram-Schmidt, so $$\vec v_1 = \begin{bmatrix} 1 \\ -1 \\ -2 \\ 0 \end{bmatrix}, \vec v_2 = \begin{bmatrix} 0 \\ 1 \\ 1 \\ -2 \end{bmatrix}, \vec v_3 = \begin{bmatrix} 1 \\ -1 \\ 1 \\ 0 \end{bmatrix}$$ 
        $$\vec u_1 = \frac{1}{\sqrt{6}} \begin{bmatrix} 1 \\ -1 \\ -2 \\ 0 \end{bmatrix}$$
        $$\vec v_2^{\perp} = \vec v_2 - (\vec u_1 \cdot \vec v_2)\vec u_1 = \begin{bmatrix} \frac{1}{2} \\ \frac{1}{2} \\ 0 \\ -2 \end{bmatrix}$$ 
        $$\vec u_2 = \frac{1}{||\vec v_2^{\perp}||}\vec v_2^{\perp} = \frac{\sqrt{2}}{3}\begin{bmatrix} \frac{1}{2} \\ \frac{1}{2} \\ 0 \\ -2 \end{bmatrix}$$ 
        $$\vec v_3^{\perp} = \vec v_3 - (\vec u_1 \cdot \vec v_3)\vec u_1 - (\vec u_2 \cdot \vec v_3)\vec u_2 = \begin{bmatrix} 1 \\ -1 \\ 1 \\ 0 \end{bmatrix}$$ 
        $$\vec u_3 = \frac{1}{||\vec v_3^{\perp}||}\vec v_3^{\perp} = \frac{1}{\sqrt{3}}\begin{bmatrix}
            1 \\ -1 \\ 1 \\ 0
        \end{bmatrix}$$
        \end{enumerate}
        \begin{enumerate}
			\item 	Letting $\vec{v}$ be as in the solution to Problem 1, we have
			\[
			\text{proj}_{V}(\vec{w}) \ = \ \left(\vec{w}\cdot\vec{v}\right)\vec{v} \ = \ \frac{8}{3} \vec v = \begin{bmatrix}
			    \frac{16}{9} \\ \frac{16}{9} \\ 0 \\ \frac{8}{9}
			\end{bmatrix}.
			\]
            \item Letting $\vec u_1, \vec u_2, \vec u_3$ be as in the solution to Problem 1, we have
            $$
            \text{proj}_{V^{\perp}}(\vec{w}) \ = \ \left(\vec{w}\cdot\vec{u}_1\right)\vec{u}_1 + \left(\vec{w}\cdot\vec{u}_2\right)\vec{u}_2 + \left(\vec{w}\cdot\vec{u}_3\right)\vec{u}_3 \ = \ \begin{bmatrix}
			    \frac{-7}{9} \\ \frac{2}{9} \\ -1 \\ \frac{10}{9}
			\end{bmatrix}.
            $$
            \item We notice that $\vec w_1 + \vec w_2 = \vec w$
        \end{enumerate}
		\end{enumerate}
\end{SaveQuestion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{SaveQuestion}[
        key=ch5-subspace-projsum-dev,
        prompt={Let $W$ be a subspace of $\bbR^n$. We saw in class that for every $\vec x \in \bbR^n$ there is a unique vector $\proj_{W}\vec x \in W$ such that $\vec x - \proj_{W}\vec x$ is orthogonal to $W$. The vector $\proj_{W}\vec x$ is called the orthogonal projection of $\vec x$ onto $W$, and we found a formula for it: if $\mathcal{U} = \{\vec {u_1}, ...,\vec {u_m}\}$ is an orthonormal basis of $W$, then $$\proj_W(\vec x) = \sum_{i=1}^m (\vec x \cdot \vec {u_i}) \vec {u_i}.$$\begin{enumerate}
        \item The transformation $\proj_{W}: \bbR^n \rightarrow \bbR^n$ is linear. To see this, justify this fact using the definition of a linear transformation on $\proj_{W}: \bbR^n \rightarrow \bbR^n$ when $\dim(W) = 2$.
        \item What is the kernel of $\proj_W$?
        \item Write the rank nullity equation for this transformation. Is it familiar?
        \item (OPTIONAL) Since the orthogonal projection $\proj_W : \bbR^n \rightarrow \bbR^n$ is linear, is there an $n \times n$ matrix $P$ such that $\proj_W (\vec x) = P \vec x$ for all $\vec x \in \bbR^n$? Can you find it?
        \end{enumerate}}
][chg-WRIT-matcom] %this is written as a comma seperated list with no spaces between commas
    [Satisfactory: Good logic on linearity, notation mistakes are fine, correct kernel is the orthogonal compliment, and correct dimensions add up to n*Can Be Improved: Some mistakes on things listed as needed for satisfactory*Try Again: Majoy conceptual misunderstanding*]    %this is written as a comma seperated list with no spaces between commas
    \begin{enumerate}
		\item Using the formula $\text{proj}_W(\vec{x}) = \sum_{i=1}^m(\vec{x}\cdot\vec{u}_i)\vec{u}_i$, this follows from the linearity of the dot product.
		\item 	$W^\bot$. For example, if $\text{proj}_W(\vec x) = \vec 0$, then $\vec x = \vec x - \text{proj}(\vec x)$ is orthogonal to $W$, i.e. $\vec x \in W^\perp$. 
		\item 	Since $W=\mathrm{Im}(\text{proj}_W)$ and $W^\bot=\ker(\text{proj}_W)$, the rank-nullity theorem says $\text{dim}(W)+\text{dim}(W^\bot)=n$
		\item This is the content of Theorem 5.3.10
	\end{enumerate}
\end{SaveQuestion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{SaveQuestion}[
        key=ch5-subspace-orthobasisr3-sbg,
        prompt={Let $V$ be the subspace of $\bbR^3$ spanned by $\begin{bmatrix} 1 \\ 0 \\ 1 \end{bmatrix}$ and $\begin{bmatrix} 0 \\ 1 \\ 0 \end{bmatrix}$. \begin{enumerate}
        \item Find a basis for $V^\bot$.
        \item Find an orthonormal basis for $V$. Use it to compute the projection of $\vec w = \begin{bmatrix} 1 \\ 2 \\ 3 \end{bmatrix}$ onto the plane $V$. Now write $\vec w = \vec{w_1} + \vec {w_2}$, where $\vec {w_1} \in V$ and $\vec {w_2} \in V^\bot$. Is this expression unique?
        \item Find the standard matrix of $\proj_V$. 
        \item Find the kernel of $\proj_V$. How does this compare to $V^\bot$?
        \item What is $\dim V^\bot + \dim V$? How can you see this an instance of rank-nullity?
        \item Explain why the union of an orthonormal basis for $V$ and one for $V^\bot$ are a basis for $\bbR^3$. What is the matrix of $\pi_V$ in this basis?
        \end{enumerate}}
][ch5-COM-vecdecomp,ch5-VG-kerim,ch5-COM-gram] %this is written as a comma seperated list with no spaces between commas
    []    %this is written as a comma seperated list with no spaces between commas
    \begin{enumerate}
        \item We are looking for vectors  $[a\,\,\,\, b \,\,\,\,\, c]^T$ 
				that have dot product zero with both  $\begin{bmatrix} 1\\ 0 \\1 \end{bmatrix}$ and $\begin{bmatrix} 0\\ 1 \\0 \end{bmatrix}.$ 
				Dotting with the second vector, we see $b = 0$. Dotting with the first, we see $a = -c$. So we get  $V^{\perp}$ is the one dimensional subspace with basis  $[1\,\,\,\,\, 0 \,\,\,\,\,\, -1]^T$.
        \item We can take $\begin{bmatrix} 1/\sqrt 2\\ 0 \\1/\sqrt 2 \end{bmatrix}$ and $\begin{bmatrix} 0\\ 1 \\0 \end{bmatrix}$ as the required orthonormal basis $\{\vec u_1, \vec u_2\}$ in the theorem.  Then the projection is 
				$$(\vec w \cdot \vec u_1)\vec u_1 + (\vec w \cdot \vec u_2) \vec u_2 = 2\sqrt 2 \vec u_1 + 2 \vec u_2 = \begin{bmatrix} 2\\ 2 \\2 \end{bmatrix}.
				$$
				Now we can take this projection to be $\vec w_1$, and $\vec w_2$ therefore must be $\vec w -  \vec w_1 =  \begin{bmatrix} -1\\ 0 \\1 \end{bmatrix}, $ which is in $V^{\perp}$.
				So the decomposition of $\vec w$ into its components in $V$ and $V^{\perp}$ is 
				$$
				\begin{bmatrix} 3\\ 2 \\1 \end{bmatrix} =  \begin{bmatrix} 2\\ 2 \\2 \end{bmatrix} + \begin{bmatrix} -1\\ 0 \\ 1 \end{bmatrix}.
				$$ It is unique.
        \item $A = \begin{bmatrix} 1/2 & 0  & 1/2  \\ 0 & 1  & 0  \\ 1/2 & 0  & 1/2 \end{bmatrix}$.
        \item The kernel is the solutions of $A\vec x = \vec 0$. Solving, we see the kernel is   the one dimensional space with basis $[1\,\,\,\,0 \,\,\,\,\, -1]^T$. This is the same as $V^{\perp}$! This makes sense, since the line through the origin  perpendicular to the plane consists exactly of the vectors which map to zero under the projection to the plane.
        \item We see $1 + 2  = 3$. This is rank nullity for $\pi_V$, since $V$ is the image of $\pi_V$, $V^{\perp}$ is the kernel of $\pi_V$, and $\mathbb{R}^3$ is the source of $\mathbb{R}^3$.
        \item $V$ and $V^{\perp}$ have only the zero vector in common. So a basis for $V$ and a basis for $V^{\perp}$ will combine to get a basis for $ \mathbb{R}^n$. 
					To see why it is an orthonormal basis: we already know all have unit length. We also know that anything in $V$ has dot product against anything in $V^{\perp}$. And the dot product of two elements both in the orthonormal basis for  $V$ or both in  the orthonormal basis $V^{\perp}$ also produces zero.
    \end{enumerate}
\end{SaveQuestion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{SaveQuestion}[
        key=ch5-ortho-transpose-sbg,
        prompt={Theorem 2.4.8 in chapter 2 states that if $A$ and $B$ are square matrices and $BA=I$, then the following are true:
        \begin{itemize}
        \item $A$ and $B$ are both invertible
        \item $A^{-1} = B$ and $B^{-1}=A$
        \item $AB=I$
        \end{itemize}
        \begin{enumerate}
	    \item[(a)] Consider an $n \times m$ matrix $A$ such that $A^TA=I_m$. Is it necessarily true that $AA^T = I_n$? Explain or give a counter-example.
        \item[(b)] Consider an $n \times n$ matrix $A$ such that $A^TA=I_n$. Is it necessarily true that $AA^T=I_n$? Explain or give a counter-example.
        \item[(c)] Consider an $n \times n$ matrix $A$ which has orthonormal columns. Compute $A^TA$, what is it equal to? Is it the same as $AA^T$? (Hint: refer to part b). Can we say that $A^T = A^{-1}$?
	\end{enumerate}}
][chg-CON-tf] %this is written as a comma seperated list with no spaces between commas
    [Correct True False for part a and b and reasonable justification*]    %this is written as a comma seperated list with no spaces between commas
    \begin{enumerate}
    \item [(a)] Not True. Counter example: $A = 
    \begin{bmatrix}
        \frac{1}{\sqrt{2}} & 0 & \frac{1}{\sqrt{2}} \\
        0 & 1 & 0
    \end{bmatrix}$ since 
    $A^TA = \begin{bmatrix}
        1 & 0 \\ 0 & 1
    \end{bmatrix} = I_2$ but 
    $AA^T = \begin{bmatrix}
        \frac{1}{2} & 0 & \frac{1}{2}\\ 0 & 1 & 0 \\ \frac{1}{2} & 0 & \frac{1}{2}
    \end{bmatrix} \neq I_3$
    \item [(b)] True.  
    Theorem 2.4.8 in chapter 2 states that if $A$ and $B$ are square matrices and $BA=I$, then the following are true:
    \begin{itemize}
        \item $A$ and $B$ are both invertible
        \item $A^{-1} = B$ and $B^{-1}=A$
        \item $AB=I$
    \end{itemize}
    \item[(c)] If $A = [a_1 a_2 ... a_n]$ where $a_i$ is a column vector, then $A^TA = \begin{bmatrix}
        a_1 \cdot a_1 & \dots & a_1 \cdot a_n \\
        \vdots & \ddots & \vdots \\
        a_n \cdot a_1 & \dots & a_n \cdot a_n
    \end{bmatrix}$. If the columns of $A$ are orthonormal we get $A^TA = I_n$. By part b since $A$ is square we also get $AA^T = I_n$. Since $A^TA=AA^T=I$ this is the definition of the inverse matrix (which is unique) so yes, $A^T=A^{-1}$.
\end{enumerate}
\end{SaveQuestion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{SaveQuestion}[
        key=ch5-leastsquare-closevec-sbg,
        prompt={\begin{enumerate}
            \item True/False A least square solution to $A\vec x=\vec b$ is the solution to $A\vec x=proj_{Col(A)} \vec b$
            \item Find the least square solution $\vec x^*$ to the system $A\vec x=\vec b$, where 
            $$A=\begin{bmatrix}
                6&9\\3&8\\2&10
            \end{bmatrix}, \quad \quad \vec b=\begin{bmatrix}
                0\\49\\0
            \end{bmatrix}
            $$
            Use paper and a pencil. Draw a sketch showing the vector $\vec b$, the image (or the column space) of $A$, the vector $A\vec x^*$, and the vector $\vec b -A\vec x^*$. Determine the error $\|\vec b-A\vec x^*\|$.
            \end{enumerate}
  }
][ch5-CON-inconsys] %this is written as a comma seperated list with no spaces between commas
    [Find a least square solution any of the 3 ways described in the PCE9*]    %this is written as a comma seperated list with no spaces between commas
    \begin{enumerate}
        \item True. A least square solution to $A\vec x=\vec b$ is a consistent system closest to $A\vec x=\vec b$. That is, it is a solution to $A\vec x=proj_{Col(A)} \vec b$.
        \item The least-square solution to $A\vec x=\vec b$ is a solution to $A^TA\vec x=A^T\vec b$. We solve
        \[
        \begin{bmatrix} 49&98\\98&245\end{bmatrix}\vec x=\begin{bmatrix}
            147\\392
        \end{bmatrix}
        \]
        This is now solvable so we create an augmented matrix and row reduce to get the vector $\vec x$ 
        $$ \begin{amatrix}{2} 49 & 98 & 147 \\ 98 & 245 & 392 \end{amatrix} \rightarrow \begin{amatrix}{2} 49 & 98 & 147 \\ 0 & 49 & 98 \end{amatrix} \rightarrow \begin{amatrix}{2} 49 & 0 & -49 \\ 0 & 49 & 98 \end{amatrix} \rightarrow \begin{amatrix}{2} 1 & 0 & -1 \\ 0 & 1 & 2 \end{amatrix}$$
        So $\vec x = \begin{bmatrix}
            -1 \\ 2
        \end{bmatrix}$.
    \end{enumerate}
\end{SaveQuestion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{SaveQuestion}[
        key=ch5-leastsquare-data-sbg,
        prompt={Fit a linear function of the form $f(t)=c_0+c_1t$ to
        the data points $$(0, 3), (1, 3), (1, 6)$$ using least squares. Sketch the solution.}
][ch5-CON-projfit] %this is written as a comma seperated list with no spaces between commas
    [Plug in points then when they get an inconsistent system solve it in any of the 3 ways from PCE9*]    %this is written as a comma seperated list with no spaces between commas
    Plugging in the points, we get
    \begin{eqnarray} \nonumber
    3&=&c_0\\ \nonumber
    3&=&c_0+c_1\\ \nonumber
    6&=& c_0+c_1
    \end{eqnarray}
    By inspection or row reduction, this system is inconsistent. Let $A=\begin{bmatrix}
    1&0\\1&1\\1&1\end{bmatrix}$ and $\vec b=\begin{bmatrix}3\\3\\6\end{bmatrix}$. We approximate a solution to $A\vec x=\vec b$ by solving $A\vec x=proj_{col(A)} \vec b$. Any solution to $A\vec x=proj_{col(A)} \vec b$ is a solution to $A^TA\vec x=A^T\vec b$. Note that $A^TA=\begin{bmatrix} 3&2\\2&2\end{bmatrix}$ and $A^T\vec b=\begin{bmatrix}12\\9\end{bmatrix}$. We solve
    \[
    \begin{bmatrix} 3&2\\2&2\end{bmatrix}\vec x=\begin{bmatrix}12\\9\end{bmatrix}
    \]
    and get $\begin{bmatrix}3\\3/2\end{bmatrix}$. 
\end{SaveQuestion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{SaveQuestion}[
        key=ch5-ortho-tfae-dev,
        prompt={Summary 5.3.8 on Orthogonal matrices which can be found on page 230 of the textbook states that for any $n \times n$ matrix $A$, the following are equivalent:\begin{enumerate}
    \item The columns of A form an orthonormal basis of $\mathbb{R}^n$.
    \item $A^TA=I_n$.
    \item $A$ preserves the dot product, meaning that $(A \vec x) \cdot (A \vec y) = \vec x \cdot \vec y$ for all $\vec x$ and $\vec y$ in $\mathbb{R}^n$.
    \item The transformation $L(\vec x) = A \vec x$ preserves length; that is, $|| A \vec x || = ||\vec x ||$ for all $\vec x$ in $\mathbb{R}^n$.
    \item A is an orthogonal matrix.
    \item $A^{-1}=A^T$.  
\end{enumerate}
We will work through a TFAE (The Following Are Equivalent) proof one step at a time for a $2 \times 2$ matrix $A$. The way TFAE proofs work is we show one-way implications that end up being circular. 
\begin{itemize}
    \item Start by justifying that (1) implies (2). Hint: compute the matrix multiplication using the dot product strategy. 
    \item Next, justify that (2) implies (3). Hint: $\vec v \cdot \vec w = \vec v ^T \vec w$. 
    \item Next, justify that (3) implies (4). Hint: What is $||\vec x ||^2$?. 
    \item Next, justify (4) implies (5). Hint: What is your definition of an orthogonal matrix? 
    \item Finally, justify (5) implies (1). Hint: A standard matrix for any transformation $T$ can be written as $[T(e_1),T(e_2)]$ and $e_1,e_2$ are orthonormal to each other. If $||T(\vec e_1) + T(\vec e_2)||^2 = ||T(\vec e_1)||^2 + ||T(\vec e_2)||^2$ then $T(e_1),T(e_2)$ are orthogonal. 
    \item Here the cycle would be complete, but (6) is never used. To make sure (6) is still equivalent show that (2) implies (6) and (6) implies (2) (or that they are the same statement).
\end{itemize}}
][chg-WRIT-matcom,ch5-CON-ortho] %this is written as a comma seperated list with no spaces between commas
    [Note to TAs: Students do not know how to do "if then" proofs. They only know how to check a definition. The use of logic can be done with plain English to justify a few things. Give them time to do the SBG question then work together on the DEV question giving hints and then some time for them about it.*]    %this is written as a comma seperated list with no spaces between commas
    (1) implies (2):
From SBG 1 this is true. 
(2) implies (3):
$A(\vec v) \cdot A(\vec w) = (A\vec v)^T(A\vec w) = \vec v ^T A^T A \vec w = \vec v ^T I_n \vec w = \vec v ^T \vec w = \vec v \cdot \vec w$ \\
(3) implies (4): $||A \vec x||^2 = (A\vec x) \cdot (A \vec x) = \vec x \cdot \vec x = ||\vec x||^2$ \\
(4) implies (5): By definition, an orthogonal matrix is the matrix representation of a transformation which preserves length, so this holds. \\
(5) implies (1): Since $A$ is an orthogonal matrix, it preserves length by definition. Because of this, the length of $A \vec e_1$ and $A \vec e_2$ are both 1 (unit length). To prove that $A \vec e_1$ and $A \vec e_2$ are orthogonal to each other, consider, since $A$ preserves length, 
$||A \vec e_1 + A\vec e_2||^2 = ||A(\vec e_1 + \vec e_2)||^2 = ||e_1 + e_2||^2 = ||e_1||^2 + 2(e_1 \cdot e_2) + ||e_2||^2$ but since $e_1 \cdot e_2 = 0$ we get $||e_1 + e_2||^2 = ||e_1||^2 + ||e_2||^2 = ||A \vec e_1||^2 + ||A \vec e_2||^2$. If $||A \vec e_1 + A \vec e_2||^2 = ||A \vec e_1||^2 + ||A \vec e_2||^2$ that means the two vectors $A \vec e_1$ and $A \vec e_2$ are orthogonal to each other. Now $A \vec e_1$ and $A \vec e_2$ are orthonormal so the columns of A are orthonormal as needed. \\
(6) if and only if (2): Since $A^TA=I_n$ can be rearranged to say $A^{-1}=A^T$ they are the same statement. 
\end{SaveQuestion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{SaveQuestion}[
        key=ch2-lintrans-sec2.2ex19to23-sbg,
        prompt={For the following, find the coefficient matrix that represents the linear transformation from $\mathbb{R}^3$ to $\mathbb{R}^3$. 
        \begin{enumerate} 
        \item The orthogonal projection onto the $xy$-plane.
        \item The reflection about the $xz$-plane.
        \item The rotation about the $z$-axis through an angle of $\pi / 2$, counterclockwise as viewed from the positive $z$-axis.
        \item The rotation about the $y$-axis through an angle $\theta$, counterclockwise as viewed from the positive $y$-axis.
        \item The reflection about the plane $y=z$.
        \end{enumerate}}
][ch2-COM-standmat] 
    [Finds four of the five coefficient matrices correctly.*]
    Consider that we can find the coefficient matrix that induces a linear transformation $T$ from $\mathbb{R}^3$ to $\mathbb{R}^3$ as follows.
    $$T(\vec x) = \begin{bmatrix} \vert & \vert & \vert \\ T(\vec e_1) & T(\vec e_2) & T(\vec e_3) \\ \vert & \vert & \vert \end{bmatrix}\vec x$$
    \begin{enumerate}
        \item Let $A$ be the matrix that induces the linear transformation $T$ of an orthogonal projection onto the $xy$-plane. We know that $\vec e_1, \vec e_2$ lie on the $xy$-plane, and thus should map to themselves. 
        $$T(\vec e_1) = \vec e_1 \quad T(\vec e_2) = \vec e_2$$
        Geometrically, we can see that $\vec e_3$ is closest to the zero vector on the $xy$-plane, and thus $T(\vec e_3) = \vec 0$. 
        Consequently, the matrix $A$ is given by the following. 
        $$A = \begin{bmatrix} \vert & \vert & \vert \\ T(\vec e_1) & T(\vec e_2) & T(\vec e_3) \\ \vert & \vert & \vert \end{bmatrix} = \begin{bmatrix} 1 & 0 & 0 \\ 0 & 1 & 0 \\ 0 & 0 & 0 \end{bmatrix}$$

        \item Let $B$ be the matrix that induces the linear transformation $T$ of a reflection about the $xz$-plane. We know that $\vec e_1, \vec e_3$ lie on the $xz$-plane, and thus should map to themselves.
        $$T(\vec e_1) = \vec e_1 \quad T(\vec e_2) = \vec e_2$$
        Geometrically, we an see that a reflection about the $xz$-plane negates the $y$ entry, and thus $T(\vec e_2) = -\vec e_2$.
        Consequently, the matrix $B$ is given by the following. 
        $$B = \begin{bmatrix} \vert & \vert & \vert \\ T(\vec e_1) & T(\vec e_2) & T(\vec e_3) \\ \vert & \vert & \vert \end{bmatrix} = \begin{bmatrix} 1 & 0 & 0 \\ 0 & -1 & 0 \\ 0 & 0 & 1 \end{bmatrix}$$

        \item Let $C$ be the matrix that induces the linear transformation $T$ of a rotation about the $z$-axis through an angle of $\pi / 2$, counterclockwise as viewed from the positive $z$-axis. Since we are rotating about the $z$-axis, we know that $z$ entry is fixed and thus $T(\vec e_3) = \vec e_3$. As for $\vec e_1, \vec e_2$, since we are rotating around the $z$-axis, this can be geometrically viewed as rotating the vectors in the $xy$-plane. By rotating $\pi / 2$ counterclockwise, we see that $T(\vec e_1) = \vec e_2, T(\vec e_2) = -\vec e_1$. 
        Consequently, the matrix $C$ is given by the following.
        $$C = \begin{bmatrix} \vert & \vert & \vert \\ T(\vec e_1) & T(\vec e_2) & T(\vec e_3) \\ \vert & \vert & \vert \end{bmatrix} = \begin{bmatrix} 0 & -1 & 0 \\ 1 & 0 & 0 \\ 0 & 0 & 1 \end{bmatrix}$$
        
        \item Let $D$ be the matrix that induces the linear transformation $T$ of a rotation about the $y$-axis through an angle $\theta$, counterclockwise as viewed from the positive $y$-axis. For this part of the question, it is easiest to use the definition of a rotation matrix about the $y$-axis. This gives us the following.   
        $$D = \begin{bmatrix} \cos(\theta) & 0 & \sin(\theta) \\ 0 & 1 & 0 \\ -\sin(\theta) & 0 & \cos(\theta) \end{bmatrix}$$
        \item Let $E$ be the matrix that induces the linear transformation $T$ of a reflection about the plane $y = z$. We know that $\vec e_1$ lies on the plane $y = z$, and thus should map to itself.
        $$T(\vec e_1) = \vec e_1$$
        Geometrically, we an see that a reflection about the plane $y = z$ swaps the $y$ and $z$ entries (try viewing the plane from the side), and thus $T(\vec e_2) = \vec e_3, T(\vec e_3) = \vec e_2$. Consequently, the matrix $E$ is given by the following.  
        $$E = \begin{bmatrix} \vert & \vert & \vert \\ T(\vec e_1) & T(\vec e_2) & T(\vec e_3) \\ \vert & \vert & \vert \end{bmatrix} = \begin{bmatrix} 1 & 0 & 0 \\ 0 & 0 & 1 \\ 0 & 1 & 0 \end{bmatrix}$$
    \end{enumerate}
\end{SaveQuestion}




%%%%   EXAMPLES %%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{SaveQuestion}[
        key=ch0-vecarith-r3sketch-exa,
        prompt={Consider the vectors $\vec u = [2,4,6]$ and $\vec v = [-5,7,3]$ in $\mathbb{R}^3:$. We can sketch the sum and the difference of these vectors.}
][ch0-VG-vecarith] %needs a drawing
    [Reasonable sketch with labelling*]    %this is written as a comma seperated list with no spaces between commas
    Drawing
\end{SaveQuestion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{SaveQuestion}[
        key=ch0-vecarith-vectorform-exa,
        prompt={Consider the vector $\vec m = \begin{bmatrix} 3 \\ 1 \end{bmatrix}$ and the point $P(2,7)$ in $\mathbb{R}^2$. The equation of the line $\ell$ with direction vector $\vec m$ that passes through $p$, written in vector form is given by
        \[
t\begin{bmatrix}
    3\\1
\end{bmatrix}+\begin{bmatrix}
    2\\7
\end{bmatrix}, \quad \text{where } t\in \mathbb{R}  
        \]
Written in set notation we get $$\ell = \left\{ \vec x \in \mathbb{R}^3 \ | \ \vec x = t \begin{bmatrix} 3 \\ 1 \end{bmatrix} + \begin{bmatrix} 2 \\ 7 \end{bmatrix}, t \in \mathbb{R}\right\},$$
or
$$
\ell = \left\{t \begin{bmatrix} 3 \\ 1 \end{bmatrix} + \begin{bmatrix} 2 \\ 7 \end{bmatrix}, t \in \mathbb{R}\right\}.
$$
}
][ch0-CON-vecline] %this is written as a comma seperated list with no spaces between commas
    [Correct answer*]    %this is written as a comma seperated list with no spaces between commas
    $$l=[2,7] + t[3,1] | t \in \bbR$$
\end{SaveQuestion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{SaveQuestion}[
        key=ch0-vecarith-2pointsvecform-exa,
        prompt={Let's write the equation of the line (in vector form) through the pair of points $A = (1,7)$ and $B = (4,10)$.
    First we need to find the direction vector for the line:
  \[\vec d = [4-1,10-7] = [3,3]\]
  Then the equation of the line in vector from written in set notation is 
  \[
  l = \{\begin{bmatrix}
      1\\7
  \end{bmatrix} + t\begin{bmatrix}
    3\\3  
  \end{bmatrix}\:|\; t \in \bbR\}.
  \]       
    }
][ch0-CON-vecline] %this is written as a comma seperated list with no spaces between commas
    []    %this is written as a comma seperated list with no spaces between commas
\end{SaveQuestion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{SaveQuestion}[
        key=ch0-vecarith-ptonline-exa,
        prompt={Consider the line $\ell$ given by the following vector form.
        $$\begin{bmatrix} x \\ y \end{bmatrix} = \begin{bmatrix} 3 \\ 1 \end{bmatrix} + t \begin{bmatrix} 2 \\ 5 \end{bmatrix}$$
        To determine if the point $P(-1,11)$ lies on the line $\ell$, we must verify whether there exists some $t \in \mathbb{R}$ such that the following holds.
        $$\begin{bmatrix} -1 \\ 11 \end{bmatrix} = \begin{bmatrix} 3 \\ 1 \end{bmatrix} + t \begin{bmatrix} 2 \\ 5 \end{bmatrix}$$
        From the drawing, we see that the point does not lie on the line. Visualization \href{https://www.desmos.com/calculator/hkx7fuzan8}{here}.}
][ch0-VG-line]
    [Reasonable drawing with labelling*] 
    To see if $P$ lies on the line we consider the equation $[-1,11] = [3,1] + t[-2,5]$
    $-1 = 3-2t \to -4 = -2t \to t = 2 \\ 11 = 1 + 5t \to 10 = 5t \to t = 2$
    Since the $t$ values are the same we know $P$ lies on the line $[x,y] = [3,1] + t[-2,5]$ \\
    \includegraphics[scale=0.5]{Question Photos/ch0-vecarith-ptonline-sbg Drawing.jpg}
\end{SaveQuestion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\begin{SaveQuestion}[
        %key=<question key>,
        %prompt={<question>}
%][<learning standards>] %this is written as a comma seperated list with no spaces between commas
    %[<rubric items>]    %this is written as a comma seperated list with no spaces between commas
    %<question solution>
%\end{SaveQuestion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\begin{SaveQuestion}[
        %key=<question key>,
        %prompt={<question>}
%][<learning standards>] %this is written as a comma seperated list with no spaces between commas
    %[<rubric items>]    %this is written as a comma seperated list with no spaces between commas
    %<question solution>
%\end{SaveQuestion}